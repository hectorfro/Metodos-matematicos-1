\chapter{Los vectores de siempre}
\section*{La ruta de este capítulo}
Suponemos que los estudiantes se acercan a estas notas, no solo conociendo algunos términos sino siendo capaces de buscar muchos otros en la red. Por lo tanto, concebimos este capítulo para que apunte a varios objetivos. Por un lado, buscamos refrescar un conjunto de conceptos básicos que seguramente son conocidos por el lector. Si no lo son, aprovechamos la oportunidad para presentarlos --en el marco de $\mathds{R}^3$, es decir ejemplificando con vectores tridimensionales--  utilizando el lenguaje abstracto al cual haremos referencia en los próximos capítulos. Siguiendo esta lógica presentamos las propiedades de los vectores en la próxima sección \ref{VectoresGeometricos}; la independencia lineal, bases, producto interno (sección \ref{IndependenciaVector3D}) y los sistemas de coordenadas (sección \ref{VectoresComponentes}). Con la excusa del algebra vectorial en coordenadas, introducimos algunos elementos de álgebra vectorial con índices, que normalmente no son cubiertos tan tempranamente (sección \ref{AlgebraVectorialIndices}) en cursos de métodos matemáticos. Adicionalmente, esta excusa nos sirve de puente para presentar nociones operativas de tensores y de análisis de vectorial que formalizaremos más adelante en los capítulos \ref{CapVectoresDualesTensores} y \ref{CapAnalisisVectorial}, respectivamente. La representación de los número complejos como vectores, con ``componentes'' reales y complejas justifica la incorporación de este repaso en la última sección \ref{VectoresNumerosComplejos}. Finalmente, este capítulo nos sirve para iniciar el uso de la herramienta de cálculo algebraico que nos acompañará en el resto del libro y que se detalla en el apéndice \ref{IntroMaxima}. 

\section{Vectores geométricos}
\label{VectoresGeometricos}
\index{Modelos en Física}
Desde  los primeros cursos de Física en educación media, venimos hablando de vectores como cantidades que tienen que ser representadas con más de un número. Son varias las razones que obligan a introducir este (y otro) tipo de cantidades ``multidimensionales''.  Enumeraremos algunas que, a nuestro criterio personal, son las más representativas.

\begin{enumerate}
\item \textbf{Necesidad de modelos matemáticos de la naturaleza. }Desde los albores del renacimiento, con Galileo Galilei a la cabeza, nos es imperioso representar cantidades de manera precisa. Las matemáticas nos apoyan en esta necesidad de precisión y desde ese entonces son el lenguaje de la actividad científica.

\item \textbf{Los modelos tienen que ser contrastados con los experimentos}. Las ciencias y sus modelos, en última instancia, tienen que ver con la realidad, con la naturaleza y por ello debemos medir y contrastar las hipótesis con esa realidad que modelamos. Necesitamos representar cantidades medibles (observables) y que, por lo tanto, tienen que ser representadas de la forma más compacta, pero a la vez más precisa posible.

\item \textbf{Las leyes de los modelos deben ser independiente de los observadores.} Cuando menos a una familia significativa de observadores, el comportamiento de la naturaleza no puede depender de la percepción de un determinado observador, por lo tanto, los modelos que construimos para describirla tampoco pueden depender de los observadores. 
\end{enumerate}
\begin{figure}[t]
\begin{center}
\includegraphics[height=3.1in,width=5.6in]
%\includegraphics[height=3.1in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_1.jpg}
\caption{Vectores y sus operaciones}
\label{fig1vectcartes}
\end{center}
\end{figure}

Es común que tropecemos con: escalares, vectores, tensores y espinores, dependiendo del número de cantidades que necesitemos para representar determinado objeto matemático. Podremos constatar que las leyes de la Física vienen escritas en forma vectorial (o tensorial) y, por lo tanto, será la misma ley para la familia de observadores equivalentes.

\subsection{Escalares y vectores}
\label{EscalaresVectores}
\index{Vectores 3D}
Dejaremos para más adelante caracterizar objetos como tensores y espinores, por ahora nos contentaremos con refrescar nuestros recuerdos con cantidades como:

\begin{itemize}
\item {\textbf{Escalares: }} Serán aquellas cantidades las cuales se representan con UN solo número, una magnitud: temperatura, volumen, masa, entre otras. Es costumbre no denotarlas de manera especial, así $T=5^{\circ}$C representará una temperatura de $5$ grados centígrados.

\item{\textbf{Vectores: }} Serán cantidades las cuales, para ser representadas por un objeto matemáticos, necesitan más de una cantidad: requieren de UN número, UNA dirección y UN sentido. Entre las cantidades que típicamente reconocemos como vectores están: la velocidad, la aceleración, la fuerza. En términos gráficos podremos decir que un vector será un segmento orientado, en el cual la dimensión del segmento representará su módulo y su orientación la dirección y el sentido. Para diferenciarlos de las cantidades escalares hay una variedad de representaciones, entre ellas: en negrita $\mathbf{a}$;  con una flecha arriba de la cantidad $\vec{a};$ con una tilde arriba o abajo $\tilde{a}$; o explicitando el origen del segmento orientado $\overrightarrow {OP}$. El módulo del vector lo representaremos dentro de la función valor absoluto, o sencillamente sin la flecha arriba $a=\left|  \mathbf{a}\right|  =| \vec{a} | $.
\end{itemize}


%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\begin{minipage}{7.8cm}
Los vectores son independientes del sistema de coordenadas. Sus características (módulo, dirección y sentido) se preservarán en todos los sistemas de coordenadas. Más aún, habrá vectores que podremos desplazar (conservando su módulo dirección y sentido) paralelos a ellos mismos, y seguirán representando las mismas cantidades. Por ello encontraremos el término de \textit{vectores deslizantes}. Un ejemplo son las fuerzas que actúan en un determinado cuerpo, como se muestra en el cuadrante I en la figura \ref{fig1vectcartes}. También habrá vectores atados a un punto en el espacio, por cuanto representan una de las propiedades de ese punto: la velocidad del viento, el campo eléctrico, o sus variaciones son ejemplos de \textit{vectores atados} (observe la figura \ref{fig2vectcartes} como ejemplos ilustrativos).
\end{minipage} \hfill 
\begin{minipage}{8.0cm} 
\includegraphics[height=2.0in,width=3.2in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_2.jpg}
\caption{Ejemplos de \textit{vectores atados }}
\label{fig2vectcartes}
\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%


\subsection{Álgebra de vectores}
\label{AlgebraVectores}
\index{Vectores 3D!Álgebra}
\index{Álgebra de vectores 3D}
Enumeraremos rápidamente el álgebra de vectores sin hacer referencia a un sistema de coordenadas en particular. Desde los cursos básicos de matemáticas  nos enseñaron a representar gráficamente este álgebra, así tenemos que:

\paragraph{Vector nulo.}
Es aquel que tiene por módulo cero y no se le pude asignar dirección ni sentido. El frecuente representar al vector nulo por $\mathbf{0}$.

\paragraph{Vector unitario.}
Es aquel que tiene por módulo la unidad, es muy útil por cuanto, para efectos algebraicos, ``contiene'' únicamente dirección y sentido. Lo denotaremos con un acento circunflejo, comúnmente llamado ``sombrero'' $\hat {\mathbf{u}}_a={\mathbf{a}}/ {| \mathbf{a} |}$,  con lo cual todo vector se podrá expresar por un módulo en la dirección y sentido de un vector unitario: $\mathbf{a}=\left| \mathbf{a}\right|  \hat{\mathbf{u}}_a =a\, \hat{\mathbf{u}}_a$.

\paragraph{Comparación de vectores.}
Al comparar sus módulos diremos que pueden ser mayores, menores o iguales. Por lo tanto, tal y como mostramos en
el cuadrante IIa de la figura \ref{fig1vectcartes}, dos vectores serán iguales, $\mathbf{a}=\mathbf{b}$, si tienen la misma dirección y sentido. 

\paragraph{Multiplicación por un número.}
Un vector multiplicado por un número, $\alpha$, cambiará su módulo si $\alpha>0$ y cambiará su sentido, y eventualmente
su módulo, si $\alpha<0$. Tal y como puede apreciarse en el cuadrante IIa de la figura \ref{fig1vectcartes}. Claramente
dos vectores proporcionales serán colineales. Diremos además, que el inverso del vector $\mathbf{a}$ será la
multiplicación de $\mathbf{a}$ por $\left( -1\right)$. Esto es: 
$\left( -1\right) \mathbf{a}=-\mathbf{a}$.

\paragraph{Suma de vectores.}
Para sumar vectores utilizamos la regla del paralelogramo, es decir, desplazamos paralelamente uno de los vectores y lo colocamos a continuación del otro, de tal forma que la diagonal del paralelogramo, que tiene por lados los vectores sumandos, constituye el vector suma, (ver cuadrantes IIa y IIb de la figura \ref{fig1vectcartes}).

Este esquema se puede generalizar para varios vectores tal y como lo mostramos en el cuadrante III de la figura \ref{fig1vectcartes}. Allí construimos un polígono cuyos lados los constituyen los vectores sumandos $\mathbf{a}, \mathbf{b}, \mathbf{c}$, $\mathbf{d}$ y $\mathbf{n}$ con $\mathbf{n}=\mathbf{a}+\mathbf{b}+\mathbf{c}+\mathbf{d}$. Nótese que aún en el caso tridimensional, el vector suma siempre será coplanar (estará en el mismo plano) a los sumandos que lo generaron.

Igualmente, podemos definir la resta de vectores al sumar el inverso. Esto es:
\[
\mathbf{a}-\mathbf{b}\equiv \mathbf{a}+\left(  -\mathbf{b}\right)  \quad\Rightarrow
\mathbf{0}=\mathbf{a}-\mathbf{a}\equiv\mathbf{a}+\left(  -\mathbf{a}\right) \,.
\]

En términos gráficos la resta de dos vectores se representa colocando los vectores (minuendo y sustraendo) con el mismo origen y uniendo las cabezas de flecha. Dependiendo de cual vector es el minuendo y cual el sustraendo el vector resta apuntará del sustraendo hacia el minuendo,  esto es:  $\left( \mathbf{a}+\mathbf{b}+\mathbf{c} \right)  -\mathbf{a}=\mathbf{b}+\mathbf{c}$.

Claramente, el módulo del vector resta representa la distancia entre los dos extremos de los vectores minuendo y sustraendo. 

\paragraph{Un resumen de propiedades.}

Las propiedades (obvias) del álgebra de vectores son:
\begin{itemize}
\item  La suma de vectores:

\begin{itemize}
\item  es cerrada $\mathbf{a}+\mathbf{b}=\mathbf{c}$,

\item  es conmutativa $\mathbf{a}+\mathbf{b}=\mathbf{b}+\mathbf{a}$,

\item  es asociativa $\left(  \mathbf{a} +\mathbf{b} \right)  +\mathbf{c}=\mathbf{a}+\left(\mathbf{b}+\mathbf{c} \right)$,

\item  tiene un único elemento neutro $\mathbf{0}+\mathbf{a}=\mathbf{a}+\mathbf{0}=\mathbf{a}$, 
$\forall \,  \mathbf{a}$,

\item  existe un elemento simétrico $ -\mathbf{a} $  (uno para cada vector) tal que $\mathbf{0}=\mathbf{a}-\mathbf{a} \equiv \mathbf{a}+\left(  -\mathbf{a} \right)$,

\item  es distributiva  respecto a la multiplicación por números: 
$\alpha\left( \mathbf{a}+\mathbf{b} \right)  =\alpha\mathbf{a}+\alpha\mathbf{b}$.
\end{itemize}

\item  La multiplicación de números por vectores:

\begin{itemize}
\item  es conmutativa $\mathbf{a}\alpha=\alpha\mathbf{a}$,

\item  es asociativa $\alpha\left(  \beta\mathbf{a}\right)  =\left(  \alpha\beta\right) \mathbf{a}$,

\item  es distributiva $\left(  \alpha+\beta\right) \mathbf{a}=\alpha\mathbf{a}+\beta\mathbf{a}$.
\end{itemize}
\end{itemize}


\subsection{Vectores linealmente independientes}
\label{IndependenciaVector3D}
\index{Independencia Lineal!Vectores 3D}
Armados con el álgebra y siendo explícito en sus propiedades podemos construir la primera aproximación a uno de los
conceptos fundamentales del álgebra lineal. La noción de \textit{independencia }o \textit{dependencia lineal.} Diremos que tres vectores $\mathbf{a},\mathbf{b},\mathbf{c}$ son \textit{linealmente independientes}  en $\mathds{R}^3$ si se cumple que:
\[
\alpha\ \mathbf{a}+\beta\ \mathbf{b}+\gamma\ \mathbf{c}=\mathbf{0} \quad \Rightarrow \quad \alpha=\beta=\gamma=0 \,.
\]
Es decir, que la única manera que al sumar cualquier múltiplo de $\mathbf{a}, \mathbf{b}$ y  $\mathbf{c}$ de modo que la suma se anule es obligando a que los escalares sean \textbf{necesariamente} nulos. En caso contrario, es decir, si no se cumple lo anterior  diremos que uno de los vectores será \textit{linealmente dependiente} y  por lo tanto se podrá expresar como combinación lineal de los otros dos. Si por ejemplo $\gamma\neq0$,  entonces: 
\[
\alpha \  \mathbf{a}+\beta \  \mathbf{b}+\gamma \ \mathbf{c}=\mathbf{0} \,\, \Rightarrow \,\, 
\mathbf{c}=-\frac{\alpha}{\gamma}\mathbf{a}-\frac{\beta}{\gamma}\mathbf{b} \,\, \Rightarrow \,\, 
\mathbf{c}=\bar{\alpha}\ \mathbf{a}+\bar{\beta}\ \mathbf{b}\,.
\]

Es muy importante señalar que los vectores linealmente independientes formarán una {\it base} para el espacio donde estos  vectores  ``viven'' y el número máximo de vectores linealmente independientes será la dimensión de  ese espacio de ``residencia''. Más adelante estudiaremos con más detalle el concepto de bases.

Tratemos de concretar algunas de estas afirmaciones.

\begin{itemize}
\item \textit{Dos vectores linealmente dependientes son colineales}. 
Es decir, los vectores están contenidos en la misma línea y es claro que:
\[
\alpha \ \mathbf{a}+\beta \ \mathbf{b}=\mathbf{0}\quad\text{con alguno de }\left\{
\begin{array}
[c]{c}
\alpha\neq0\\
\beta\neq0
\end{array}
\right\}  \quad  \Rightarrow \quad   \left\{
\begin{array}
[c]{c}
\mathbf{a}=-\dfrac{\beta}{\alpha}\mathbf{b}\\
\\
\mathbf{b}=-\dfrac{\alpha}{\beta}\mathbf{a}
\end{array}
\right.
\]
el contrario también será cierto: \textit{si dos vectores son colineales ellos serán linealmente dependientes.}
\[
\mathbf{a}=\lambda\mathbf{b}\,\, \Rightarrow \,\,  
\alpha\mathbf{a}+\beta\mathbf{b}=\mathbf{0}\,\, \Rightarrow \,\,  
\alpha\lambda\mathbf{b}+\beta\mathbf{b}=\mathbf{0} \,\, \Rightarrow \,\,  \left(  \alpha\lambda+\beta\right)  \mathbf{b}=\mathbf{0}\,\, \Rightarrow \,\,  
\lambda=-\frac{\beta}{\alpha} \,,
\]
con lo cual podremos afirmar que si dos vectores son linealmente independientes ellos \textbf{no} son colineales.


\item \textit{Tres vectores linealmente dependientes son coplanares}.   Por ser los tres vectores \textit{linealmente dependientes} al menos uno de los escalares tiene que ser distinto de cero, digamos  $\gamma$,  esto es:
\[
\alpha\ \mathbf{a}+\beta \ \mathbf{b}+\gamma \ \mathbf{c}= \mathbf{0}\quad  \Rightarrow \quad  
\mathbf{c}=-\frac{\alpha}{\gamma}\mathbf{a}-\frac{\beta}{\gamma}\mathbf{b}=\xi^1 \mathbf{a}+\xi^2\mathbf{b} \,,
\]
pero como $\xi^1 \mathbf{a}\propto\mathbf{a}$ y $\xi^2\ \mathbf{b}\propto \mathbf{b}$, esto significa que: $\xi^1 \mathbf{a}$ y $\mathbf{a}$  son colineales, de la misma manera que  $\xi^2 \mathbf{b}$ y  $\mathbf{b}$, y  por lo tanto, la  suma estará en el mismo plano.

\item \textit{Dos vectores linealmente independientes generan todos los vectores coplanares}. 
Dado dos vectores $\mathbf{a}$ y $\mathbf{b}$ linealmente independientes, entonces cualquier vector
$\mathbf{c}$, coplanar con $\mathbf{a}$ y $\mathbf{b}$,  podrá expresarse como una combinación lineal de éstos. Diremos que: $\mathbf{c}$ se expresa en términos de $\mathbf{a}$ y $\mathbf{b}$ como: $\mathbf{c} = \xi^1\mathbf{a}+\xi^2 \mathbf{b}$, y esa expresión es única.

La primera de las afirmaciones es directa por cuanto hemos visto que si $\mathbf{a}$ y $\mathbf{b}$ son linealmente independientes y $\mathbf{c}$ es coplanar con $\mathbf{a}$ y $\mathbf{b}$, entonces, necesariamente $\mathbf{a}, \mathbf{b}$ y $\mathbf{c}$ son linealmente dependientes. Esto es:
\[
\alpha \ \mathbf{a}+\beta \ \mathbf{b}+\gamma \ \mathbf{c}={\bf 0} \,\,\Rightarrow\,\, \mathbf{c}=-\frac{\alpha}{\gamma}\mathbf{a}-\frac{\beta}{\gamma}\mathbf{b}=\xi^1 \mathbf{a}+\xi^2 \mathbf{b} \,.
\]

La demostración de que la expansión es única viene de suponer que existen dos maneras distintas de representar al mismo vector $\mathbf{c}$. Veamos:
\[
\left.
\begin{array}
[c]{c}
\mathbf{c}=\xi^1 \mathbf{a}+\xi^2 \mathbf{b}\\
\\
\mathbf{c}=\zeta^1 \mathbf{a}+\zeta^2 \mathbf{b}
\end{array}
\right\}  \,\,\Rightarrow\,\, \mathbf{0}=\left( \xi^1-\zeta^1\right)   \mathbf{a}+
\left( \xi^2-\zeta^2\right)   \mathbf{b}\,\,\Rightarrow\,\,\left\{
\begin{array}
[c]{c}
 \xi^1-\zeta^1 =0\,\,\Rightarrow\,\, \quad \xi^1=\zeta^1\\
\\
\xi^2-\zeta^2=0\,\,\Rightarrow\,\, \quad \xi^2=\zeta^2
\end{array}
\right.
\]
debido a que $\mathbf{a}$ y $\mathbf{b}$ son linealmente independientes. 

La demostración para el caso tridimensional es equivalente. Es decir tres vectores linealmente independientes $\mathbf{a},\mathbf{b}$ y $\mathbf{c}$ expanden, de manera unívoca, todos los vectores del espacio. Esta demostración queda para el lector.

\item \textit{Vectores Base}.   Cuando un vector $\mathbf{c}$ se pueda expresar en términos de dos vectores linealmente independientes, $\mathbf{a}$ y $\mathbf{b}$, por ejemplo: $\mathbf{c}=\xi^1\mathbf{a}+\xi^2\mathbf{b}$, diremos que $\mathbf{a}$ y $\mathbf{b}$ forman una base para todos los vectores coplanares a éstos. Igualmente para el caso tridimensional: tres vectores linealmente independientes $\mathbf{a},\mathbf{b}$ y $\mathbf{c}$ conformarán una base para los vectores del espacio. Los números $\xi^1$ y $\xi^2$ para el caso bidimensional se denominan las componentes de $\mathbf{c}$ a lo largo de $\mathbf{a}$ y $\mathbf{b}$. Equivalentemente, $\left(\xi^1, \xi^2, \xi^3\right)$ serán las componentes de cualquier vector para el caso 3D a lo largo de $\mathbf{a},\mathbf{b}$ y $\mathbf{c},$ respectivamente. Esta nomenclatura será más evidente luego de la próxima sección.
\end{itemize} 

\begin{figure}[t]
\begin{center}
\includegraphics[height=3.0in,width=5.8in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_3.jpg}
\caption{Productos de vectores}
\label{fig3vectcartes}
\end{center}
\end{figure}

\subsection{Productos de vectores}
\label{ProductosVectores}
\index{Productos de Vectores 3D}
\index{Vectores 3D!Productos}
\index{Producto!Vectores 3D}

Hemos sumado y restado vectores, el siguiente paso es multiplicarlos. Básicamente existen dos formas de multiplicar vectores: el producto  escalar y el producto vectorial, veremos a continuación de que se trata y sin especificar un sistema de coordenadas para referirlos. 

\subsubsection{Producto escalar}
\label{ProductoEscalar1}
\index{Producto escalar}
\index{Producto!escalar}
\index{Escalar!Producto}
\index{Desigualdad de Cauchy-Schwarz!Vectores 3D}
Denominaremos producto escalar de dos vectores $\mathbf{a}$ y $\mathbf{b}$ a un escalar cuyo valor será igual al
producto de los módulos multiplicado por el coseno del ángulo que ellos forman:
\[
\zeta=\mathbf{a}\cdot\mathbf{b}=\left|  \mathbf{a}\right|  \left|  \mathbf{b}\right|
\cos(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle } \,.
\]

El significado geométrico del producto escalar es evidente, cuadrante I de la figura \ref{fig3vectcartes}. El producto escalar representa la proyección de $\mathbf{a}$ sobre $\mathbf{b}$ y equivalentemente la proyección de $\mathbf{b}$ sobre $\mathbf{a}$.

De esta definición se derivan varias consecuencias las cuales por obvias no dejan de ser importantes:
\begin{itemize}
\item \textit{El producto escalar de un vector consigo mismo, siempre es positivo}:\\
 $\zeta=\mathbf{a}\cdot\mathbf{a}=\left|  \mathbf{a}\right| ^{2}\geq0$, y sólo será nulo si $\mathbf{a}$
es el vector nulo. Esto es, $\zeta=0 \,\,  \Rightarrow \,\,  \mathbf{a}=\mathbf{0}$. Con esto podemos concluir que $\left|\mathbf{a}\right|  =\sqrt{\mathbf{a}\cdot\mathbf{a}}=\sqrt{\zeta}$.

\item \textit{El producto escalar es conmutativo}:\\
$\zeta=\mathbf{a}\cdot\mathbf{b}=\mathbf{b}\cdot\mathbf{a}$,  ya que el ángulo entre los vectores es el mismo y la multiplicación entre escalares es conmutativa.

\item \textit{El producto escalar es distributivo}: \\
Esto es, $\mathbf{a} \cdot\left(  \mathbf{b}+\mathbf{c}\right)  =\mathbf{a}\cdot\mathbf{b} +\mathbf{a}\cdot\mathbf{c}$. La demostración (gráfica) puede apreciarse en el cuadrante II de la figura \ref{fig3vectcartes}.

\item \textit{La multiplicación por un número}:\\$
\bar{\zeta}=\alpha \zeta  = \left|  \alpha\right|  \left(  \mathbf{a}\cdot\mathbf{b}\right)  =
\left(\alpha\mathbf{a}\right)  \cdot\mathbf{b}=\mathbf{a} \cdot \left(  \alpha\mathbf{b}\right)=
\left|  \alpha\mathbf{a}\right|  \left|  \mathbf{b}\right|  \cos(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle }=
\left|  \mathbf{a}\right|  \left| \alpha\mathbf{b}\right|  \cos(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle }$.

\item \textit{Desigualdad de Cauchy-Schwarz}. \\
A partir de la definición de producto interno es inmediata la comprobación de la siguiente desigualdad:
\[
\left(  \mathbf{a}\cdot\mathbf{b}\right)^{2}=\left(  \left|  \mathbf{a}\right|
\left|  \mathbf{b}\right|  \cos(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}\right) ^{2}\,\,  \Rightarrow \,\,  \left(  \mathbf{a}\cdot\mathbf{b}\right)^{2}
\leq\left|  \mathbf{a}\right|  ^{2}\left|  \mathbf{b}\right| ^{2}
\,\, \Leftrightarrow \,\,  \mathbf{a}\cdot\mathbf{b}  \leq\left|  \mathbf{a}\right|  \left|  \mathbf{b}\right| \,,
\]
ya que: $0\leq\cos^{2}(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle }\leq1$.

\item \textit{Del producto escalar surge el teorema del coseno}.\\
Es inmediato calcular el producto escalar de un vector consigo mismo, para ello vamos a suponer que $\mathbf{c}=\mathbf{a}+\mathbf{b}$, con lo cual:
\[
\mathbf{c}=\mathbf{a}+\mathbf{b}\,\,  \Rightarrow \,\,  \mathbf{c}\cdot\mathbf{c}=\left(  \mathbf{a}+\mathbf{b}\right)  \cdot\left(  \mathbf{a}+\mathbf{b}\right)  \,\,  \Rightarrow \,\, 
\left|  \mathbf{c} \right|^{2}=\left|  \mathbf{a}\right|^{2}+\left|  \mathbf{b}\right|^{2} + 2\left|  \mathbf{a}\right|  \left|  \mathbf{b}\right| \cos(\theta)\,,
\]
donde $\theta$ es el ángulo que forman los vectores $\mathbf{a}$ y $\mathbf{b}$. Esto no  es otra cosa que el teorema del coseno y está ilustrado en el cuadrante III de la figura \ref{fig3vectcartes}.

\item \textit{Dos vectores no nulos son ortogonales (perpendiculares) si su producto escalar es nulo}.\\
 Esta afirmación es inmediata:
\[
\mathbf{a}\ \bot\ \mathbf{b} \,\,\Rightarrow\,\,  \theta_{\left\langle \mathbf{a},\mathbf{b}\right\rangle }=
\frac{\pi}{2} \,\,\Rightarrow\,\,  \mathbf{a}\cdot\mathbf{b}=\left|
\mathbf{a}\right|  \left|  \mathbf{b}\right|  \cos(\theta)_{\left\langle \mathbf{a} ,\mathbf{b}\right\rangle }=0\,.
\]
\end{itemize}


\subsubsection{Producto vectorial} 
\label{ProductorVectorial1} 
\index{Producto vectorial}
A diferencia del producto escalar que genera un escalar, el producto vectorial tiene como resultado otro vector: $\mathbf{c}=\mathbf{a}\times\mathbf{b}$  (realmente un pseudovector o vector axial en contraposición a los vectores polares, pero eso lo veremos más adelante en la sección \ref{PseudoCantidades}), con las siguientes características:

\begin{itemize}
\item  El módulo de $\mathbf{c}$, será:
\[
\left|  \mathbf{c}\right|  =\left|
\mathbf{a}\right|  \left|  \mathbf{b}\right|  \operatorname*{sen}(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}\,.
\] 
Es claro que el módulo de $\mathbf{c}$ representa el área del paralelogramo cuyos lados están formados por $\mathbf{a}$ y $\mathbf{b}$ (ver el cuadrante V de la figura \ref{fig3vectcartes}).

\item  Tal y como muestran los cuadrantes IV y V de la figura
\ref{fig3vectcartes}, $\mathbf{c}$ tendrá como dirección la perpendicular al plano que forman $\mathbf{a}$ y $\mathbf{b}$, y como sentido la regla del pulgar derecho, regla de la mano derecha, o de manera  más elegante, será positiva cuando la multiplicación de $\mathbf{a} \times\mathbf{b}$ corresponda  al sentido antihorario.
\end{itemize}

Podemos deducir algunas consecuencias de esta definición.
\begin{itemize}
\item \textit{El producto vectorial es anticonmutativo}.\\
$\mathbf{a}\times\mathbf{b}=-\mathbf{b}\times\mathbf{a}$, y se sigue de la definición que expresa el cuadrante IV de la figura \ref{fig3vectcartes}.

\item \textit{El producto vectorial es distributivo respecto a la suma}.\\
$\mathbf{a}\times\left(  \mathbf{b}+\mathbf{c}\right)  =\mathbf{a} \times  \mathbf{b} +\mathbf{a}\times\mathbf{c}$. La demostración de esto lo dejaremos para más adelante. 
\item \textit{La multiplicación por un número}.
\[
\left|  \mathbf{c}\right|  =\left|  \alpha\right|  \left|  \mathbf{a}\times\mathbf{b} \right|  =
\left|  \left(  \alpha\mathbf{a}\right)  \times\mathbf{b}\right|=\left|  \mathbf{a}\times\left(  \alpha\mathbf{b}\right) \right|  = 
\left| \alpha\mathbf{a}\right|  \left|  \mathbf{b}\right|  \operatorname{sen}(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}=
\left|  \mathbf{a}\right|  \left|  \alpha\mathbf{b}\right|  \operatorname{sen}(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}\,.
\]

\item \textit{Dos vectores serán colineales si su producto vectorial se anula}. \\
Como en el caso cuando se anulaba el producto escalar 
identificábamos a dos vectores ortogonales, cuando se anula el producto vectorial tendremos dos vectores paralelos. Es claro que esto se cumple de inmediato:
\[
\mathbf{a}\ \Vert\ \mathbf{b}\,\,\Rightarrow\,\,  
\theta_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}=0
\,\,\Rightarrow\,\,  \left|  \mathbf{c}\right|  =\left|  \mathbf{a}\times\mathbf{b}\right|
=\left|  \mathbf{a}\right|  \left|  \mathbf{b}\right|  \operatorname{sen}(\theta)_{\left\langle \mathbf{a},\mathbf{b}\right\rangle}=0\,.
\]

Si el módulo del vector es cero, obvio que es el vector nulo. Ahora bien, también de aquí deducimos que:
\[
\mathbf{c}=\mathbf{a}\times\mathbf{b} \,\,\Rightarrow\,\,  \mathbf{c}\cdot\mathbf{a}=\left(\mathbf{a}\times\mathbf{b}\right)  \cdot\mathbf{a}=\mathbf{c}\cdot\mathbf{b}=\left(  \mathbf{a}\times\mathbf{b}\right)  \cdot\mathbf{b}=0\,.
\]
\end{itemize}

\subsection{Producto triple o mixto}
\label{ProductoTriple}
\index{Producto Triple}
\index{Producto Mixto}
Analicemos ahora el número (pseudoescalar) que proviene de la multiplicación:
\[
V=\mathbf{c}\cdot\left(  \mathbf{a}\times\mathbf{b}\right)  =\left|  \mathbf{c}\right|
\left|  \left(  \mathbf{a}\times\mathbf{b}\right)  \right|  \cos(\theta)_{\left\langle
\mathbf{c},\mathbf{a}\times\mathbf{b}\right\rangle }\,.
\]
Este producto también cumple con algunas propiedades que enunciaremos ahora y demostraremos más tarde.

\begin{itemize}
\item \textit{El producto mixto representa el volumen del paralelepípedo cuyos lados son los vectores }$\mathbf{a},\mathbf{b}$ y $\mathbf{c}$. \\
 $\left|  \mathbf{a}\times \mathbf{b}  \right| $ representa el área de la base y la altura está representada por la proyección del vector $\mathbf{c}$ sobre la perpendicular al plano de la base que es, precisamente $\left| \mathbf{c}\right|  \cos
(\theta)_{\left\langle \mathbf{c},\mathbf{a}\times\mathbf{b}\right\rangle }$.
\item \textit{El producto mixto es cíclico respecto a sus factores}.
\[
\left(  \mathbf{a}\times\mathbf{b}\right)  \cdot\mathbf{c}=
\left(  \mathbf{c}\times\mathbf{a}\right)  \cdot\mathbf{b}=
\left(  \mathbf{b}\times\mathbf{c}\right)  \cdot\mathbf{a} \,.
\]
Esta afirmación se verá demostrada más adelante.
\item \textit{El producto mixto se anula cuando se repite alguno de sus factores}.
\[
\left(  \mathbf{a}\times\mathbf{b}\right)  \cdot \mathbf{a}=
  \left(  \mathbf{a} \times \mathbf{b}\right)  \cdot \mathbf{b}=
  \left(  \mathbf{a}\times\mathbf{a}\right) \cdot\mathbf{c}=
  \left(  \mathbf{b}\times\mathbf{b}\right)  \cdot \mathbf{c}=0\,.
\]
Claramente, si $\left( \mathbf{a}\times\mathbf{b}\right)  \bot \, \mathbf{a} \,\,\Rightarrow\,\, 
\left(  \mathbf{a}\times\mathbf{b}\right)  \cdot\mathbf{a}=0$.

\item \textit{Si los tres vectores }$\mathbf{a},\mathbf{b}$\textit{ y }$ \mathbf{c} 
$\textit{ son coplanares (linealmente dependientes) entonces:} 
\[
\left( \mathbf{a}\times\mathbf{b}\right)\cdot\mathbf{c}=0 \,. 
\] 
Dicho de manera más elegante, útil e impactante: tres vectores que cumplen con:
\[
\left(\mathbf{a}\times\mathbf{b}\right)  \cdot\mathbf{c}\neq0 \,,
\]
son linealmente independientes y forman una base para el espacio tridimensional. 
Esa base se denominará levógira (contraria al giro de las manecillas del reloj) si el producto 
$\left( \mathbf{a}\times\mathbf{b}\right) \cdot \mathbf{c}<0$ y dextrógira (la convencional base de la 
mano derecha) si $\left( \mathbf{a}\times\mathbf{b}\right) \cdot\mathbf{c}>0.$
\end{itemize}

\subsection{{\color{Fuchsia}Ejemplos}}
\label{EjemploVectores}
\begin{enumerate}

\item En un segmento de recta $AB$ ubicamos un punto $D$ de manera que este punto divide al segmento en dos partes, es decir, en la proporción $\alpha$ : $\beta$ $(\overline{AB}=\overline{AD}+\overline{DB}=\alpha+\beta)$. Para ubicar el vector posición del punto $D$ podemos hacer lo siguiente.

A los puntos $A$ y $B$ le hacemos corresponder el vector ${\bf a}$ y el vector ${\bf b}$, respectivamente, con un origen común $O$. De manera que ${\bf c}={\bf b}-{\bf a}$  es un vector que va desde el punto $A$ al punto $B$. Entonces, la distancia $\overline{OD}$, a la que le podemos asociar  el vector ${\bf d}$,  no es más que:
\[
{\bf d}= \overline{OD}= 
{\bf a}+\frac{\alpha}{\alpha+\beta}({\bf b}-{\bf a}) =
\left(1- \frac{\alpha}{\alpha+\beta} \right){\bf a} + 
\frac{\alpha}{\alpha+\beta}{\bf b}= 
\frac{\beta}{\alpha+\beta}{\bf a} + \frac{\alpha}{\alpha+\beta}{\bf b}\,.
\]


\item Hemos definido la posición ${\bf r}$ del  centro de masa, para un sistema de $N$ partículas, al vector:
\[
{\bf r} = \frac{\Sigma_{i=1}^{N} m_{i} {\bf r}_{i} }{\Sigma_{j=1}^{N} m_{j}}\,,
\]
donde ${\bf r}_{i}$ corresponde con la posición de la $i-$ésima partícula.
Determinaremos la posición del centro de masa para un sistema de tres masas, $m_{i} =$ 1,2,3, ubicadas en los vértices de un triángulo equilátero de lado $l=2$.

Colocando el origen de coordenadas en uno de los vértices y uno de los ejes de coordenadas sobre uno de los lados, entonces tenemos:
\[
{\bf r} = \frac{\Sigma_{i=1}^{3} m_{i} {\bf r}_{i} }{\Sigma_{j=1}^{3} m_{j}} = \frac{m_{1}{\bf r}_{1} +  m_{1}{\bf r}_{1} }{M_{T}} = \frac{1 \cdot 2 {\bf i} + 3 \cdot \left({\bf i} + \sqrt{3} {\bf j}  \right)}{6} =  \frac{ 5}{6 }{\bf i} + \frac{\sqrt{3}}{2} {\bf j} \,.
\]


\item Dada una base ortonormal $\{ {\bf i}, {\bf j}, {\bf k} \}$ y los siguientes vectores:
\[
{\bf a} = 3{\bf i} + 2{\bf j} + {\bf k}\,, \quad {\bf b} = 3{\bf i} - 2{\bf j} + {\bf k}\,, \quad {\bf c} = {\bf i} -  {\bf k} \,.
\]

Queremos comprobar si $\{ {\bf a}, {\bf b}, {\bf c} \}$ forman una base.
  
Veamos, para que los vectores formen una base tienen que ser linealmente independientes. Esto es:
$
\alpha {\bf a} + \beta {\bf b} + \gamma  {\bf c}  =0 \,\, \Rightarrow \,\, \alpha = \beta = 
\gamma = 0 $,  con lo cual:
\[
\alpha \left(  3{\bf i} + 2{\bf j} + {\bf k} \right) + \beta \left(  3{\bf i} - 2{\bf j} + {\bf k} \right) + 
\gamma  \left(  {\bf i} -  {\bf k}  \right) =0 \,\, \Rightarrow \,\, 
\left\{\begin{array}{ l}
  3 \alpha + 3 \beta + \gamma = 0      \\
  2 \alpha - 2 \beta  = 0        \\
   \alpha +  \beta - \gamma = 0          
\end{array} 
\right.
\]
es fácil ver que la solución de este sistema es: $\alpha = \beta = \gamma =0$, por lo tanto, se demuestra que los vectores son linealmente independientes y por consiguiente forman una base.

Otra manera de resolverlo es mostrar que: ${\bf c} \cdot \left( {\bf a} \times {\bf b} \right) \neq 0$, y efectivamente:
\[
{\bf c} \cdot \left( {\bf a} \times {\bf b} \right) = \left|\begin{array}{ccc}1 & 0 & -1 \\3 & 2 & 1 \\3 & -2 & 1\end{array}\right| = 4 \neq 0 \,.
\]

Ahora bien,  si $\{ {\bf a}, {\bf b}, {\bf c} \}$ forman una base, podemos expresar otros vectores en términos de ésta base. Tomemos los vectores: ${\bf d} = {\bf i} + 2{\bf j}\,, \,\, {\bf e} = 3{\bf i} - 2{\bf j}$ y ${\bf f} = {\bf a} \times {\bf b}$ y expresémoslos en términos de $\{ {\bf a}, {\bf b}, {\bf c} \}$. 
  
Entonces, para el vector {\bf d} tenemos:
 \[
{\bf d}= {\bf i} + 2{\bf j} = \alpha \left(  3{\bf i} + 2{\bf j} + {\bf k}\right) + \beta \left(  3{\bf i} - 2{\bf j} + {\bf k}\right) + \gamma  \left(  {\bf i} -  {\bf k} \right)  \,\, \Rightarrow \,\, 
\left\{\begin{array}{ l}
  3 \alpha + 3 \beta + \gamma = 1      \\
  2 \alpha - 2 \beta  = 2        \\
   \alpha +  \beta - \gamma = 0          
\end{array} 
\right.
\] 
resolviendo el sistema de ecuaciones anterior tendremos que: ${\bf d} = \frac{5}{8} {\bf a} -\frac{3}{8}  {\bf b} + \frac{1}{4} {\bf c}$. 

Seguidamente, para el vector {\bf e} se tiene: 
 \[
{\bf e}=3{\bf i} - 2{\bf j} = \alpha \left(  3{\bf i} + 2{\bf j} + {\bf k}\right) + \beta \left(  3{\bf i} - 2{\bf j} + {\bf k}\right) + \gamma  \left(  {\bf i} -  {\bf k} \right)  \,\, \Rightarrow \,\, 
\left\{\begin{array}{ l}
  3 \alpha + 3 \beta + \gamma = 3      \\
  2 \alpha - 2 \beta  = -2        \\
   \alpha +  \beta - \gamma = 0          
\end{array} 
\right.
\] 
resolviendo el nuevo sistema de ecuaciones resulta que: ${\bf e} = -\frac{1}{8} {\bf a} +\frac{7}{8}  {\bf b} + \frac{3}{4}   {\bf c} $.

Ahora bien, 
\[
{\bf f}= {\bf a} \times {\bf b}= \left(  3{\bf i} + 2{\bf j} + {\bf k}\right) \times  \left(  3{\bf i} - 2{\bf j} + {\bf k}\right)= \left|\begin{array}{ccc}{\bf i} & {\bf j} & {\bf k}\\3 & 2 & 1 \\3 & -2 & 1\end{array}\right| =
 4{\bf i}  -12{\bf k}\,,
\]
con lo cual para el vector {\bf f} resulta:
 \[
{\bf f}=4{\bf i}  -12{\bf k}= \alpha \left(  3{\bf i} + 2{\bf j} + {\bf k}\right) + \beta \left(  3{\bf i} - 2{\bf j} + {\bf k}\right) + \gamma  \left(  {\bf i} -  {\bf k} \right)  \,\, \Rightarrow \,\, 
\left\{\begin{array}{ l}
  3 \alpha + 3 \beta + \gamma = 4      \\
  2 \alpha - 2 \beta  = 0        \\
   \alpha +  \beta - \gamma = -12          
\end{array} 
\right.
\]
y finalmente, al resolver el sistema anterior,  ${\bf f}=  {\bf a} \times {\bf b} = -{\bf a} - {\bf b} +10   {\bf c}$\,.


\item  Consideremos los siguientes tres vectores: ${\bf w}_{1}={\bf i} +3 {{\bf k}}\,,  {\bf w}_{2}
=2{\bf i}-3{\bf j}$ y ${\bf w}_{3}=-{\bf j}+ {\bf k}$ ¿Formarán una base para $\mathds{R}^{3}$? 

Veamos entonces si son linealmente independientes:
\[\alpha {\bf w}_{1} + \beta{\bf w}_{2} +\gamma {\bf w}_{3} = 0 \,\, \Rightarrow \,\, \alpha=\beta=\gamma= 0 \,,
\]
La comprobación es directa al resolver el siguiente sistema de ecuaciones:
\[
\left.
\begin{array}{cccc}
\alpha & +2 \beta &  & =0 \\ 
& -3 \beta & - \gamma & =0 \\
3 \alpha &  & +\gamma & =0 
\end{array}\right.
\]
cuya solución es $\alpha=\beta=\gamma= 0$. Por lo tanto, forman una base para $\mathds{R} ^{3}$.

Como forman base, podemos expresar otro vector, digamos: ${\bf a}={\bf i} -3{\bf j}+3{\bf k}$, en término de la base $\left\{ {\bf w}_{1}, {\bf w}_{2}, {\bf w}_{3}\right\} $, esto es:
\[
{\bf a} = \alpha {\bf w}_{1} + \beta {\bf w}_{2} +\gamma {\bf w}_{3} \,\, \Rightarrow \,\, 
\left\{
\begin{array}{cccc}
\alpha & +2 \beta &  & =1 \\
 & -3 \beta & - \gamma & =-3 \\
 3 \alpha &  & +\gamma & =3
\end{array}\right\} \,\, \Rightarrow \,\,\left\{ 
\begin{array}{c}\alpha = \frac{1}{3} \\ \\ \beta = \frac{1}{3} \\ \\ \gamma = 2 \end{array} \right.
\]
es decir:
\[
{\bf a} = \frac{1}{3} {\bf w}_{1} + \frac{1}{3} {\bf w}_{2} +2 {\bf w}_{3}\,.
\]
\end{enumerate}

\newpage
\subsection{{\color{red}Practicando con Maxima}} 

El programa de manipulación simbólica {\bf Maxima} está diseñado para realizar una gran cantidad de cálculos algebraicos y numéricos que iremos descubriendo a medida que desarrollemos los diferentes temas de este curso. Es indispensable ir al apéndice \ref{IntroMaxima} para familiarizarnos con la sintaxis básica del programa. 

{\bf Maxima} es una potente calculadora y maneja números de diferentes tipos: enteros, racionales, irracionales, complejos y números con decimales (punto flotante). 

Haremos algunos cálculos sencillos para ir calentando. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
log(20);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o1) }
\log(20)
\end{math}
\newline

Es probable que necesitemos el valor numérico de $\log(20)$.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
log(20),numer;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
2.995732273553991
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
420/16000;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
\frac{21}{800}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
420/16000,numer;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
0.02625
\end{math}
\newline

Podemos utilizar la función {\bf float} para el mismo resultado

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
float(log(20)); float(420/16000);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
2.995732273553991
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
0.02625
\end{math}
\newline

El programa contiene una gran cantidad de funciones matemáticas básicas internas y entre ellas las trigonométricas:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
sin(%pi/3);cos(%pi/3);tan(%pi/3);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
\frac{\sqrt{3}}{2}
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
\frac{1}{2}
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o9) }
\sqrt{3}
\end{math}
\newline 

Ahora recurriremos a una de las facilidades que nos ofrece el programa para agrupar objetos matemáticos: las listas. Las listas se escriben entre corchetes y los objetos de la lista separados con comas. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
[sin(%pi/3),cos(%pi/3),tan(%pi/3)];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10) }
\left[ \frac{\sqrt{3}}{2} , \frac{1}{2} , \sqrt{3} \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
[sin(%pi/3),cos(%pi/3),tan(%pi/3)],numer;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
\left[ 0.8660254037844386 , 0.5000000000000001 , 1.732050807568877  \right] 
\end{math}
\newline

Cuando necesitemos generar una lista por medio de alguna regla específica o formula usamos la función {\bf makelist}. La sintaxis es la siguiente:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i12) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
makelist(exp(t*x),t,1,10);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o12) }
\left[ e^{x} , e^{2\,x} , e^{3\,x} , e^{4\,x} , e^{5\,x} , e^{6\,x}
  , e^{7\,x} , e^{8\,x} , e^{9\,x} , e^{10\,x} \right] 
\end{math}
\newline

Podemos también aplicar una función a cada elemento de la lista, en este caso a cada elemento le aplicaremos la función $\ln(x)$. Para tal fin utilizaremos el comando {\bf map}.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i13) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
map(log,(makelist(exp(t*x),t,1,10)));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
\left[ x , 2\,x , 3\,x , 4\,x , 5\,x , 6\,x , 7\,x , 8\,x , 9\,x , 
 10\,x \right] 
\end{math}
\newline

Si queremos, por ejemplo, sumar todos los elementos de la lista anterior utilizamos la función {\bf apply} con la operación que queremos realizar. Aquí aprovecharemos para utilizar un atajo muy práctico que consiste en el uso del símbolo $\%$, que toma la última salida del programa para ser usado en la instrucción siguiente, de esta manera nos evitamos volver a escribir toda la instrucción anterior. La sintaxis para todo esto es:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i14) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
apply("+",%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o14) }
55\,x
\end{math}
\newline

Podemos asignarle a una lista el nombre de una variable.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i15) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
L:[sin(%pi/3),log(3),sqrt(2),abs(x),exp(x^2)];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o15) }
\left[ \frac{\sqrt{3}}{2} , \log(3) , \sqrt{2} , \left| x\right|  , 
 e^{x^2} \right] 
\end{math}
\newline

De manera que para aislar  elementos de una lista escribimos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i16) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
L[1]; L[4];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o16) }
\frac{\sqrt{3}}{2}
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o17) }
\left| x\right| 
\end{math}
\newline

Esto nos permite operar con sus elementos.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i18) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
L[2]*(L[1]+ L[4])/L[5];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o18) }
\log(3)\,e^ {- x^2 }\,\left(\left| x\right| +\frac{\sqrt{3}}{2} \right)
\end{math}
\newline

La primera utilidad que le podemos dar a las listas es que nos permite definir vectores. Si queremos que el programa interprete los vectores
\[
{\bf a}=(a^1,a^2,a^3)\,,\,\, {\bf b}=(b^1,b^2,b^3)\,,\,\,  {\bf c}=(c^1,c^2,c^3)\,,\,\,  {\bf v0}=(0,0,0)\,, 
\]
los podemos escribir como listas:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i19) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:[a1,a2,a3]; b:[b1,b2,b3];c:[c1,c2,c3]; v0:[0,0,0];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o19) }
\left[ { a_1} , { a_2} , { a_3} \right] 
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o20) }
\left[ { b_1} , { b_2} , { b_3} \right] 
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o21) }
\left[ { c_1} , { c_2} , { c_3} \right] 
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o22) }
\left[ 0 , 0 , 0 \right]
\end{math}
\newline

Como vimos, las operaciones básicas sobre los vectores cumplen un conjunto de propiedades:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i23) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a+b=b+a;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o23) }
\left[ { b_1}+{ a_1} , { b_2}+{ a_2} , { b_3}+ { a_3} \right] =\left[ { b_1}+{ a_1} , { b_2}+{ a_2}  , { b_3}+{ a_3} \right]
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i24) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
(a+b)+c=a+(b+c);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o24) }
\left[ { c_1}+{ b_1}+{ a_1} , { c_2}+{ b_2}+ { a_2} , { c_3}+{ b_3}+{ a_3} \right] =\left[ { c_1}+ { b_1}+{ a_1} , { c_2}+{ b_2}+{ a_2} , { c_3}+
 { b_3}+{ a_3} \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i25) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a+v0=a;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o25) }
\left[ { a_1} , { a_2} , { a_3} \right] = \left[ { a_1} , { a_2} , { a_3} \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i26) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a-a=v0;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o26) }
\left[ 0 , 0 , 0 \right] =\left[ 0 , 0 , 0 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i27) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
alpha*(a+b)=alpha*a+alpha*b,factor;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o27) }
\left[ \alpha\,\left({ b_1}+{ a_1}\right) , \alpha\,\left(
 { b_2}+{ a_2}\right) , \alpha\,\left({ b_3}+{ a_3}\right) \right] =\left[ \alpha\,\left({ b_1}+{ a_1}\right) ,  \alpha\,\left({ b_2}+{a_2}\right) , \alpha\,\left({ b_3}+ { a_3}\right) \right]
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i28) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
(alpha+beta)*a=alpha*a+beta*a,factor;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o28) }
\left[ { a_1}\,\left(\beta+\alpha\right) , { a_2}\,\left( \beta+\alpha\right) , { a_3}\,\left(\beta+\alpha\right) \right] = \left[ { a_1}\,\left(\beta+\alpha\right) , { a_2}\,\left(\beta +\alpha\right) , { a_3}\,\left(\beta+\alpha\right) \right]
\end{math}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}
\begin{enumerate}
\item Dado el triángulo: $ A=(2, 3)$,  $B=(6, 9)$, $C=(8, 1)$.  Utilizando álgebra vectorial encuentre: 
\begin{enumerate}
\item el baricentro, es decir, el punto donde se interceptan las medianas del triángulo. 
\item el circuncentro, es decir, el punto donde se interceptan las mediatrices del triángulo. 
\end{enumerate}

\item Utilice métodos vectoriales para probar que las líneas que unen los puntos medios con las aristas opuestas (bimedianas) de un tetraedro $OABC$ se interceptan en un punto, y que ese punto divide en dos partes cada una de las líneas. 

\item Los vertices de un triángulo $ABC$ tienen como vectores posición $\mathbf{a}$, $\mathbf{b}$ y $\mathbf{c}$, respectivamente y relativos a un origen común $O$. Demuestre que el vector posición $\mathbf{g}$ del centróide $G$ del triángulo viene dado por:
\[
\mathbf{g}=\frac13(\mathbf{a}+\mathbf{b}+\mathbf{c})\,.
\]

\item Un paralelogramo tiene un ángulo agudo de $\pi/3$ y lados de longitud $a=1$ y $b=2$. Si pensamos que esos lados como vectores 
$\mathbf{a}$ y $\mathbf{b}$ encuentre:
\begin{enumerate}
\item Los vectores: $\mathbf{a} +\mathbf{b}$ y $\mathbf{a} -\mathbf{b}$.
\item Los vectores: $2\mathbf{a} +3\mathbf{b}$ y $5\mathbf{a} -7\mathbf{b}$.
\end{enumerate}

\item Con la definición de posición de centro de masa del ejemplo \ref{EjemploVectores}, encuentre el centro de masas para los siguientes sistemas:
\begin{enumerate}
\item Masas iguales a: $1, 2, 3, 4$ en los vértices de un cuadrado de lados $a=2$.
\item Masas iguales a: $1, 2, 3, 4$ en los vértices inferiores de un cubo cuyos lados son de longitud $a=2$ y masas iguales a: $5, 6, 7, 8$ en la vértices superiores.
\end{enumerate}

\item ¿Los siguientes vectores son linealmente independientes?  
\[
{\bf a}=(0,2,-1),\; {\bf b}=(0,1/2,-1/2), \;{\bf c}=(0,-2/3,-1/3)\,.
\]

\item Las componentes de un vector y la regla para sumar vectores se combinan para introducir la forma más simple de representar un vector como una combinación lineal de los vectores más elementales que podemos tener. Estos vectores  forman lo que conocemos la base canónica: $\{{\bf i},{\bf j},{\bf k}\}$, vectores de longitud unitaria que apuntan en la dirección positiva de los ejes $x$, $y$ y  $z$. 

Compruebe, entonces,  si los siguientes vectores forman una base: 
\begin{enumerate}
\item 
$
{\bf e}_1= 2{\bf i}+{\bf j}-3{\bf k}\,,\quad
{\bf e}_2=  {\bf i}-4{\bf k}\,,\quad
{\bf e}_3= 4{\bf i}+3{\bf j}-{\bf k}
$
\item 
$
{\bf e}_1= {\bf i}-3{\bf j}+2{\bf k}\,,\quad
{\bf e}_2=  2{\bf i}-4{\bf j}-{\bf k}\,,\quad
{\bf e}_3= 3{\bf i}+2{\bf j}-{\bf k}
$
\end{enumerate}

\item Un paralelogramo tiene un ángulo agudo de $\pi/4$ y lados 
$a=1, b=2$. Si consideramos que los lados son vectores, encuentre:
\begin{enumerate}
\item El área del paralelogramo. 
\item La proyección de cada lado sobre la dirección del otro.
\end{enumerate}
\item Considere un triángulo cuyos lados están conformados por los vectores ${\bf a}$, ${\bf b}$ y ${\bf c}={\bf a}+{\bf b}$. Con el producto vectorial entre ellos demuestre la ley del seno:
\[
\frac{a}{\sin(\alpha)}=\frac{b}{\sin(\beta)}=\frac{c}{\sin(\gamma)}\,.
\]
donde $\alpha, \beta, \gamma$ son los ángulos opuestos a los lados $a, b, c$ respectivamente.

\item Demuestre que el volumen de un tetraedro formado a partir de tres vectores ${\bf a}, {\bf b}$ y ${\bf c}$ que coinciden en un mismo origen, puede representarse de la manera siguiente:
\[
V=\frac{1}{6}\left|{\bf a}\cdot ({\bf b}\times{\bf c})\right|\,.
\]
\end{enumerate}


\section{Vectores en componentes}
\label{VectoresComponentes}
\index{Componentes de Vectores}
\index{Sistemas de coordenadas}
\index{Coordenadas ! Sistemas de}
\index{Cosenos Directores}

La formulación de las leyes físicas debe hacerse en término de cantidades vectoriales (tensoriales). Esto independiza su formulación de un sistema particular de coordenadas, pero llegado el momento de calcular valores y utilizar estas leyes, es mucho más conveniente referirla a un sistema de coordenadas particularmente adaptado a la geometría del problema. En ese caso, la ecuación vectorial se convertirá en tantas ecuaciones como componentes (referidas al sistema de coordenadas utilizado) tengan los vectores en ese sistema de coordenadas.

\subsection{Bases y componentes}
\label{BasesCoodenadas3D}
\index{Vectores 3D!Componentes}
\index{Componentes vectores 3D}
Tal y como mencionamos anteriormente, tres vectores \textbf{no coplanares} cualesquiera son linealmente independientes y constituyen una base para el espacio tridimensional. Denominaremos  a estos vectores base como $\left\{  {\bf w}_{i} \right\} $,  y por ser linealmente independientes podremos expresar
cualquier vector ${\bf a}$ como una combinación lineal única, tal y como lo mostramos en el cuadrante I de la
figura \ref{fig4vectcartes}.

\begin{figure}[t]
\begin{center}\includegraphics[height=3.0in,width=5.0in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_4.jpg}
\caption{Vectores, bases y componentes}
\label{fig4vectcartes}
\end{center}
\end{figure}

Con los vectores base $\left\{{\bf w}_{1}, {\bf w}_{2}, {\bf w}_{3}\right\}  $ podemos construir un sistema (oblicuo en general) de coordenadas al colocarlos con un mismo origen, esto es:
\[
\mathbf{a}=a^{1} {\bf w}_{1}+ a^{2}{\bf w}_{2}+a^{3} {\bf w}_{3}\,,
\]
donde las cantidades $\left\{  a^{1}, a ^{2}, a^{3}\right\} $ son números (no son escalares) que representan las componentes del vector ${\bf a}$ a lo largo de cada uno de los vectores base $\left\{  {\bf w}_{1}, {\bf w}_{2}, {\bf w}_{3}\right\}$. Nótese que por costumbre (la cual será evidente más adelante, en la sección \ref{EspacioVectorialDual}) etiquetamos estos números con superíndices y la letra que identifica al vector.

Más aún, cada punto $P$ del espacio viene definido por un radio vector ${\bf r} \left(P\right)  \equiv\overrightarrow{OP}$ que une el origen de coordenadas con el punto $P$ y se le asocian tres
números $\left\{  {x}^{1}, {x}^{2}, {x}^{3}\right\}$, los cuales son las proyecciones a lo
largo de cada uno de los ejes coordenados $\left\{\overline{0 {x}^{1}}, \overline{0 {x}^{2}},\overline{0{x}^{3}}\right\} $.  Los números $\left\{ {x}^{1}, {x}^{2},  {x}^{3}\right\} $ se denominarán
componentes de ${\bf r} \left(  P\right)  $ en el sistema de referencia 
$\left\{ {\bf w}_{1},{\bf w}_{2},{\bf w}_{3}\right\} $.

Existe una familia de sistemas de coordenadas en la cual sus vectores base son ortogonales (o mejor
ortonormales), es decir los vectores base $\left\{ {\bf e}_{1},{\bf e}_{2},{\bf e}_{3}\right\}  $ son perpendiculares entre si. Tal y como mostraremos más adelante, siempre se puede construir un sistema ortogonal $\left\{  {\bf e}_{1},{\bf e}_{2},{\bf e}_{3} \right\} $ u ortonormal  
$\left\{ {\bf i}_{1}, {\bf i}_{2}, {\bf i}_{3} \right\} $ a partir de una base genérica de vectores
linealmente independientes $\left\{  {\bf w}_{1},{\bf w}_{2},{\bf w}_{3}\right\}$.  Cuando el sistema sea
ortogonal sus componentes se denominarán rectangulares. Dependiendo del signo del triple producto mixto, el sistema de coordenadas será dextrógiro ($\left(  {\bf e}_{1}\times{\bf e}_{2}\right)  \cdot{\bf e}
_{3}>0$) o levógiro ($\left(  {\bf e}_{1}\times{\bf e}_{2}\right) \cdot{\bf e}_{3}<0$), tal y como se muestra en el cuadrante III de la figura \ref{fig4vectcartes}.

Es costumbre ancestral\footnote{Quizá por las arraigadas relaciones de dominación de los derechos sobre los izquierdos  (en latín e italiano los zurdos son siniestros), o quizá tal vez por conservar la definición de volumen como positivo.} utilizar la convención dextrógira donde el producto: 
$\left( {\bf e}_{1}\times{\bf e}_{2}\right) \cdot{\bf e}_{3}>0$,  y en ese caso utilizamos el bien conocido conjunto de vectores unitarios $\left\{  \mathbf{i}, \mathbf{j}, \mathbf{k} \right\}$ 
con los que ya hemos estado familiarizados: 
\[
{\bf a}=a_{x} \mathbf{i}+a_{y}\mathbf{j}+a_{z} \mathbf{k} 
\quad \text{y} \quad \mathbf{r} \left(  P\right)  =x\ \mathbf{i} +y\ \mathbf{j} +z\ \mathbf{k} \,.
\]

También es costumbre representar  este sistema de coordenadas ortonormal
como: $\mathbf{i}  \equiv \mathbf{i}_{1},  \mathbf{j}  \equiv \mathbf{i}_{2}$ y $\mathbf{k} \equiv \mathbf{i}_{3}$  para recordar que estamos en un sistema de coordenadas cartesianas y utilizaremos los superíndices $1,2,3$ para indicar las componentes del vector.
\[
{\bf a}=a^{1} \mathbf{i}_1 +a^{2}\mathbf{i}_2 +a^{3} \mathbf{i}_3 
\quad \text{y} \quad \mathbf{r} \left(  P\right)  =x^1\ \mathbf{i}_1 +x^2\ \mathbf{i}_2 +x^3\ \mathbf{i}_3 \,.
\]

Obviamente el módulo del vector se podrá expresar con la utilización del teorema de Pitágoras:
\[
\left|  {\bf a} \right|  = \sqrt{(a^{1})^{2} +(a^{2})^{2}+(a^{3})^{2}} \quad
\text{y}\quad  \left| \mathbf{r} \left(P\right)  \right| =\sqrt{(x^{1})^2+(x^{2})^2+(x^{3})^2}\,,
\]
y la multiplicación por un número será:
\[
\alpha  {\bf a}=\alpha\left(  a^{1} \mathbf{i}_1 + a^{2} \mathbf{i}_2 +a^{3}\mathbf{i}_3\right)  =
\left(  \alpha a^1\right)\mathbf{i}_1+ \left(  \alpha a^2\right) \mathbf{i}_2+\left(  \alpha a^3\right)  
\mathbf{i}_3 \,\, \Rightarrow \,\, \left| \alpha  {\bf a} \right|  =
\alpha\sqrt{(a^{1})^2+(a^{2})^2+(a^{3})^2} \,.
\]
Igualmente para un vector unitario:
\[
\hat{\bf u}_a =\dfrac{{\bf a}}{\left|  {\bf a}\right|  }=
\frac{a^1 \mathbf{i}_1 +a^2 \mathbf{i}_2 +a^3 \mathbf{i}_3}{\sqrt{(a^{1})^2 +(a^{2})^2 +(a^{3})^2 } }\,,
\]
con lo cual todo vector:
\[
{\bf a}=\left|  {\bf a}\right|  \hat{\bf u}_a = \sqrt{(a^{1})^2 +(a^{2})^2 +(a^{3})^2} \ \hat{\bf u}_a \,.
\]

\subsection{Cosenos directores}
\label{CosenosDirectores}
\index{Cosenos directores}
Como se puede apreciar en el cuadrante IV de la figura \ref{fig4vectcartes}, podemos construir tres triángulos rectángulos con el radio vector ${\bf a}\left(P\right)$ como hipotenusa de cada uno de ellos. Los ángulos que forma el radio vector ${\bf a}\left(P\right)$ con cada uno de los ejes coordenados $\left\{ x,y,z\right\}$ son $\left\{  \alpha ,\beta,\gamma\right\}$, respectivamente, con lo cual:
\begin{equation}
a_{x}=\left|  {\bf a}\right|  \cos(\alpha)\,,\quad a_{y}=\left|  {\bf a}\right| \cos(\beta) \quad \text{y} \quad 
a_{z}=\left|  {\bf a}\right|  \cos(\gamma) \quad  \Rightarrow \quad  \cos^{2}(\alpha)+\cos^{2}(\beta)+\cos^{2}(\gamma)=1 \,,
\label{cosdirectores}
\end{equation}
pero además:
\[
\hat{\bf u}_a = \frac{{\bf a}}{\left|  {\bf a}\right|}=
\cos(\alpha)\ \mathbf{i}+\cos(\beta)\ \mathbf{j}+\cos(\gamma)\ \mathbf{k}\,.
\]


\subsection{Una división fallida}
Uno esperaría que para cada una de las definiciones de productos vectoriales, existiera el vector cociente, es decir, que pudiéramos ``despejar'' uno de los vectores multiplicados en términos del otro. La situación es que esta operación no está definida unívocamente y lo podemos intuir a partir de una de la definición del producto escalar.
Supongamos que tenemos que:  $\zeta=\mathbf{a}\cdot \mathbf{b}$, con lo cual, si pudiéramos ``despejar'', digamos, $\mathbf{b}={\zeta}/ {\mathbf{a}}$ ¿Tendríamos entonces definido $\mathbf{b}$ de una manera unívoca? La respuesta es NO,  ya que $\zeta =\mathbf{a}\cdot\left( \dfrac{\zeta}{\mathbf{a}}+\mathbf{d} \right)$, donde $\mathbf{a}\ \bot\ \mathbf{d}$, por lo cual existen infinitos $\mathbf{b}=\dfrac{\zeta} {\mathbf{a}}+\mathbf{d}$ que cumplen $\zeta=\mathbf{a}\cdot\mathbf{b}$.


\subsection{Algebra vectorial en componentes}
\label{Algebravectorialycoordenadas}
\index{Algebra vectorial y coordenadas}

Es posible reescribir toda el álgebra vectorial que hemos visto  mediante operaciones referidas a sistemas de coordenadas, como mostraremos a continuación. Por simplicidad, anclaremos nuestro sistema de coordenadas a la base canónica $\{\mathbf{i}_i\}$.

\index{Vectores 3D!Suma/resta}
Para los vectores ${\bf a}=\left(a^{1}\mathbf{i}_{1}+a^{2}\mathbf{i}_{2}+a^{3}\mathbf{i}_{3}\right)$ y ${\bf b}=\left(  b^{1} \mathbf{i}_{1}+b^{2}\mathbf{i}_{2}+b^{3}\mathbf{i}_{3}\right)$, la suma será representada por:
\[
{\bf a}+{\bf b}=\left(  a^{1}\mathbf{i}_{1}+a^{2}\mathbf{i}_{2}+a^{3}\mathbf{i}_{3}\right)  +\left(  b^{1} \mathbf{i}_{1}+b^{2}\mathbf{i}_{2}+b^{3}\mathbf{i}_{3}\right)  =
\left(  a^{1}+b^{1}\right)  \mathbf{i}_{1}+\left(  a^{2}+b^{2}\right)  \mathbf{i}_{2}+\left(  a^{3}+b^{3}\right)  \mathbf{i}_{3} \,,
\]
y obviamente, la resta:
\[
{\bf a}-{\bf b}=
\left(  a^{1}\mathbf{i}_{1}+a^{2}\mathbf{i}_{2}+a^{3}\mathbf{i}_{3}\right)  -\left(  b^{1}\mathbf{i}_{1}+
b^{2}\mathbf{i}_{2}+b^{3}\mathbf{i}_{3}\right)  =
\left(  a^{1}-b^{1}\right)  \mathbf{i}_{1}+\left(  a^{2}-b^{2}\right)  \mathbf{i}_{2}+\left(  a^{3}-b^{3}\right)  \mathbf{i}_{3} \,,
\]
con lo cual la distancia entre dos puntos $P$ y $M$ será:
\[
d\left(  P,M\right)  =\left|  \left( \mathbf{r} \left(P\right)  ={\bf a}\right)  -\left(  \mathbf{r} \left(M\right)  =
{\bf b}\right)  \right|  =\sqrt{\left( x^1-y^1\right)^{2}+\left(  x^2-y^2\right)  ^{2}+\left(  x^3-y^3 \right)  ^{2}} \,.
\]

\subsection{Dependencia e independencia lineal}
\label{IndependenciaVector3D2}
\index{Dependencia lineal!Vectores 3D}
\index{Independencia lineal!Vectores 3D}
\index{Vectores 3D!Dependencia lineal}
\index{Vectores 3D!Independencia lineal}
Ahora es fácil estudiar la dependencia o independencia lineal en
coordenadas. Otra vez, tres vectores: 
${\bf a}=a^1 \mathbf{i}_1+ a^2\mathbf{i}_2+a^3\mathbf{i}_3 \,,
{\bf b}= b^1\mathbf{i}_1+  b^2\mathbf{i}_2+ b^3\mathbf{i}_3$ y ${\bf c}=
 c^1 \mathbf{i}_1+ c^2\mathbf{i}_2+ c^3\mathbf{i}_3$,  serán \textit{linealmente
independientes} si se cumple que:
\[
\alpha \ {\bf a}+\beta \ {\bf b}+\gamma \ {\bf c}= \mathbf{0} \,\, \Rightarrow \,\, \alpha=\beta=\gamma=0\,.
\]

Veamos qué sucede para la base canónica: $  \mathbf{i}_{1}=\mathbf{i}  \equiv \left(1,0,0\right), \mathbf{i}_{2}=\mathbf{j}  \equiv\left( 0,1,0\right),  \mathbf{i}_{3}=\mathbf{k} \equiv\left( 0,0,1\right)$. Estos vectores son claramente linealmente independientes y por lo tanto constituyen una base.


En general tendremos que:
\begin{align*}
\mathbf{0} &  =\alpha \left( a^1\mathbf{i}_1+a^2\mathbf{i}_2 +a^3 \mathbf{i}_3\right)  +
\beta \left( b^1\mathbf{i}_1+ b^2\mathbf{i}_2+ b^3\mathbf{i}_3 \right)  +
\gamma\left( c^1\mathbf{i}_1+ c^2\mathbf{i}_2+ c^3\mathbf{i}_3  \right)   
& \\
&  =
\left(  \alpha a^1+\beta  b^1+\gamma  c^1\right)  \mathbf{i}_1+
\left(  \alpha a^2+\beta  b^2+\gamma  c^2\right)  \mathbf{i}_2+
\left(  \alpha a^3+\beta  b^3+\gamma  c^3\right)  \mathbf{i}_3
\, \, \Rightarrow \, \, \left\{
\begin{array}
[c]{c}
\alpha a^1+\beta  b^1+\gamma  c^1=0\\
\alpha a^2+\beta  b^2+\gamma  c^2=0\\
\alpha a^3+\beta  b^3+\gamma  c^3=0
\end{array}
\right.
\end{align*}

Esto no es otra cosa que un sistema de 3 ecuaciones lineales con 3 incógnitas: $\left\{ \alpha,\beta,\gamma\right\} $, y la solución que estamos buscando $\alpha=\beta=\gamma=0$ se cumplirá si:
\[
\left|
\begin{array}
[c]{ccc}
a^1 &  b^1 &  c^1\\
a^2 &  b^2 &  c^2\\
a^3 &  b^3 &  c^3
\end{array}
\right|  =
a^1 \left(  b^2 c^3- b^3 c^2\right) +
a^2 \left(  b^3 c^1- b^1 c^3\right) +
a^3 \left(  b^1 c^2- b^2 c^1\right)    \neq 0 \,.
\]

\subsection{Productos de vectores en componentes}
\subsubsection{Producto escalar}
\label{ProductoEscalar2}
\index{Producto escalar}
\index{Escalar!Producto}
\index{Vectores 3D!Producto escalar}
Ahora refrasearemos, en término de una base de vectores ortogonales, lo expresado en la sección \ref{ProductoEscalar1}.  Representaremos el producto escalar de dos vectores en una base cartesiana $\left\{ \mathbf{i}_1, \mathbf{i}_2,  \mathbf{i}_3 \right\}$, que es una base ortonormal, de la siguiente manera:
\[
{\bf a} \cdot{\bf b}=\left( a^1\mathbf{i}_1+a^2 \mathbf{i}_2+a^3\mathbf{i}_3 \right)  
\cdot\left(   b^1\mathbf{i}_1+ b^2\mathbf{i}_2+ b^3\mathbf{i}_3 \right)  =
a^1 b^1+a^2  b^2+a^3  b^3 \,,
\]
ya que por ser ortogonales se tiene que:
\[
\mathbf{i}_1  \cdot \mathbf{i}_1= \mathbf{i}_2 \cdot \mathbf{i}_2= \mathbf{i}_3 \cdot \mathbf{i}_3= 1 \,,
\quad \text{y} \quad
\left\{
\begin{array}
[c]{c}
\mathbf{i}_1 \cdot \mathbf{i}_2=\mathbf{i}_2 \cdot \mathbf{i}_1=0\\
\mathbf{i}_1 \cdot \mathbf{i}_3=\mathbf{i}_3 \cdot \mathbf{i}_1=0\\
\mathbf{i}_2 \cdot \mathbf{i}_3=\mathbf{i}_3 \cdot \mathbf{i}_2=0
\end{array}
\right. 
\]

Las propiedades del producto escalar en coordenadas cartesianas se comprueban fácilmente.
\begin{itemize}
\item \textit{El producto escalar de un vector consigo mismo, siempre es positivo}. 
\[
\zeta={\bf a}\cdot{\bf a}=\left|  {\bf a}\right|  ^{2}= (a^1)^{2}+(a^2)^{2}+(a^3)^{2}\geq0 \,,
\]
y 
\[
(a^1)^{2}+(a^2)^{2}+(a^3)^{2}=0   \,\,  \Rightarrow \,\,  
a^1=a^2=a^3=0\quad\Leftrightarrow\quad{\bf a}={\bf 0}\,.
\]
Adicionalmente: $|{\bf a}| =\sqrt{\zeta}=\sqrt{{\bf a}\cdot{\bf a}}=\sqrt{(a^1)^{2}+(a^2)^{2}+(a^3)^{2}}$.

\item \textit{El producto escalar es conmutativo}.
\[
\zeta={\bf a}\cdot{\bf b}={\bf b}\cdot{\bf a}=a^1 b^1+a^2 b^2+a^3 b^3= b^1a^1+ b^2a^2+ b^3a^3\,.
\]
\item \textit{El producto escalar es distributivo}.
\[
{\bf a}\cdot\left(  {\bf b}+{\bf c}\right) = \left[ a^1\mathbf{i}_1+a^2\mathbf{i}_2 + a^3 \mathbf{i}_3\right]  \cdot   \left[  \left(  b^1+ c^1\right) \mathbf{i}_1+\left(   b^2+ c^2\right)  \mathbf{i}_2+\left(  b^3+ c^3\right)  \mathbf{i}_2\right] \,,
\]
por lo tanto:
\begin{eqnarray*}
a^1\left(  b^1+ c^1\right)  +a^2\left(   b^2+ c^2\right)  +a^3\left( b^3+ c^3\right) &=&
\left( a^1 b^1+a^1 c^1\right)  +\left(  a^2 b^2+a^2 c^2\right)+\left(  a^3 b^3+a^3 c^3\right)  \\
= \left( a^1 b^1+a^2 b^2+a^3 b^3\right)  +\left( a^1 c^1+a^2 c^2+a^3 c^3\right) &=& {\bf a}\cdot{\bf b}+{\bf a} \cdot{\bf c} \,.
\end{eqnarray*}

\item \textit{La multiplicación por un escalar}.
\[
\left|  \alpha\right|  \left(  {\bf a} \cdot {\bf b}\right)  =
\left(  \alpha{\bf a}\right)  \cdot{\bf b}={\bf a}\cdot\left(\alpha{\bf b}\right)  =
\left(  \alpha a^1\right)   b^1+\left(  \alpha a^2 \right)   b^2+\left(  \alpha a^3\right)   b^3=
a^1 \left(  \alpha b^1\right)  +a^2\left(  \alpha  b^2\right)  +a^3\left(  \alpha b^3\right)\,.
\]

\item \textit{Desigualdad de Cauchy-Schwarz}.
\[
 {\bf a}\cdot{\bf b} =a^1 b^1+a^2 b^2+a^3 b^3\leq
\sqrt{(a^1)^{2} + (a^2)^{2}+ (a^3)^{2} }
\sqrt{(b^1)^{2} + (b^2)^{2}+ (b^3)^{2}}= \left|  {\bf a}\right|  \left|  {\bf b}\right|  \,.
\]

\item \textit{Diremos que dos vectores, no nulos son ortogonales (perpendiculares) si su producto escalar es nulo}. Esta afirmación es inmediata:
\[
{\bf a}\ \bot\ {\bf b}\quad \Rightarrow \quad  \theta_{\left\langle {\bf a},{\bf b}\right\rangle }=
\frac{\pi}{2}\quad  \Rightarrow \quad  {\bf a}\cdot{\bf b}=
\left| {\bf a}\right|  \left|  {\bf b}\right|  \cos(\theta)_{\left\langle {\bf a}, {\bf b}\right\rangle }=0 \,, 
\]
por lo cual:
\[
a^1b^1+a^2 b^2+a^3 b^3=\left|  {\bf a}\right|  \left|  {\bf b} \right|  \cos(\theta)_{\left\langle {\bf a}, {\bf b}\right\rangle} \,\,  \Rightarrow \,\,  \cos(\theta)_{ \left\langle {\bf a}, {\bf b}\right\rangle }=\frac{a^1 b^1+a^2 b^2+a^3 b^3} {\sqrt{(a^1)^{2} + (a^2)^{2}+ (a^3)^{2} }   \sqrt{ (b^1)^{2}+ (b^2)^{2}+ (b^3)^{2}}}\,,
\]
de donde se deduce que para dos vectores perpendiculares:
\[
{\bf a}\bot{\bf b}\,\,   \Rightarrow \,\,   0=a^1 b^1+a^2 b^2+a^3 b^3 \,.
\]

\item \textit{Del producto escalar surge el teorema del coseno}.  

Es inmediato generalizar el producto escalar de un vector consigo mismo, para ello suponemos que $\bf{c}=\bf{a}+\bf{b}$, con lo cual:
\[
{\bf c}= {\bf a}+ {\bf b} \,\,  \Rightarrow \,\,  {\bf c} \cdot {\bf c}=\left(  {\bf a}+{\bf b} \right)  \cdot\left(  {\bf a}+{\bf b} \right)  \,\,  \Rightarrow \,\,   \left|  {\bf c} \right|  ^{2}=\left|  {\bf a}\right| ^{2}+\left|  {\bf b}\right|^{2}+ 2\left|  {\bf a} \right|  \left|  {\bf b}\right|  \cos(\theta)_{\left\langle{\bf a},{\bf b}\right\rangle } \,,
\]
que no es otra cosa que el teorema del coseno y está ilustrado en el cuadrante III de la figura \ref{fig3vectcartes}.
\end{itemize}


\subsubsection{Producto vectorial}
\label{ProductoVectorial}
\index{Producto vectorial}
\index{Vectorial!Producto}
\index{Vectores 3D!Producto vectorial}
De igual manera, lo que aprendimos en la sección \ref{ProductorVectorial1} ahora lo expresamos en términos de las componentes de los vectores en una base ortonormal de la forma:
\[
\label{produtovectorial1}
{\bf c}={\bf a}\times{\bf b}=\left( a^2 b^3-a^3 b^2\right)
\mathbf{i}_1+\left(  a^3 b^1-a^1 b^3\right)  
\mathbf{i}_2+\left( a^1 b^2-a^2 b^1\right)  \mathbf{i}_3\,,
\]
lo anterior se puede organizar como el determinante de la matriz:
\[
\label{produtovectorial2}
{\bf c}={\bf a}\times{\bf b}=\left|
\begin{array}
[c]{ccc}
\mathbf{i}_1 & \mathbf{i}_2 & \mathbf{i}_3\\
a^1 & a^2 & a^3\\
 b^1 &  b^2 &  b^3
\end{array}
\right| \,,
\]
con lo cual:
\begin{eqnarray*}
\left|  {\bf c}\right|  &=&\sqrt{\left( a^2 b^3-a^3 b^2\right) ^{2}+
\left(  a^3 b^1-a^1 b^3\right) ^{2}+\left( a^1 b^2-a^2 b^1\right)  ^{2}}\\
&=&  \sqrt{(a^1)^{2} + (a^2)^{2}+ (a^3)^{2}} \
 \sqrt{ (b^1)^{2}+ (b^2)^{2}+ (b^3)^{2}}  \operatorname*{sen}
(\theta)_{\left\langle {\bf a}, {\bf b}\right\rangle} \,.
\end{eqnarray*}

\subsubsection{Triple producto mixto}
\index{Triple producto vectorial}
\index{Producto vectorial mixto}
\index{Vectores 3D!Producto vectorial mixto}
Finalmente, analicemos el número (pseudoescalar) que proviene de la multiplicación:
\[
V={\bf c}\cdot\left(  {\bf a}\times{\bf b}\right)  =
\left |  {\bf c}\right | \left |  {\bf a}\times{\bf b}  \right |  \cos(\theta)
_{\left\langle {\bf c},{\bf a}\times{\bf b}\right\rangle }=\left|
\begin{array}
[c]{ccc}
 c^1 &  c^2 &  c^3\\
a^1 & a^2 & a^3\\
 b^1 &  b^2 &  b^3
\end{array}
\right| \,.
\]
Obviamente, este número representa del volumen del paralelepípedo cuyos lados quedan definidos por los vectores: ${\bf a},{\bf b}$ y ${\bf c}$.

\subsection{{\color{Fuchsia}Ejemplos}}
\label{EjemplosBase}
\begin{enumerate}
\item Si tenemos los vectores ${\bf a}={\bf i}+3{\bf j}+5{\bf k}$ y ${\bf b}=2{\bf i}+4{\bf j}+6{\bf k}$
 podemos ver que el ángulo que forman es fácil de calcular:
\[
\cos(\theta)=\frac{{\bf a}\cdot{\bf b}}{|{\bf a}||{\bf b}|} =
\frac{\left[{\bf i}+3{\bf j}+5{\bf k}\right] \cdot
\left[2{\bf i}+4{\bf j}+6{\bf k}\right]}
{ \sqrt{1^2+3^2+5^2} \sqrt{2^2+4^2+6^2}}=
\frac{2+12+30}{\sqrt{35} \sqrt{56}}=
\frac{44}{\sqrt{35} \sqrt{56}}=\frac{22}{\sqrt{14} \sqrt{35}} \,.
\]
Por lo tanto, $\theta=\arccos\left(\frac{22}{\sqrt{14} \sqrt{35}}\right)=0.11088$. 

Notemos que de la ecuación (\ref{cosdirectores}) para los vectores ${\bf a}$ y ${\bf b}$ y su componentes resulta que: 
\[
\cos(\alpha)=\frac{a_x}{|{\bf a}|}=\frac{1}{\sqrt{35}}\,, \,\, 
\cos(\beta)=\frac{a_y}{|{\bf a}|}=\frac{3}{\sqrt{35}} \,, \,\, 
\cos(\gamma)=\frac{a_z}{|{\bf a}|}=\frac{5}{\sqrt{35}}
\,\, \Rightarrow \,\, \left[\frac{1}{\sqrt{35}}\right]^2+
\left[\frac{3}{\sqrt{35}}\right]^2+\left[\frac{5}{\sqrt{35}}\right]^2=1 \,,
\]
\[
\cos(\alpha)=\frac{b_x}{|{\bf b}|}=\frac{2}{\sqrt{56}}\,, \,\, 
\cos(\beta)=\frac{b_y}{|{\bf b}|}=\frac{4}{\sqrt{56}} \,, \,\, 
\cos(\gamma)=\frac{b_z}{|{\bf b}|}=\frac{6}{\sqrt{56}}
\,\, \Rightarrow \,\, \left[\frac{2}{\sqrt{56}}\right]^2+
\left[\frac{4}{\sqrt{56}}\right]^2+\left[\frac{6}{\sqrt{56}}\right]^2=1 \,.
\]
Y además podemos ver claramente que el ángulo entre los vectores y los cosenos directores están relacionados, como se muestra a continuación:
\[
\cos(\theta)= 
\frac{1}{\sqrt{35}}\frac{2}{\sqrt{56}}+
\frac{3}{\sqrt{35}}\frac{4}{\sqrt{56}}+
\frac{5}{\sqrt{35}}\frac{6}{\sqrt{56}}=
\frac{22}{\sqrt{14} \sqrt{35}}\,.
\]

\item Consideremos los vectores: $
{\bf e}_{1}=\mathbf{i} \equiv \left(1,0,0\right), \  
{\bf e}_{2}=\mathbf{i}+\mathbf{j} \equiv\left(1,1,0\right), \
{\bf e}_{3}=\mathbf{i}+\mathbf{j}+\mathbf{k} \equiv\left(1,1,1\right)$.   
Al escribir el sistema de ecuaciones resulta: 
\[
\alpha=0 \,,\quad  \alpha + \beta=0\,, \quad \alpha + \beta +\gamma =0 
\,\,  \Rightarrow \,\, \alpha=0\,,\quad \beta=0 \,,\quad  \gamma=0 \,,
\]
con lo cual demostramos que son linealmente independientes y por lo tanto constituyen una base para los vectores tridimensionales.

 \item Dados los vectores: ${\bf a}={\bf i}+2{\bf j}+3{\bf k}$, ${\bf b}=4{\bf i}+5{\bf j}$  y ${\bf c}=3{\bf i}+2{\bf j}+{\bf k}$. 
 
Podemos ver que $\alpha {\bf a}+\beta {\bf b}+\gamma {\bf c}={\bf 0}$ implica que:
\[
\alpha \left[{\bf i}+2{\bf j}+3{\bf k}\right]+
\beta \left[4{\bf i}+5{\bf j}\right]+
\gamma \left[3{\bf i}+2{\bf j}+{\bf k}\right]={\bf 0}
\,\, \Rightarrow \,\,
\left\{
\begin{array}
[c]{r}
\alpha+4\beta +3\gamma =0\\
2\alpha + 5 \beta  +2\gamma =0\\
3\alpha +\gamma=0
\end{array}
\right.
\]
Cuya solución es: $\alpha=\beta=\gamma=0$. Por lo tanto el conjunto $\{ {\bf a},{\bf b},{\bf c}\}$ es linealmente independiente.

Por otro lado, si queremos calcular el volumen recurrimos al triple producto vectorial:
\[
V={\bf a}\cdot\left[{\bf b}\times{\bf c}\right]=
 \left[{\bf i}+2{\bf j}+3{\bf k}\right] \cdot 
 \left[4{\bf i}+5{\bf j}\right] \times  \left[3{\bf i}+2{\bf j}+{\bf k}\right]= \left[{\bf i}+2{\bf j}+3{\bf k}\right] \cdot  
 \left[5{\bf i}-4{\bf j}-7{\bf k}\right]= -24 \,.
\]

Si tenemos un vector arbitrario, digamos, ${\bf d}=d_1{\bf i}+d_2{\bf j}+d_3{\bf k}$ y construimos las siguientes cantidades:
\[
c_1=-\frac{{\bf a}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
c_2 =-\frac{{\bf b}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
c_3= -\frac{{\bf c}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})}\,.
\]
resulta:
\[
c_1=\frac{d_1+2d_2+3d_3}{24} \,,\quad
c_2=\frac{4d_1+5d_2}{24}\,,\quad
c_3=\frac{3d_1+2d_2+d_3}{24}\,,
\]
y podemos ver que: $c_1 ({\bf b} \times{\bf c} )+ c_2({\bf c} \times{\bf a} ) + c_3 ({\bf a} \times{\bf b} ) + {\bf d}$, es igual a:
\begin{eqnarray*}
\frac{d_1+2d_2+3d_3}{24} (5{\bf i}-4{\bf j}-7{\bf k} )&+& 
\frac{4d_1+5d_2}{24} (4{\bf i}-8{\bf j}+4{\bf k}  ) +
\frac{3d_1+2d_2+d_3}{24} (-15{\bf i}+12{\bf j}-3{\bf k} ) \\
&+& d_1{\bf i}+d_2{\bf j}+d_3{\bf k} = {\bf 0}\,.
\end{eqnarray*}

Es decir,
\[
c_1 ({\bf b} \times{\bf c} )+ c_2({\bf c} \times{\bf a} ) + c_3 ({\bf a} \times{\bf b} ) + {\bf d}={\bf 0}\,,
\]
siempre y cuando el conjunto $\{ {\bf a},{\bf b},{\bf c}\}$ sea linealmente independiente y ${\bf d}$ un vector arbitrario. 

\end{enumerate}

\newpage
\subsection{{\color{red}Practicando con Maxima}} 
\index{Vectores con Maxima}
\index{Maxima!Vectores con}
Con el programa de manipulación simbólica {\bf Maxima} haremos algunos cálculos sencillos con vectores. Nuevamente recomendamos ver el apéndice  \ref{IntroMaxima} como introducción al programa.

Dados los vectores, en coordenadas cartesianas: ${\bf a}={\bf i}+2{\bf j}+3{\bf k}$ y ${\bf b}=7{\bf i}+8{\bf j}+9{\bf k}$.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:[1,2,3];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o1) }
\left[ 1 , 2 , 3 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
b:[7,8,9];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
\left[ 7 , 8 , 9 \right] 
\end{math}
\newline

La multiplicación por escalares y suma es simple, si queremos calcular 
$\alpha\, {\bf a} + \beta \, {\bf b}$, escribimos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
alpha*a + beta*b;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
\left[ 7\,\beta+\alpha , 8\,\beta+2\,\alpha , 9\,\beta+3\,\alpha
  \right] 
\end{math}
\newline 

Para el producto escalar procedemos utilizando el operador punto,  como se muestra a continuación.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a.b;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
50
\end{math}
\newline 

El cálculo de producto vectorial no es tan obvio, debemos cargar previamente la librería {\bf vect}. 
%%%%%%%%%
\index{Maxima!\texttt{vect}}
\index{\texttt{vect}}
%%%%%%%%%

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
load(vect)$
\end{verbatim}}
\end{minipage}
\newline

El operador para el producto vectorial es una tilde  y además debemos utilizar la función {\bf express}. Entonces, para calcular ${\bf a} \times {\bf b}$, ejecutamos los siguientes comandos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
express(a~b);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
\left[ -6 , 12 , -6 \right] 
\end{math}
\newline

La norma de un vector, como ya vimos, es:  $\sqrt{{\bf a} \cdot {\bf a}}$

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
sqrt(a.a);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
\sqrt{14}
\end{math}
\newline

Si tenemos otro vector, digamos ${\bf c}=-4{\bf i}+5{\bf j}-6{\bf k}$, el producto triple: ${\bf a}\cdot{\bf b}\times{\bf c}$ se calcula así:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
c:[-4,5,-6];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
\left[ -4 , 5 , -6 \right]
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i9) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a.express(b~c);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o9) }
120
\end{math}
\newline

El ángulo entre los vectores ${\bf a}$ y ${\bf b}$, es:
\[
\theta=\arccos\left(\frac{{\bf a}\cdot {\bf b}}{|{\bf a}| |{\bf b}|}\right)\,.
\]
En {\bf Maxima} usamos la función {\bf acos(x)}   para el  $\mbox{arcocoseno}(x)$.  Consultar el manual del programa para ver el resto de las funciones trigonométricas. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
acos((a.b)/(sqrt(a.a)*sqrt(b.b)));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10)}
\mbox{acos} \left(\frac{50}{\sqrt{14}\,\sqrt{194}}\right)
\end{math}
\newline

Seguramente lo queremos es el valor numérico, esto se hace agregando  la función {\bf float}.  Con la siguiente sintaxis logramos el objetivo:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
acos((a.b)/(sqrt(a.a)*sqrt(b.b))),float;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
0.2858867976945064
\end{math}
\newline

Para finalizar, podemos considerar el problema de la independencia lineal de vectores. Tomemos el conjunto de vectores del ejemplo \ref{EjemplosBase}, es decir, los vectores: ${\bf a}={\bf i}+2{\bf j}+3{\bf k}$, ${\bf b}=4{\bf i}+5{\bf j}$ y ${\bf c}=3{\bf i}+2{\bf j}+{\bf k}$. El sistema de ecuaciones a resolver era:
\[
\left\{
\begin{array}
[c]{r}
\alpha+4\beta +3\gamma =0\\
2\alpha + 5 \beta  +2\gamma =0\\
3\alpha +\gamma=0
\end{array}
\right.
\]

Disponemos de un comando que permite resolver sistemas de ecuaciones lineales, este comando se llama {\bf linsolve}.  Podemos escribir el sistema de ecuaciones como una lista y luego resolver: 
 %%%%%%%%%
\index{Maxima!\texttt{linsolve}}
%%%%%%%%%

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i12)  \end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ecus:[alpha+4*beta+3*gamma=0,2*alpha+5*beta+2*gamma=0,3*alpha+gamma=0];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o12) }
\left[ 3\,\gamma+4\,\beta+\alpha=0 , 2\,\gamma+5\,\beta+2\,\alpha=0 , \gamma+3\,\alpha=0 \right]
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i13)  \end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
linsolve(ecus,[alpha,beta,gamma]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
\left[ \alpha=0 , \beta=0 , \gamma=0 \right]
\end{math}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}

\begin{enumerate}
\item Con la definición del producto escalar entre vectores, demuestre que si $\theta$ es el ángulo entre los vectores ${\bf a}$ y ${\bf b}$, entonces:
\[
\cos(\theta)=\frac{a_1b_1}{ab}+\frac{a_2b_2}{ab}+\frac{a_3b_3}{ab}\,.
\]
Donde las cantidades $a_i/a$ y $b_i/b$ son los cosenos directores de  ${\bf a}$ y ${\bf b}$ respectivamente. 

\item Encuentre la distancia del punto $P$ al origen, si $P$ viene dado por el vector posición: $\mathbf{r}= 2\mathbf{i}+4\mathbf{j}-3\mathbf{k}$. Y si para un punto arbitrario el vector posición es: $\mathbf{r}= x\mathbf{i}+y\mathbf{j}+z\mathbf{k}$ ¿Qué superficie describe éste vector cuando $|\mathbf{r}|=3$? 

\item Encuentre los cosenos directores y los correspondientes  ángulos para los siguientes vectores:
\begin{enumerate}
\item ${\bf a}={\bf i}+{\bf j}+{\bf k}$.
\item ${\bf b}={\bf i}-2{\bf j}+2{\bf k}$.
\item ${\bf c}=4{\bf i}-2{\bf j}+3{\bf k}$.
\end{enumerate}

\item Sea $\{ {\bf i}_1, {\bf i}_2, {\bf i}_3\}$ una base ortonormal  dextrógira. Verifique que los vectores:
\[
{\bf a}= {\bf i}+2{\bf j}+3{\bf k} \,,\quad   {\bf b}= {\bf i}+5{\bf j} \,,\quad 
{\bf c}= 3{\bf i}+2{\bf j}+{\bf k} \,.
\]
forman una base ¿Esta base será del tipo dextrógiro o levógiro?

\item Sea $\{ {\bf i}_1, {\bf i}_2, {\bf i}_3\}$ una base ortonormal ¿Son los siguientes conjuntos de vectores una base? 
\begin{enumerate}
\item $
{\bf a}_1= 2{\bf i}+{\bf j}-3{\bf k} \,,\quad   
{\bf a}_2= {\bf i}-4{\bf k} \,,\quad 
{\bf a}_3= 4{\bf i}+3{\bf j}-{\bf k}$.
\item $
{\bf b}_1= {\bf i}-3{\bf j}+2{\bf k} \,,\quad   
{\bf b}_2= 2{\bf i}-4{\bf j}-{\bf k} \,,\quad 
{\bf b}_3= 3{\bf i}+2{\bf j}-{\bf k}$.
\end{enumerate}


\item Dados los vectores: 
\[
{\bf a}= {\bf i}_1+2{\bf i}_2+3{\bf i}_3\,, \quad
{\bf b}= 4{\bf i}_1+5{\bf i}_2+6{\bf i}_3\,, \quad
{\bf c}= 3{\bf i}_1+2{\bf i}_2+ {\bf i}_3\,, \quad
{\bf d}= 6{\bf i}_1+5{\bf i}_2+4{\bf i}_3 \,.
\]
\begin{enumerate}
\item Encuentre: 
\[
{\bf a} +{\bf b} + {\bf c} + {\bf d} \,,\quad 
{\bf a} +{\bf b} - {\bf c} - {\bf d} \,,\quad
\mathbf{a} -\mathbf{b} + \mathbf{c} - \mathbf{d} \,,\quad
-\mathbf{a} +\mathbf{b} - \mathbf{c} + \mathbf{d} \,.
\]
\item El ángulo entre los vectores $\mathbf{a}, \mathbf{b}, \mathbf{c}, \mathbf{d}$ y  los vectores base ${\bf i}_1, {\bf i}_2, {\bf i}_3$.
\item La magnitud de los vectores  $\mathbf{a}, \mathbf{b}, \mathbf{c}, \mathbf{d}$.
\item El ángulo entre $\mathbf{a}$ y $\mathbf{b}$ y entre $\mathbf{c}$ y $\mathbf{d}$.
\item La proyección  de $\mathbf{a}$ sobre $\mathbf{b}$.
\item ¿Son los vectores $\mathbf{a}, \mathbf{b}, \mathbf{c}, \mathbf{d}$  coplanares?
\item Encuentre $(\mathbf{a}+\mathbf{b})\cdot (\mathbf{c}+\mathbf{d})$.
\item Los productos  $\mathbf{a} \times \mathbf{b}$,  $\mathbf{b} \times \mathbf{c}$,
 $\mathbf{c} \times \mathbf{d}$ y los ángulos que estos forman con $\mathbf{d}$.
\item $\mathbf{c}\cdot (\mathbf{a} \times \mathbf{b})$.
\end{enumerate}

\item Verifique la desigualdad triangular: $|{\bf a}+{\bf b}|\leq |{\bf a}|+|{\bf b}|$, para los siguientes vectores:
\begin{enumerate}
\item ${\bf a}={\bf i}+2{\bf j}+3{\bf k} $ y $ {\bf b}=2{\bf i}+{\bf j}+7{\bf k}$.
\item ${\bf a}=2{\bf i}-{\bf j}-2{\bf k} $ y $ {\bf b}=3{\bf i}+2{\bf j}+3{\bf k}$.
\end{enumerate}

\item Si ${\bf a}$ y ${\bf b}$ son vectores arbitrarios y $\alpha$ y $\beta$ números, demuestre que:
\[
|\alpha {\bf a}+\beta{\bf b}|^2 \leq \alpha^2| {\bf a}|^2+2\alpha\beta
({\bf a}\cdot{\bf b})+\beta^2|{\bf b}|^2\,.
\]
\item Si ${\bf a}, {\bf b}, {\bf c}$ y ${\bf d}$ son vectores arbitrarios y $\alpha, \beta, \gamma$ escalares que satisfacen:
\[
\alpha ({\bf b} \times{\bf c} )+ \beta ({\bf c} \times{\bf a} ) +
\gamma ({\bf a} \times{\bf b} ) + {\bf d} ={\bf 0}\,,
\]
demuestre que si ${\bf a}, {\bf b}$ y ${\bf c}$ son linealmente independientes, entonces: 
\[
\alpha=-\frac{{\bf a}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
\beta =-\frac{{\bf b}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
\gamma= -\frac{{\bf c}\cdot{\bf d}}{{\bf a}\cdot({\bf b} \times{\bf c})}\,.
\]
\item Si ${\bf a}, {\bf b}, {\bf c}$ y ${\bf d}$ son vectores arbitrarios y $\alpha, \beta, \gamma$ escalares que satisfacen:
\[
\alpha {\bf a}+ \beta {\bf b}+\gamma {\bf c} + {\bf d} ={\bf 0}\,,
\]
demuestre que si ${\bf a}, {\bf b}$ y ${\bf c}$ son linealmente independientes, entonces: 
\[
\alpha=-\frac{{\bf d}\cdot({\bf b} \times{\bf c})}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
\beta =-\frac{{\bf d}\cdot({\bf c} \times{\bf a})}{{\bf a}\cdot({\bf b} \times{\bf c})} \,,\quad
\gamma= -\frac{{\bf d}\cdot({\bf a} \times{\bf b})}{{\bf a}\cdot({\bf b} \times{\bf c})}\,.
\]
Ayuda: tome el producto escalar de la ecuación con ${\bf b} \times{\bf c}$, ${\bf a} \times{\bf c}$ y ${\bf a} \times{\bf b}$.

\item Demuestre que los vectores ${\bf a}={\bf i}+2{\bf j}+{\bf k}$, ${\bf b}=2{\bf i}-{\bf j}-{\bf k}$ y ${\bf c}=4{\bf i}+3{\bf j}+{\bf k}$ son linealmente independientes. Escoja un vector ${\bf d}$ y verifique los resultados de los dos últimos ejercicios. 

\item Utilizando {\bf Maxima} realice todos los ejercicios anteriores y compare los resultados.


\end{enumerate}

\section{Aplicaciones del álgebra vectorial}
\label{AplicacionesAlgebraVectorial}
\index{Aplicaciones!Álgebra vectorial} 
\index{Álgebra vectorial!Aplicaciones} 

Uno de los terrenos más exitosos de las aplicaciones del álgebra vectorial es la geometría analítica. Esto se realiza en base a la definición que hiciéramos del radio vector, en la cual a cada punto, 
$P$, del espacio le asociábamos un radio vector posición tal y como lo mostramos en el cuadrante I de la figura \ref{fig4vectcartes}.
\[
P\longleftrightarrow(x,y,z)  \equiv\left(  x^{1},x^{2}
,x^{3}\right)  \,\,  \Rightarrow \,\,  {\bf r}\left(  P\right)  =
x\ \mathbf{i}+y\ \mathbf{j}+z\ \mathbf{{k}}=
x^{1}\mathbf{i}_{1}+x^{2}\mathbf{i}_{2}+
x^{3}\mathbf{i}_{3}=\sum_{i=1}^3 x^{i}\mathbf{i}_{i}\,.
\]
A partir de esta definición todas las propiedades geométricas del
espacio las podemos construir con vectores.


\subsection{Rectas y vectores}
\label{RectasVectores}
\index{Rectas y vectores}
\index{Vectores 3D!Rectas}
La ecuación de la recta en término de vectores la definiremos fijando uno de sus puntos, digamos: 
\[
{\bf r}\left( P_{1}\right)  \equiv {\bf x} \left(  P_{1}\right)  ={\bf x}_{1}= 
x_1\ \mathbf{{i} }+y_1\ \mathbf{{j} }+z_1\ \mathbf{{k} }=
x_{(1)}^{1} \mathbf{{i} }_{1}+
x_{(1)}^{2} \mathbf{{i} }_{2}+
x_{(1)}^{3} \mathbf{{i} }_{3} \longleftrightarrow \left(x_{1},y_{1},z_{1}\right) \, ,
\]
y un vector que indique su dirección, digamos $\mathbf{a} =a^{1}\mathbf{{i}}+a^{2}\mathbf{{j} } +a^3 \mathbf{{k}}$ (ver cuadrante I de la figura \ref{fig5vectcartes}) con lo cual la ecuación de una recta en lenguaje vectorial será:
\[
{\bf x} ={\bf x} _{1}+\lambda \mathbf{a}  \,\,  \Rightarrow \,\,  x_{1} \mathbf{{i} }+y_{1}\mathbf{{j} }+z_{1} \mathbf{{k} } +\,  \lambda\left(a^{1} \mathbf{{i} }+a^{2} \mathbf{{j} }+a^{3} \mathbf{{k}}\right) \,\,  \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
x=x_{1}+\lambda a^{1}\\ \\
y=y_{1}+\lambda a^{2}\\ \\
z=z_{1}+\lambda a^{3} 
\end{array}
\right. 
\]
donde $\mathbf{x} =x\ \mathbf{{i} }+y\ \mathbf{{j} }+z\ \mathbf{{k} }$ es  el conjunto de puntos genéricos que cumple con la ecuación de la recta en 3D. 

\begin{figure}[t]
\begin{center}
\includegraphics[height=2.5in,width=6.5in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_5.jpg}
\caption{Geometría analítica y vectores cartesianos}
\label{fig5vectcartes}
\end{center}
\end{figure}

Existe una manera más elegante, como veremos en la sección siguiente, de reescribir las ecuaciones anteriores utilizando la notación de índices\footnote{Quitaremos aquí el símbolo de sumatoria, esta convención quedará clara en la siguiente sección, pero mantengamos en mente que tenemos una suma sobre el índice $i$.}.  Las ecuaciones ahora son más evidentes:
\[
{\bf x} ={\bf x} _{1}+\lambda\mathbf{a} \,\,  \Rightarrow \,\,  x^{i}\mathbf{{i} }_{i}=
x_{(1)}^{i}\mathbf{{i} }_{i}+\lambda a^{i}\mathbf{{i} }_{i} \,\,  \Rightarrow \,\,  
x^{i}=x_{(1)}^{i}+\lambda a^{i}\,,\qquad \text{para }\, i=1,2,3 \, .
\]
donde: $\left(x, y, z\right)\equiv \left(x^1,  x^2, x^3\right)$ y 
$\left(\mathbf{i}, \mathbf{j}, \mathbf{k}\right)\equiv \left(\mathbf{i}_1,  \mathbf{i}_2, \mathbf{i}_3\right)$.

Nótese que efectivamente se cumplen tres ecuaciones escalares y cada una de ellas tiene la forma de una recta.
Además, tal y como se muestra la figura \ref{fig5vectcartes} el punto genérico $\left(x,y,z\right) $ lo describe (sobre la recta) la variación del módulo de $\mathbf{a}$ mediante la constante de proporcionalidad $\lambda.$ Si se requiere describir una recta que pase por dos puntos: $\left(x_{1},y_{1},z_{1}\right)$ y $\left(  x_{2},y_{2},z_{2}\right)$ entonces una vez seleccionado uno de los puntos (digamos $\left(  x_{1}, y_{1}, z_{1}\right) $) seleccionamos el vector $\mathbf{a} ={\bf r} \left(P_{2}\right)  - {\bf r}\left(  P_{1}\right)$ como la resta de los dos radio vectores a los puntos $P_{2}$ y $P_{1}$. Esto es:
\[
{\bf x} ={\bf x} _{1}+\lambda\left(  {\bf x} _{2}-{\bf x} _{1}\right) \,.
\]

Al despejar $\lambda$ de la ecuaciones de las rectas resulta:
\[
x^{i}=x_{(1)}^{i}+\lambda a^{i} \,\, \Rightarrow \,\, \lambda=
\frac{x^{i}-x_{(1)}^{i}}{a^{i}} =\frac{x-x_{1}}{a^{1}}=\frac{y-y_{1}}{a^{2}}=\frac{z-z_{1}}{a^{3}}\,,
\]
y de manera  equivalente:
\[
x^{i}=x_{(1)}^{i}+\lambda\left(  x_{(2)}^{i}-x_{(1)}^{i}\right)  
\,\, \Rightarrow \,\, 
\lambda=\frac{x^{i}-x_{(1)}^{i}}{x_{(2)}^{i}-x_{(1)}^{i}}=
\frac{x-x_{1}}{x_{2}-x_{1}}=\frac{y-y_{1}}{y_{2}-y_{1}}=\frac{z-z_{1}}{z_{2}-z_{1}}\,.
\]

\subsection{Planos y vectores}
\label{PlanosVectores}
\index{Planos y vectores}
\index{Vectores 3D!Planos}
Ocurre exactamente lo mismo cuando construimos la ecuación vectorial para un plano. En general una superficie la define su vector normal (perpendicular). En el caso de una superficie plana (un plano) tendrá una única normal
que lo define, por lo tanto, un plano vendrá definido por su vector perpendicular en un punto, digamos $Q=P_{1}: \left( x_{1},y_{1},z_{1}\right)$.  La ecuación vectorial del plano vendrá definida por todos los vectores $\overrightarrow{PQ}$ tales que sean perpendiculares a un determinado vector ${\bf a}$ (ver cuadrante II de la figura \ref{fig5vectcartes}). Donde el punto $P$ es un punto genérico $\left(x,y,z\right)$ que define un radio vector. La ecuación  vectorial del plano será simplemente: 
\[
\mathbf{a} \cdot \overrightarrow{PQ}=
\mathbf{a} \cdot \left[ {\bf r} \left(  P\right)  -\underset{\bf{b}}{\underbrace{{\bf r} \left(  P_{1}\right)  }}\right]  =0
 \quad \Leftrightarrow \quad \mathbf{a} \cdot \left(  {\bf r} -{\bf r} _{1}\right)  =0
 \quad\Leftrightarrow \quad\mathbf{a} \cdot{\bf r} =
 \underset{b}{\underbrace{\mathbf{a} \cdot{\bf r} _{1}}}\,.
\]
Esto es, se tiene que cumplir la condición:
\begin{align*}
\left(  a^{1}\ \mathbf{{i} }+a^{2}\ \mathbf{{j} } +a^{3}\ \mathbf{{k} }\right)  \cdot \left[ \left(  x\ \mathbf{{i} }+y\ \mathbf{{j} }+z\ \mathbf{{k} }\right)  -\left(  x_{1}
\ \mathbf{{i} }+y_{1}\ \mathbf{{j} }+z_{1}\ \mathbf{{k} }\right)  \right]  &  =0\\
\left(  a^{1}\ \mathbf{{i} } +a^{2}\ \mathbf{{j} } +a^{3}\ \mathbf{{k} }\right)  \cdot\left[  \left(  x-x_{1}\right)
\ \mathbf{{i} }+\left(  y-y_{1}\right)  \mathbf{{j} }+\left(z-z_{1}\right)  \mathbf{{k} }\right]   &  =0\\
a^{1}\left(  x-x_{1}\right)  +a^{2}\left(  y-y_{1}\right)  +a^{3}\left( z-z_{1}\right)   &  =0 \,,
\end{align*}
con lo cual, la ecuación del plano queda como siempre la hemos conocido:
\[
a^{1}x+a^{2}y+a^{3}z-a^{1}x_{1}-a^{2}y_{1}-a^{3}z_{1}=0 \,\,  \Rightarrow \,\,
a^{1}x+a^{2}y+a^{3}z=b=a^{1}x_{1}+a^{2}y_{1}+a^{3}z_{1}\,.
\]

Nuevamente, de manera  compacta:
\[
a^{i}x_{i}-a^{j}x_{j(1)}=0\,\,  \Rightarrow \,\,  a_{k}x^{k}=b=a_{l}x_{(1)}^{l}\,.
\]

Es claro que ${\bf a} \cdot{\bf r} _{1}=b$ es la proyección del radio vector ${\bf r} \left(  P_{1}\right)  $ sobre la perpendicular que define al plano. Por lo tanto será la distancia entre el plano y el origen de coordenadas. Si $b=0$ el plano pasa por el origen de coordenadas.

Consideremos ahora el cuadrante III de la figura \ref{fig5vectcartes}. Allí están especificados tres puntos en el espacio caracterizados por sus correspondientes radio vectores posición: ${\bf r} \left(  P_{1}\right)={\bf r} _{1},{\bf r} \left(  P_{2}\right)  ={\bf r} _{2}$ y ${\bf r} \left(P_{3}\right)  ={\bf r} _{3}$. Estos tres puntos serán coplanares si:
\[
\left(  {\bf r} _{1}-{\bf r} _{2}\right)  \cdot\left[  \left(  {\bf r} _{2}-{\bf r} _{3}\right)  \times\left(  {\bf r} _{3}-{\bf r} _{1}\right)  \right] =0\quad \Leftrightarrow \quad 
\varepsilon_{mnl}\left(  x_{1}^{m}-x_{2}^{m}\right)  \left(  x_{2}^{n}-x_{3}^{n}\right)  \left(  x_{3}^{l}-x_{1}
^{l}\right)  =0\,,
\]
y la ecuación vectorial del plano vendrá dada por:
\[
\left(  {\bf r} -{\bf r} _{1}\right)  \cdot\left[ \left(  {\bf r} _{2}-{\bf r}_{1}\right)  
\times\left(  {\bf r} _{3}-{\bf r} _{1}\right)  \right]=0 \,.
\]

\subsection{{\color{Fuchsia}Ejemplos}}
\label{EjemploPlanos}
\begin{enumerate}
\item Un plano viene determinado por los puntos $A=(1,1,1)$, $B=(1,2,3)$ y $C=(0,0,0)$. Para encontrar la ecuación del plano podemos hacer lo siguiente: Encontremos el vector posición de los puntos $A$ y $B$, 
\[
{\bf r}_{AB}={B}-{A}=(0,1,2)\,, \quad {\bf r}_{AC}={C}-{A}=(-1,-1,-1)\,,
\]
un vector normal al plano es: ${\bf n}={\bf r} _{AB}\times {\bf r} _{AC}=(1,-2,1)$.

Para la ecuación del plano, podemos escoger el vector  $\mathbf{a}=(1,1,1)$ por lo que tenemos entonces que:
\[
{\bf n}\cdot{\bf r} = {\bf n}\cdot\mathbf{a} \,\,  \Rightarrow \,\,   
(1,-2,1)\cdot (x,y,z)=(1,-2,1)\cdot (1,1,1) \,\,  \Rightarrow \,\, 
x-2y+z=0\,.
\]


\item  Dados los siguientes puntos en el espacio: $(1,0,3)$, $( 2,-1,0 )$, $( 0,-1,1)$, $(-1,0,1)$.

Consideremos los tres primeros puntos, que podemos considerar coplanares ya que bastan tres puntos para definir un plano. 
Estos tres puntos son los vertices de un triángulo cuya área podemos calcular de la siguiente manera:

Primero seleccionamos uno de los puntos como un vértice privilegiado (digamos $( 2,-1,0 )$) respecto al cual construiremos dos vectores que representan dos de los lados del triángulo. Esto es:
\[
{\bf a} = (1,0,3) - ( 2,-1,0 ) \leftrightarrow {\bf a} = - {\bf i} +{\bf j} +3 {{\bf k}}\,,\quad
{\bf b} = (0,-1,1) - ( 2,-1,0 )  \leftrightarrow {\bf b} = -2{\bf i}   +{{\bf k}}\,,
\]
con lo cual, el área del triángulo será la mitad del área del paralelogramo que tiene por lados estos dos vectores. Es decir:
\[
A = \frac{1}{2} | {\bf a} \times {\bf b} | \,\,  \Rightarrow \,\,  {\bf a} \times {\bf b} = \left|\begin{array}{ccc}{\bf i} & {\bf j} & {{\bf k}} \\-1 & 1 & 3 \\-2 & 0 & 1\end{array}\right| = {\bf i} -5 {\bf j} +2{{\bf k}} \,\,  \Rightarrow \,\, A = \frac{1}{2}| {\bf i} -5 {\bf j} +2{{\bf k}}|=\frac{\sqrt{30}}{2}\,.
\]

Por otro lado, la ecuación del plano que generan estos tres puntos se calcula con la siguiente ecuación:
\[
\left(  {\bf r}-{\bf r}_{1}\right)  \cdot \left(  \left(  {\bf r}_{2}-{\bf r}_{1}\right)  \times\left(  {\bf r}_{3}-{\bf r}_{1}\right)  \right) =0\,,
\]
donde:
\[
{\bf r} = x {\bf i} + y{\bf j} + z {{\bf k}}, \quad {\bf r}_{1} =  {\bf i}  + 3 {{\bf k}}, \quad {\bf r}_{2} = 2 {\bf i} -{\bf j}, \quad {\bf r}_{3} =  -{\bf j} + {{\bf k}},
\]
con lo cual la ecuación del plano queda como:
\[
\left|\begin{array}{ccc}(x -1) & y  & (z - 3) \\1 & -1 & -3 \\-1 & -1 & -2\end{array}\right|=0  \,\, \Rightarrow \,\,
 -(x -1) + 5y -2(z -3) = 0 \,\, \Rightarrow \,\, x -5y +2z = 7\,.
\]

Podemos verificar si el cuarto punto, $(-1,0,1)$, se encuentra en el plano, es decir, debemos verificar que cumple la ecuación que lo define. 
\[
x -5y +2z = 7 \,\, \Rightarrow \,\,(-1) -5(0) +2(1) \neq 7\,,
\]
por lo tanto, los cuatro puntos no son coplanares. Podemos entonces  calcular la distancia del cuarto punto al plano construyendo un vector unitario normal al plano.
\[
\hat{\bf n}_{P} = \frac{{\bf a} \times {\bf b} }{| {\bf a} \times {\bf b}|} =\frac{1}{\sqrt{30}} \left(  {\bf i} -5 {\bf j} +2{\bf k} \right) \,,
\]
con lo cual la distancia al cuarto punto será:
\[
d =  \hat{\bf n}_{P}  \cdot {\bf c} = \frac{1}{\sqrt{30}} \left(  {\bf i} -5 {\bf j} +2{\bf k} \right) \cdot \left( -3 {\bf i}  +{\bf j} + {\bf k}\right) = -\frac{6}{\sqrt{30}}\,.
\]
\end{enumerate}

\newpage
\subsection{{\color{red}Practicando con Maxima}} 

Consideremos el plano determinado por los puntos $P=(1, 1, 1)$, $Q=(2, 4, 6)$ y $R=(2, 2, 2)$. Para construir la ecuación del plano primero ingresamos los vectores posición de cada punto. 
También incorporaremos las librerías {\bf vect} y {\bf draw} que necesitaremos.
%%%%%%%%%%%%%%
\index{Maxima!\texttt{draw}}
\index{\texttt{draw}}
%%%%%%%%%%%%%%

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
load(vect)$ load(draw)$
\end{verbatim}}
\end{minipage}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
P:[1,1,1];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
\left[ 1 , 1 , 1 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Q:[2,4,6];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
\left[ 2 , 4 , 6 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
R:[2,2,2];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
\left[ 2 , 2 , 2 \right] 
\end{math}
\newline

Podemos verificar que los vectores estén en el mismo plano simplemente calculando el triple producto vectorial: ${\bf P}\cdot({\bf Q}\times{\bf R})$ entre ellos. Sabemos que si es nulo es porque los vectores son coplanares. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
P.express(Q~R);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
0
\end{math}
\newline

Necesitamos ahora calcular  los vectores que van del punto $P$ al punto  $Q$ y del punto $P$ al punto $R$, es decir, los vectores: ${\bf PQ}={\bf Q}-{\bf P}$ y ${\bf PR}={\bf R}-{\bf P}$

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
PQ:Q-P;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
\left[ 1 , 3 , 5 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
PR:R-P;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
\left[ 1 , 1 , 1 \right] 
\end{math}
\newline

Un vector normal al plano será sencillamente el vector ${\bf N}={\bf PQ}\times {\bf PR}$:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
N:express(PQ~PR);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
\left[ -2 , 4 , -2 \right] 
\end{math}
\newline

Podemos escoger cualquiera de los vectores originales, en este caso  al vector ${\bf P}$, para escribir la ecuación del plano: ${\bf N}\cdot {\bf r}={\bf N}\cdot {\bf P}$.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i9) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
r:[x,y,z]; 
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o9) }
\left[ x , y , z \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
plano:N.r=N.P;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10) }
-2\,z+4\,y-2\,x=0
\end{math}
\newline

Probemos a graficar el plano. Para saber mas sobre las diferentes opciones que incorpora {\bf Maxima} para hacer gráficas, en dos o tres dimensiones,  es recomendable consultar el manual de usuario.

Utilizaremos el comando {\bf wxdraw3d} para hacer que la figura aparezca embebida dentro de nuestra hoja de trabajo. Es recomendable consultar también las funciones {\bf draw} y {\bf gr3d}.
%%%%%%%%%%%%%%
\index{Maxima!\texttt{wxdraw3d}}
\index{\texttt{wxdraw3d}}
\index{Maxima!\texttt{gr3d}}
\index{\texttt{gr3d}}
\index{Maxima!\texttt{draw}}
\index{\texttt{draw}}
%%%%%%%%%%%%%%


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
wxdraw3d(implicit(plano,x,-1,1,y,-1,1,z,-1,1));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
\end{math}
\begin{figure}[h]\nonumber
\begin{center}
\includegraphics[height=2.6in,width=4.5in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_5aMax}
\end{center}
\end{figure}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}
\label{EjerciciosAplicacionVectores}

\begin{enumerate}
\item Para las rectas dadas a continuación: 
\begin{enumerate}
\item $L: \quad  \frac{3x-1}{4}= \frac{2y+3}{2}= {2-3z}$.
\item $L: \quad  \frac{2x+1}{3}= \frac{3y+2}{3}= -2+4z$.
\end{enumerate}
Encuentre los vectores posición para dos puntos diferentes sobre la recta y un vector unitario paralelo a la recta $L$.


\item Dada una linea recta $L_1$ que pasa a través de los puntos $(-2,3,1)$ y $(1,4,6)$ encuentre:
\begin{enumerate}
\item El vector posición de un punto sobre la recta y un vector paralelo a ésta.
\item Una recta $L_2$ paralela a $L_1$ y que pase por el punto $(1,2,1)$.
\end{enumerate}

\item Una linea recta tiene como ecuación vectorial: 
${\bf r}= {\bf a}+\lambda {\bf b}$, donde: ${\bf a}=3{\bf j}+2{\bf k}$ y ${\bf b}=2{\bf i}+ {\bf j}+2{\bf k}$. 

Encuentre la ecuación cartesiana de la recta y las coordenadas de tres puntos sobre la recta.

\item Una linea recta pasa por el punto  $(3,2,-3)$ y paralela al vector ${\bf a}=2{\bf i}+3{\bf j}-3{\bf k}$. Encuentre la ecuación cartesiana de la recta y las coordenadas de tres puntos sobre la recta.

\item Dado un plano que pasa por el punto $(2,3,-5)$ y con vector normal ${\bf a}=2{\bf i}+{\bf k}$, encuentre la forma cartesiana de la ecuación del plano.

\item Encuentre la ecuación del plano con normal ${\bf a}$ y que contiene el punto $P$ cuando:
\begin{enumerate}
\item ${\bf a}=2{\bf i}-3{\bf j}+{\bf k}$, $P=(1,0,1)$.
\item ${\bf a}={\bf i}-2{\bf j}+2{\bf k}$, $P=(2,-3,4)$.
\end{enumerate}


 \begin{figure}[t]
\begin{center}
\includegraphics[width=4.5in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_6.jpg}
\caption{Las 5 redes de Bravais bidimensionales fundamentales:  1 Oblicuas, 2 rectangular, 3 rectangular centrada (rómbica), 4 hexagonal, y 5 cuadrada. Figura tomada de \url{http://en.wikipedia.org/wiki/Bravais_lattice}.}
\label{fig6Capt1}
\end{center}
\end{figure}  

\item El ángulo entre dos planos se define como el ángulo entre sus normales. Encuentre el ángulo entre los siguientes planos:
\begin{enumerate}
\item $x+3y+2z= 4$ y  $2x-5y+z=2$.
\item $3x+2y-2z=4$ y  $2x+y+2z=1$.
\end{enumerate}

\item Demuestre que la ecuación de una esfera puede expresarse como: 
\[
|{\bf r}-{\bf c}|^2 = ({\bf r}-{\bf c}) \cdot ({\bf r}-{\bf c})= a^2\,,
\]
donde ${\bf c}$ es el vector posición del centro de la esfera y $a$ el radio.


\item Auguste Bravais\footnote{\url{http://en.wikipedia.org/wiki/Auguste_Bravais}} se dio cuenta que replicando un arreglo geométrico muy simple, se puede describir una estructura cristalina. Dicho de otro modo, que conociendo una celda simple, podemos conocer la estructura cristalina. Esto es, que las posiciones de los átomos en una red cristalina puede ser descrita por un vector: 
\[
{\bf R} = \mathbf{a} + \mathbf{b} + \mathbf{c} = n^{1}{\bf a}_{1} + n^{2}{\bf a}_{2} +n^{3}{\bf a}_{3} = n^{i}{\bf a}_{i} \,,
\] 
donde los ${\bf a}_{i}$ son vectores no coplanares (vectores primitivos o, simplemente en nuestro lenguaje, vectores base). Los $ n^{i}$ son números enteros (negativos, cero o positivos). La posición de cada átomo de un cristal puede ser descrita como reescalamientos (discretos) de este vector genérico o, de manera más precisa, la traslación del origen de coordenadas por un vector.  

Ese concepto se conoce como redes de Bravais\footnote{\url{http://en.wikipedia.org/wiki/Bravais_lattice}}. En cada red puede haber varios vectores primitivos\footnote{\url{http://www.engr.sjsu.edu/rkwok/Phys175A/Chapter\%201.pdf}}. Se puede definir la \textit{celda primitiva} como la estructura mínima que replicada reproduce todo el cristal. Vale decir, la estructura cristalina es invariante bajo traslaciones espaciales del tipo:
\[
{\bf{R}'} = {\bf R} + {\bf T}  \,, \quad \mbox{con } \,\, {\bf T} = m^{i}{\bf a}_{i} \,.
\]

\begin{figure}[t]
\begin{center}
\includegraphics[height=1.8in,width=2.0in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_7a.jpg}
\includegraphics[height=1.8in,width=2.0in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_7b.jpg}
\includegraphics[height=1.8in,width=2.0in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_7c.jpg}
\caption{A la izquierda red cristalina bidimensional. Al centro cuatro detalles geométricos: mural egipcio, mural asirio, tejido tahití e ilustración en pieza de porcelana china (Tomado de: \url{http://en.wikipedia.org/wiki/Wallpaper_group}).  A la derecha, teselados de M.C. Escher, tomados de: \url{http://www.wikipaintings.org/en/paintings-by-genre/tessellation?firstArtist=m-c-escher\#artist-m-c-escher}.}
\label{fig7Capt1}
\end{center}
\end{figure} 

\begin{enumerate}
\item \textbf{Redes de Bravais bidimensionales}.  Tal y como muestra la figura \ref{fig6Capt1} existen 5 tipos distintos de redes de Bravais bidimensionales.

\begin{enumerate}
\item Dada la red bidimensional de la figura \ref{fig7Capt1} (Izquierda) encuentre todos los posibles vectores primitivos y celdas primitivas asociadas.

 \item La humanidad ha estado seducida por la geometría desde que empezó a representar figuras. A partir de las cuatro imágenes que se ilustran en la figura \ref{fig7Capt1} (Centro), encuentre todos los posibles vectores  y celdas primitivas asociadas.

\item Maurits Cornelis Escher\footnote{\url{http://en.wikipedia.org/wiki/M._C._Escher}} fue un fenomenal dibujante holandés, quien se interesó por las simetrías de los grupos de imágenes de papel tapiz. Berend, hermano de Maurits, era cristalógrafo y le mostró la belleza de las simetrías de la naturaleza. En las cuatro obras del género de teselado\footnote{\url{http://en.wikipedia.org/wiki/Tessellation}}  de M.C. Escher, presentadas en la figura \ref{fig7Capt1} (Derecha) encuentre todos los posibles vectores  y celdas primitivas asociadas.
\end{enumerate}


\item \textbf{Redes de Bravais tridimensionales}. Este tipo de redes complica un poco más el escenario. Se puede demostrar que existen 14 de estas redes, tal y como se muestran en la figura \ref{fig8Capt1}.
 

\begin{enumerate}
 \item Muestre que los volúmenes de ocupación atómica, para los sistemas: monoclínico, triclínico, ortorómbico, tetragonal, romboédrico, hexagonal y cúbico, corresponden a las expresiones que se muestran en la figura \ref{fig8Capt1}. 
 
\begin{figure}[t]
\begin{center}
\includegraphics[width=4in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_8.jpg}
\caption{Las 14 Redes de Bravais tridimensionales y las estructuras cristalinas asociadas. Tomado de: \url{http://en.wikipedia.org/wiki/Bravais_lattice}.}
\label{fig8Capt1}
\end{center}
\end{figure}
\end{enumerate} 

\item El sistema cúbico, el más simple, corresponde a un sistema con un único parámetro de red $a= |\mathbf{a}|$, ya que  $ \mathbf{a} = \mathbf{b} = \mathbf{c} $. Además, una posible descripción, para el caso más simple, es $ \mathbf{a} = {\bf i}\,,  \mathbf{b} = {\bf j}\,,   \mathbf{c} ={\bf k}$, los tres vectores cartesianos ortogonales. Existen otros sistemas que también están asociados al cúbico. Estos son el sistema cúbico cara centrada (\textit{fcc} por sus siglas en inglés) y cúbico cuerpo centrado (\textit{bcc}). En el primero existen átomos en el centro de cada una de las caras del cubo definido por la tríada, $ \mathbf{a} = \mathbf{b} = \mathbf{c}$. En el sistema \textit{fcc} se añade un átomo la centro del cubo simple. 

\begin{enumerate}
\item Muestre que un sistema \textit{bcc} también puede ser descrito por los vectores primitivos: 
\[
\mathbf{a} = a {\bf i}\,,\quad \mathbf{b} = a {\bf j} \,,\quad 
\mathbf{c} = a({\bf i} + {\bf j} +{\bf k})/2 \,.
\] 
Dibuje la celda primitiva y calcule su volumen.
\item Muestre que un sistema \textit{bcc} también puede ser descrito por los vectores primitivos: 
\[
\mathbf{a} = a ({\bf j} + {\bf k} -  {\bf i})/2\,,\quad 
\mathbf{b} = a ({\bf k} + {\bf i} -  {\bf j})/2\,,\quad
\mathbf{c} = a( {\bf i} + {\bf j} -{\bf k})/2\,.
\] 
Dibuje la celda primitiva y calcule su volumen.
\item Muestre que un sistema \textit{fcc} también puede ser descrito por los vectores primitivos: 
\[
\mathbf{a} =  a( {\bf j} +{\bf k})/2\,,\quad
\mathbf{b}  = a( {\bf i} + {\bf k})/2\,,\quad
\mathbf{c} =  a( {\bf i} + {\bf j})/2 \,.
\] 
Otra vez, dibuje la celda primitiva y calcule su volumen.
\end{enumerate}

\item Se puede definir la red recíproca como:
 \[
 \mathbf{a'} = \frac{\mathbf{b} \times \mathbf{c} }{ \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c} )}\,,\quad
  \mathbf{b'} = \frac{\mathbf{c} \times \mathbf{a} }{ \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c} )} \quad \mbox{y} \quad 
  \mathbf{c'} = \frac{\mathbf{a} \times \mathbf{b} }{ \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c} )} \,.
 \] 
 De esta manera es claro que, por construcción, $ \mathbf{a'} \cdot \mathbf{b} = \mathbf{a'} \cdot \mathbf{c}  = 0$ y además $\mathbf{a'} \cdot \mathbf{a} = 1$. Con lo cual podemos generalizarlo como $ \mathbf{\hat{e}}^{i'} \cdot \mathbf{\hat{e}}_{j} = \delta^{i'}_{j}$. 
 
 Exprese los vectores y las celdas recíprocas para los  sistemas cúbico simple, y los distintos \textit{bcc} y \textit{fcc}. Calcule además el volumen de cada celda recíproca. 
 
\end{enumerate}
\item Realice los cálculos anteriores utilizando el programa {\bf Maxima}.

\end{enumerate}


\section{Álgebra vectorial con índices}
\label{AlgebraVectorialIndices}
\index{Algebra vectorial con índices}
Antes de comenzar con la presentación de este esquema de cálculo cabe aclarar algunas costumbres y convenciones con la notación de índices que estaremos utilizando durante el resto de este curso.
\subsection{Convención de Einstein}
\label{ConvencionEinstein}
\index{Einstein!Convención de}
\index{Convención de Einstein}
\index{Índices!Convención de Einstein}

El convenio de suma de Einstein, es una simplificación que se utiliza para abreviar la escritura de las sumatorias, en el que se suprime el símbolo de sumatoria y consiste en lo siguiente:

\begin{enumerate}
\item  Los índices repetidos (arriba y abajo) indicarán suma por los valores que tomen los índices. Las componentes de los vectores tendrán índices arriba y los vectores base abajo:
\[
{\bf a}=a^{1}\mathbf{e}_{1}+a^{2}\mathbf{e}_{2}+a^{3}\mathbf{e}_{3}=
\sum_{m=1}^{3}a^{m}\mathbf{e}_{m}\quad\Leftrightarrow\quad{\bf a}=
a^{m}\mathbf{e}_{m} = a^{i}\mathbf{e}_{i} \,.
\]

\item  Los índices repetidos son mudos (no importa las letras que los etiquete) y representan suma. Así:
\[
{k}^{j}{a}_{j}={k}^{m}{a}_{m}={k}^{1}{a}_{1} +{k}^{2}{a}_{2} +{k}^{3}{a}_{3}={b} \,.
\]

En este punto del discurso, la posición de los índices (arriba y abajo) solo tiene sentido estético y solo así indican suma. 
Más adelante veremos que representan cantidades distintas.
\item  Llamaremos contracción cuando sumamos respecto a un par de índices, vale decir:
\[
{A}_{i}^{j} \,\, \Rightarrow \,\, 
\sum_{i}{A}_{i}^{i}={A}_{1}^{1}+{A}_{2}^{2} +{A}_{3}^{3} 
\,\, \Rightarrow \,\,
{A}_{i}^{i}={A}_{1}^{1}+{A}_{2}^{2}+{A}_{3}^{3} \,.
\]
\end{enumerate}

Las cantidades con dos o más índices las llamaremos componentes de tensores, y deben entenderse como arreglos bidimensionales (tridimensionales, tetradimensionales, según el número de índices). Estas cantidades serán considerados en detalle posteriormente pero  por ahora, contentémonos con saber qué cosas son cantidades con dos índices. Es claro que la contracción de índices convierte un conjunto de números $\left(  i \times j \right) \rightarrow 1$, en un sólo número. 

Los índices libres (aquellos que no están sumados) indican el número de objetos disponibles y deben mantenerse a ambos lados de la ecuación. Por ejemplo:
\[
{B}_{i}= {K}_{i}^{k}{A}_{k} \quad\Leftrightarrow\quad
\left\{
\begin{array}
[c]{c}
{K}_{1}^{1}{A}_{1}+{K}_{1}^{2}{A}_{2}+{K}_{1}^{3}{A}_{3}={B}_{1}\\
\\
{K}_{2}^{1}{A}_{1}+{K}_{2}^{2}{A}_{2}+{K}_{2}^{3}{A}_{3}={B}_{2}\\
\\
{K}_{3}^{1}{A}_{1}+{K}_{3}^{2}{A}_{2}+{K}_{3}^{3}{A}_{3}={B}_{1}
\end{array}
\right.
\]
con lo cual ${B}_{i}={K}_{i}^{k}{A}_{k}$ representa 3 ecuaciones. La operación ${B}_{ij}={K}_{i}^{k}{A}_{kj}$ representa 9.


\index{Kronecker!Delta de}
\index{Delta de Kronecker}
\index{Kronecker!Leopold Kronecker}
La delta de Kronecker\footnote{Leopold Kronecker (7 diciembre 1823 Legnica, Polonia, 29 diciembre 1891, Berlin, Alemania) Matemático polaco con importantes contribuciones en teoría de números, funciones elípticas y álgebra, así como la interrelación entre estas disciplinas.} es un objeto matemático de dos índices, representa $\delta_{i}^{k}=1$ si $i=k$, y es nula en los otros casos. Por ejemplo:
\[
{K}_{ij}^{k}\ \delta_{k}^{i}={K}_{1j}^{1}\underset{=1}{\underbrace{\delta_{1}^{1}}}+{K}_{2j}^{1}\overset{=0}
{\overbrace{\delta_{1}^{2}}}+{K}_{3j}^{1}\overset{=0}{\overbrace
{\delta_{1}^{3}}}+{K}_{1j}^{2}\overset{=0}{\overbrace{\delta_{2}^{1}}
}+{K}_{2j}^{2}\underset{=1}{\underbrace{\delta_{2}^{2}}}+{K}
_{3j}^{2}\overset{=0}{\overbrace{\delta_{2}^{3}}}+{K}_{1j}^{3}
\overset{=0}{\overbrace{\delta_{3}^{1}}}+{K}_{2j}^{3}\overset
{=0}{\overbrace{\delta_{3}^{2}}}+{K}_{3j}^{3}\ \underset{=1}
{\underbrace{\delta_{3}^{3}}}\,,
\]
es decir:
\[
{K}_{ij}^{k}\ \delta_{k}^{i}={K}_{kj}^{k}={K}_{ij}^{i}={K}_{1j}^{1}+{K}_{2j}^{2}+{K}_{3j}^{3} \,.
\]
\index{Levi-Civita!Tensor}
\index{Tensor!Levi-Civita} 
\index{Levi-Civita!Tullio Levi-Civita}

Además de la delta de Kronecker introduciremos el símbolo de permutación de Levi-Civita\footnote{Tullio Levi-Civita (1873 Padova, Veneto, 1941 Roma, Italia) Geómetra italiano y uno de los desarrolladores del cálculo tensorial que más tarde sería utilizado por Einstein y Weyl como el lenguaje de la Relatividad General.}, $\varepsilon^{ijk}$, para el caso de tres dimensiones: $i,j,k=1,2,3$.
\[
\varepsilon_{ijk}=\varepsilon^{ijk}=\left\{
\begin{array}
[c]{ll}
+1 & \mbox{cuando}\quad \{\left(i,j,k\right)=\left(1,2,3\right) ;\left(  3,1,2\right)
;\left(  2,3,1\right)  \}\mbox{ permutación cíclica}\\
-1 & \mbox{cuando}\quad \{\left(i,j,k\right)=\left(  1,3,2\right)  ;\left(  3,2,1\right)
;\left(  2,1,3\right)  \}\mbox{ permutación impar o anticíclica}\\
\ \ 0 & \mbox{cuando}\quad  \{i=j\,,\quad  i=k\quad \wedge\quad  j=k\} 
\end{array}
\right.
\]
Por lo tanto, es distinto de cero cuando todos los índices son diferentes. Toma el valor $1$ si la permutación de índices es cíclica (o par), y toma el valor $-1$ si la permutación es anticíclica (o impar). 

Si queremos calcular, por ejemplo:  $c^{i}=\varepsilon^{ijk}a_{j}b_{k}$, entonces resulta:
\begin{eqnarray*}
c^{1}=\varepsilon^{111}a_{1}b_{1}+\varepsilon^{112}a_{1}b_{2}+\varepsilon^{113} a_{1}b_{3}+\varepsilon^{121}a_{2}b_{1}+\varepsilon^{122}a_{2}b_{2}+\varepsilon^{123}a_{2}b_{3}+\varepsilon^{131}a_{3}b_{1}+\varepsilon^{132}a_{3}b_{2}+\varepsilon^{133}a_{3}b_{3}\,, \\
c^{2}=\varepsilon^{211}a_{1}b_{1}+\varepsilon^{212}a_{1}b_{2}+\varepsilon^{213}a_{1}b_{3}+\varepsilon^{221}a_{2}b_{1}+\varepsilon^{222}a_{2}b_{2}+\varepsilon^{223}a_{2}b_{3}+\varepsilon^{231}a_{3}b_{1}+\varepsilon^{232}a_{3}b_{2}+\varepsilon^{233}a_{3}b_{3} \,,\\
c^{3}=\varepsilon^{311}a_{1}b_{1}+\varepsilon^{312}a_{1}b_{2}+\varepsilon^{313}a_{1}b_{3}+\varepsilon^{321}a_{2}b_{1}+\varepsilon^{322}a_{2}b_{2}+\varepsilon^{323}a_{2}b_{3}+\varepsilon^{331}a_{3}b_{1}+\varepsilon^{332}a_{3}b_{2}+\varepsilon^{333}a_{3}b_{3} \,,
\end{eqnarray*}
con lo cual:
\[
c^{i}=\varepsilon^{ijk}a_{j}b_{k}\,\, \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
c^{1}=\varepsilon^{123}a_{2}b_{3}+\varepsilon^{132}a_{3}b_{2}=a_{2}b_{3}-a_{3}b_{2}\\
\\
c^{2}=\varepsilon^{231}a_{3}b_{1}+\varepsilon^{213}a_{1}b_{3}=a_{3}b_{1}-a_{1}b_{3}\\
\\
c^{3}=\varepsilon^{312}a_{1}b_{2}+\varepsilon^{321}a_{2}b_{1}=a_{1}b_{2}-a_{2}b_{1}
\end{array}
\right.
\]

A continuación enumeramos algunas propiedades de la delta de Kronecker y del símbolo de permutación de Levi-Civita, dejamos al lector su demostración. Ellas son:
\begin{align*}
\delta_{j}^{j}  &  =3 \,,\\
\varepsilon_{jkm}\varepsilon^{ilm}  &  =\delta_{j}^{i}\delta_{k}^{l}
-\delta_{k}^{i}\delta_{j}^{l}=\delta_{j}^{i}\delta_{k}^{l}-\delta_{j}
^{l}\delta_{k}^{i} \,, \\
\varepsilon_{jmn}\varepsilon^{imn}  &  =2\delta_{j}^{i}\,,\\
\varepsilon_{ijk}\varepsilon^{ijk}  &  =6 \,.
\end{align*}


\subsection{Vectores e índices}
\index{Índices!Álgebra de vectores}
\index{Vectores 3D!Álgebra con índices}

Disponemos ahora de una manera más elegante para escribir ecuaciones que involucren vectores. Veamos que forma toma el álgebra vectorial con esta nueva notación.

\subsubsection{Sumas de vectores}
La suma de vectores será expresada de la siguiente manera:
\[
{\bf a}+{\bf b}=a^{i}\mathbf{e}_{i}+b^{i}\mathbf{e}_{i}=\left(  a^{i}+b^{i}\right)  \mathbf{e}_{i}=c^{i} \mathbf{e}_{i}\,\, \Rightarrow \,\,  c^{i}=a^{i}+b^{i}\quad\text{con }i=1,2,3 \,.
\]

\subsubsection{Producto escalar}
A partir da ahora y de forma equivalente, expresaremos el producto escalar en término de los índices. De forma y manera que:
\[
{\bf a}\cdot{\bf b}=\left|  {\bf a}\right|  \left|  {\bf b}\right| \cos(\theta)_{{\bf a}{\bf b}}=a^{i}b_{i} \quad \text{con }i=1,2,3 \,.
\]

\subsubsection{Producto vectorial}
En términos de índices, la componente $i$ del producto vectorial se puede expresar como:
\[
{c}^i=\left({\bf a}\times{\bf b}\right) ^{i}=\varepsilon^{ijk} a_{j}  b_{k} \quad \text{con }i,j,k=1,2,3 \,.
\]
De esta manera, todas las particularidades de producto vectorial ahora descansan en las propiedades del símbolo de Levi-Civita.

\subsubsection{Triple producto mixto}
Para finalizar, analicemos ahora el número (pseudoescalar) que proviene de la multiplicación mixta:
\[
{\bf c}\cdot\left(  {\bf a}\times{\bf b}\right)  =\left|  {\bf c}\right| \left|   {\bf a}\times{\bf b}  \right|  \cos(\theta)
_{\left\langle {\bf c},{\bf a}\times{\bf b}\right\rangle }=c^{i}
 \varepsilon_{ijk}\ a^{j}b^{k}= \varepsilon_{ijk}\ c^{i} a^{j}b^{k}  =  \left|
\begin{array}
[c]{ccc}
 c^1 &  c^2 &  c^3\\
a^1 & a^2 & a^3\\
 b^1 &  b^2 &  b^3
\end{array}
\right| \,.
\]

\subsection{Rotación de coordenadas}
\label{RotacionCoordenadas}
\index{Rotación de coordenadas}
\index{Coordenadas! Rotación de}
Consideremos un sistema de coordenadas cartesiano $(x,y,z)$ y su base canónica $\{{\bf i}, {\bf j}, {\bf k}\}$, si rotamos el sistema de coordenadas un ángulo $\phi$ alrededor del eje $z$ tendremos un nuevo sistema de coordenadas $({\tilde x}, {\tilde y}, {\tilde z})$ y una nueva base $\{\tilde{\bf i}, \tilde{\bf j}, \tilde{\bf k}\}$. La regla de transformación que relaciona ambos sistemas de coordenadas es:
\[
\left\{
\begin{array}
[c]{ccl}
x & = & {\tilde x}\cos(\phi)- {\tilde y}\ \mbox{sen}(\phi)\\
y & = & {\tilde x}\ \mbox{sen}(\phi)+ {\tilde y}\cos(\phi) \\
z & = & {\tilde z}
\end{array}
\right.   \quad  \Longleftrightarrow \quad 
\left\{
\begin{array}
[c]{ccl}
{\tilde x} & = & { x}\cos(\phi) + { y}\ \mbox{sen}(\phi)\\
{\tilde y} & = & -{ x}\ \mbox{sen}(\phi)+ { y}\cos(\phi) \\
{\tilde z}& = & { z}
\end{array}
\right.
\label{rotacionejez}
\]

Mientras que las bases transformarán, como veremos más adelante, como:
\[
\left\{
\begin{array}
[c]{ccl}
\tilde{\bf i} & = & {\bf i}\cos(\phi)+{\bf j}\ \mbox{sen}(\phi)\\
\tilde{\bf j} & = & -{\bf i}\ \mbox{sen}(\phi)+ {\bf j}\cos(\phi) \\
\tilde{\bf k} & = & {\bf k}
\end{array}
\right. 
\]

Diremos que un triplete de números $\left(a^1, a^2,  a^3\right)$ definen las componente de un vector ${\bf a}=a^1{\bf i}+a^2{\bf j}+a^3{\bf k}$ si estas cantidades transforman bajo rotación de la siguiente manera:
\[
{\tilde a}_1  =  {a}_1\cos(\phi) + {a}_2\ \mbox{sen}(\phi)\,, \quad \,
{\tilde a}_2  =  -{a}_1\ \mbox{sen}(\phi)+ {a}_2\cos(\phi) \,, \quad \,
{\tilde a}_3  =  {a}_3 \, .
\]

Notemos también lo siguiente, al usar la notación de índices podemos escribir las ecuaciones de transformación de coordenadas así:
\[
\left\{
\begin{array}
[c]{ccl}
{\tilde x} & = & { x}\cos(\phi) + { y}\ \mbox{sen}(\phi)\\
{\tilde y} & = & -{ x}\ \mbox{sen}(\phi)+ { y}\cos(\phi) \\
{\tilde z}& = & { z}
\end{array} 
\right. \,\,  \Rightarrow \,\, 
\left\{
\begin{array}
[c]{ccl}
{\tilde x}^1&=& A^1_1 {x}^1+A^1_2{x}^2+A^1_3{x}^3\\
{\tilde x}^2&=& A^2_1 {x}^1+A^2_2{x}^2+A^2_3{x}^3\\
{\tilde x}^3&=& A^3_1 {x}^1+A^3_2{x}^2+A^3_3{x}^3
\end{array} 
\right.
\,\,  \Rightarrow \,\,
{\tilde x}^i= {\tilde A}^i_j {x}^j \,, 
\label{transrota}
\]
con: $i,j=1, 2, 3$. 

Se puede ver fácilmente que las cantidades ${\tilde A}^i_j$, en coordenadas cartesianas, vienen dadas por:
\[
{\tilde A}^i_j  =\frac{\partial {\tilde x}^i}{\partial x^j} \,,
\]
y como la transformación de coordenadas es invertible, se tiene que:
\[
x^j= A^j_i {\tilde x}^i \,, \quad \, \mbox{con:}\quad \, A^j_i  =\frac{\partial {x}^j}{\partial {\tilde x}^i}\,,
\]
y se cumple la siguiente condición de ortogonalidad:
\[
{\tilde A}^i_k A^j_i =\delta^j_k\,.
\]
Por lo tanto, en general, diremos que las componentes de un vector transformarán de la manera siguiente:
\[
\label{transformacomponentes1}
{\tilde a}^i =\frac{\partial {\tilde x}^i}{\partial x^j} {a}^j \equiv  {\tilde A}^i_j {a}^j\,\quad \Leftrightarrow \quad
a^i = \frac{\partial  x^i}{\partial {\tilde x}^j} {a}^j \equiv   A^i_j {a}^j\ \,.
\]


\subsection{Escalares, pseudoescalares, vectores y pseudovectores}
\label{PseudoCantidades}
\index{Pseudo-escalares}
\index{Pseudo-vectores}
Además de las rotaciones podemos considerar otra clase de transformaciones: las reflexiones. Estas transformaciones, $(x^{1}, x^{2}, x^{3}) \rightarrow (-x^{1}, x^{2}, x^{3})$, muestran una sutil diferencia entre dos tipos de cantidades vectoriales: los vectores polares y los axiales, diferencia que no se puede apreciar en las rotaciones.

Una reflexión en el plano $yz$ se puede representar como un cambio de signo en la componente $x$ del vector: 
\begin{equation}
(a_{x}, a_{y}, a_{z})  \rightarrow (-a_{x}, a_{y}, a_{z}) \,,
\label{reflexion}
\end{equation}
o también:
\[
a^{1}\mathbf{e}_{1} + a^{2}\mathbf{e}_{2} +a^{3}\mathbf{e}_{3} \rightarrow  
a^{1}(-\mathbf{e}_{1}) + a^{2}\mathbf{e}_{2} +a^{3}\mathbf{e}_{3} \equiv 
(-a^{1})\mathbf{e}_{1} + a^{2}\mathbf{e}_{2} +a^{3}\mathbf{e}_{3} \, .
\]

Diremos que los objetos que transforman de esta manera bajo reflexión son vectores polares o simplemente vectores. Nótese que esa transformación de coordenadas es equivalente a invertir el vector base: $\mathbf{e}_{1} \rightarrow -\mathbf{e}_{1}$. 

Ahora bien, si dos vectores polares $\mathbf{a}$ y $\mathbf{b}$, son transformados bajo reflexión como en (\ref{reflexion}), entonces un vector axial $\mathbf{c}$ transformará como: 
\[
\mathbf{c} = \mathbf{a} \times \mathbf{b} \rightarrow  \mathbf{\tilde{a}} \times \mathbf{\tilde{b}} = -\mathbf{\tilde{c}}\,. 
\]
Es decir, los vectores axiales o pseudovectores cambian de signo bajo reflexión de los vectores que los generan\footnote{Esta inversión de vector axial puede comprobarse fácilmente utilizando la definición de productor vectorial (\ref{produtovectorial1}) en la cual se aprecia que un cambio en el signo en $a_{x}$ y $b_{x}$ induce un cambio de signo en $c_{y}$ y $c_{z}$.}. 

De igual manera notamos que $d ={\bf a} \cdot {\bf b}$ queda invariante bajo la transformación (\ref{reflexion}), mientras que $V={\bf c}\cdot\left(  {\bf a}\times{\bf b}\right)$ cambia de signo. Siguiendo el ejemplo de vectores y pseudovectores, llamaremos escalar a $d$ y pseudoescalar a $V$. 

Existen importantes cantidades físicas que vienen representadas por pseudovectores, entre ellas mencionamos: la cantidad de momento angular, $ \mathbf{L} = \mathbf{r} \times \mathbf{p}$; el torque ${\boldsymbol \tau} =\mathbf{r} \times \mathbf{F}$  y el campo de inducción magnética, 
$\dfrac{\partial \mathbf{B}}{\partial t}=- \mathbf{\nabla} \times\mathbf{E}$. 

Pseudovectores y vectores representan distintos objetos geométricos. Los primeros se asocian a orientaciones de superficies, mientras que los segundos lo están con segmentos de rectas orientadas. El vector velocidad angular, ${\boldsymbol \omega}$, es un pseudovector por cuanto $\mathbf{r}$ y $\mathbf{v}$ son vectores polares y $\mathbf{v} = {\boldsymbol  \omega } \times \mathbf{r}$.  Algo equivalente ocurre con la aceleración de Lorentz $\mathbf{a} = q\mathbf{v}\times \mathbf{B}$, donde $\mathbf{B}$ es el campo magnético.  

En general, podemos representar la reflexión (\ref{reflexion}) bajo el esquema que presentamos en (\ref{transformacomponentes1}), es decir, como transformaciones del tipo: 
\[
\left(
\begin{array}{r}
\tilde{a}_{x} \\        
\tilde{a}_{y} \\
\tilde{a}_{z} \\        
\end{array}
\right) \equiv
\left(
\begin{array}{r}
-a_{x} \\        
a_{y} \\
a_{z} \\        
\end{array}
\right) =
\left(
\begin{array}{rrr}
-1 & 0 & 0 \\        
 0 & 1 & 0 \\
 0 &  0 & 1\\        
\end{array}
\right) 
\left(
\begin{array}{c}
a_{x} \\        
a_{y} \\
a_{z} \\        
\end{array}
\right) \,.
\]
donde:
\[
 {\tilde a}^i = {\tilde A}^i_j {a}^j \, , 
\,\, \text{donde} \,\,\,
{\tilde A}^i_j = \frac{\partial {\tilde x}^i}{\partial x^j} =
\left(
\begin{array}{rrr}
-1 & 0 & 0 \\        
 0 & 1 & 0 \\
 0 &  0 & 1\\        
\end{array}
\right) \,,
\]
es la matriz de transformación de coordenadas\footnote{Una discusión de vectores y pseudovectores puede consultarse en la nota de Quigley, Robert J. ``Pseudovectors and Reflections'' American Journal of Physics 41, no. 3 (1973): 428-430; y en el capítulo 52 del Vol. 1 de Feynman, R.P., Leighton, R.B. and Sands, M., 2013. The Feynman Lectures on Physics, Desktop Edition. Basic Books. Para algunas de las consecuencias que se presentan cuando se consideran cantidades físicas y transformaciones de reflexión.}. 

Notemos que aquí el determinante de la matriz de transformación tiene como valor $-1$ ($\det|{\tilde A}|=-1$) ¿Cuál es el valor del determinante de la matriz que podemos asociar a (\ref{transrota})?

El hecho de que el $\det|{\tilde A}|=1$  o $\det|{\tilde A}|=-1$, permite clasificar a las transformaciones de coordenadas en {\it transformaciones propias} o {\it transformaciones impropias}, respectivamente. 

Entonces, en general, diremos que las componentes de vectores y pseudovectores transformarán bajo reflexión de la siguiente manera:
\[
\text{si:} \quad {\tilde A}^i_j = \frac{\partial {\tilde x}^i}{\partial x^j}  \,\, \Rightarrow \,\,
\left\{
\begin{array}{ll}
{\tilde a}^i = {\tilde A}^i_j {a}^j \,,   &  \text{vectores polares o simplemente vectores, }  \\ \\
{\tilde p}^i = \det|{\tilde A}| {\tilde A}^i_j {p}^j   \,, &  \text{pseudovectores o vectores axiales}.      
\end{array}
\right.
\]
\newpage

\subsection{{\color{Fuchsia}Ejemplos}}
\label{ParCalculos}
\index{Ejemplos cálculos vectoriales con índices}
\index{Índices!Ejemplos cálculos vectoriales}

\begin{enumerate}
\item Mostraremos a continuación dos casos de identidades vectoriales que pueden ser fácilmente demostradas mediante la utilización de índices.

\begin{enumerate}
\item ${\bf a}\times\left(  {\bf b}\times{\bf c}\right)  =\left(  {\bf c}
\cdot{\bf a}\right)  {\bf b}-\left(  {\bf a}\cdot{\bf b}\right)  {\bf c}$

El resultado será un vector, por lo tanto:
\begin{eqnarray*}
\left( {\bf a}\times\left(  {\bf b}\times{\bf c}\right)  \right)^{i}  
=\varepsilon^{ijk}a_{j}\left(  {\bf b}\times{\bf c}\right)_{k}
&=&\varepsilon^{ijk}a_{j}\varepsilon_{kmn}b^{m}c^{n}=\varepsilon
^{ijk}\varepsilon_{kmn}a_{j}b^{m}c^{n}=\varepsilon^{ijk}\varepsilon_{mnk}  a_{j}b^{m}c^{n}\\
&=& \left(  \delta_{m}^{i}\delta_{n}^{j}-\delta_{m}^{j}\delta_{n}^{i}\right)
a_{j}b^{m}c^{n}=\delta_{m}^{i}\delta_{n}^{j}a_{j}b^{m}c^{n}-\delta_{m}
^{j}\delta_{n}^{i}a_{j}b^{m}c^{n} \\
&=& \delta_{m}^{i}b^{m}\delta_{n}^{j}a_{j}c^{n}-\delta_{n}^{i}c^{n}\delta
_{m}^{j}a_{j}b^{m}=b^{i}\underset{\left(  {\bf c}\cdot{\bf a}\right)
}{\underbrace{a_{n}c^{n}}}-c^{i}\underset{\left(  {\bf a}\cdot{\bf b}\right)
}{\underbrace{a_{j}b^{j}}}\\
&=& b^{i}\left(  {\bf c}\cdot{\bf a}\right)  -c^{i}\left(  {\bf a}\cdot {\bf b} \right)= {\bf b} \left(  {\bf c}
\cdot{\bf a}\right) -{\bf c}\left(  {\bf a}\cdot{\bf b}\right) \,.
\end{eqnarray*}

En la segunda línea hemos hecho uso de la identidad: $\varepsilon_{jkm}\varepsilon^{ilm}   =\delta_{j}^{i}\delta_{k}^{l}
-\delta_{k}^{i}\delta_{j}^{l}=\delta_{j}^{i}\delta_{k}^{l}-\delta_{j}
^{l}\delta_{k}^{i} $.


\item $\left(  {\bf a}\times{\bf b}\right)  \cdot\left(  {\bf c}\times {\bf d} \right)  =
\left(  {\bf a}\cdot{\bf c}\right)  \left(  {\bf b}\cdot {\bf d} \right)  -
\left(  {\bf a}\cdot {\bf d} \right)  \left(  {\bf b}\cdot {\bf c} \right)  $

El lado derecho es un escalar, por lo tanto:
\begin{align*}
\left(  {\bf a}\times{\bf b}\right)  \cdot\left(  {\bf c}\times {\bf d} \right)   &  =
\left(  {\bf a}\times{\bf b}\right)  ^{l}\left(  {\bf c} \times {\bf d} \right)  _{l}\\
&  =\varepsilon^{ljk}a_{j}b_{k}\ \varepsilon_{lmn}c^{m}d^{n}=\varepsilon
^{ljk}\varepsilon_{lmn}\ a_{j}b_{k}c^{m}d^{n}\\
&  =\varepsilon^{jkl}\varepsilon_{mnl}\ a_{j}b_{k}c^{m}d^{n}=\left(
\delta_{m}^{j}\delta_{n}^{k}-\delta_{m}^{k}\delta_{n}^{j}\right)  a_{j}
b_{k}c^{m}d^{n}\\
&  =\delta_{m}^{j}\delta_{n}^{k}a_{j}b_{k}c^{m}d^{n}-\delta_{m}^{k}\delta
_{n}^{j}a_{j}b_{k}c^{m}d^{n}\\
&  =\underset{\left(  {\bf a}\cdot{\bf c}\right)  }{\underbrace{\delta_{m}
^{j}a_{j}c^{m}}}\underset{\left(  {\bf b}\cdot {\bf d} \right)  }{\underbrace
{\delta_{n}^{k}b_{k}d^{n}}}-\underset{\left(  {\bf b}\cdot{\bf c}\right)}
{\underbrace{\delta_{m}^{k}b_{k}c^{m}}}\underset{\left(  {\bf a}\cdot {\bf d} \right) }
{\underbrace{\delta_{n}^{j}a_{j}d^{n}}}\\
&  =\left(  {\bf a}\cdot{\bf c}\right)  \left(  {\bf b}\cdot {\bf d} \right)
-\left(  {\bf b}\cdot{\bf c}\right) \left(  {\bf a}\cdot {\bf d} \right)  \,.
\end{align*}\end{enumerate}

\item Si tenemos tres vectores $\{ {\bf a}, {\bf b}, {\bf c} \}$ queremos ver si se cumple: 
\[
 {\bf a} \times ({\bf b} \times {\bf c}) +  {\bf b} \times ({\bf c} \times {\bf a}) +  {\bf c} \times ({\bf a} \times {\bf b})= {\bf 0}\,.
 \] 

En notación de índices resulta:
 \[
{\bf a} \times ({\bf b} \times {\bf c}) +  {\bf b} \times ({\bf c} \times {\bf a}) +  {\bf c} \times ({\bf a} \times {\bf b})    = 
  \epsilon^{lmi}a_{m}\epsilon_{ijk}b^{j}c^{k} + \epsilon^{lmi}b_{m}\epsilon_{ijk}c^{j}a^{k} + \epsilon^{lmi}c_{m}\epsilon_{ijk}a^{j}b^{k} \,,
 \]
con lo cual, arreglando:
\begin{eqnarray*}
\epsilon^{lmi}\epsilon_{ijk}a_{m}b^{j}c^{k} + \epsilon^{lmi}\epsilon_{ijk}b_{m}c^{j}a^{k} + \epsilon^{lmi}\epsilon_{ijk}c_{m}a^{j}b^{k} &=&
\left( \delta^{l}_{j} \delta^{m}_{k} -  \delta^{m}_{j} \delta^{l}_{k}  \right) a_{m}b^{j}c^{k} + \left( \delta^{l}_{j} \delta^{m}_{k} -  \delta^{m}_{j} \delta^{l}_{k}  \right) b_{m}c^{j}a^{k} \\
&+& 
 \left( \delta^{l}_{j} \delta^{m}_{k} -  \delta^{m}_{j} \delta^{l}_{k}  \right) c_{m}a^{j}b^{k} \,,
\end{eqnarray*}
y ahora desarrollando los productos de las $\delta$'s, e identificando término a término, notamos que se anulan:
\[
\underbrace{a_{k}b^{l}c^{k} }_{I}-\underbrace{a_{k}b^{k}c^{l} }_{II}+\underbrace{b_{k}c^{l}a^{k}}_{II}-\underbrace{b_{k}c^{k}a^{l}}_{III} 
+\underbrace{c_{k}a^{l}b^{k}}_{III}-\underbrace{c_{k}a^{k}b^{l}}_{I}  = 0\,.
 \]
 
\item Vimos que los vectores polares transforman bajo una reflexión respecto al plano $yz$ de la forma:
\[
{\bf e}_1 \rightarrow - {\bf e}_1 \,\, \Rightarrow \,\,
({\tilde a}^1,{\tilde a}^2,{\tilde a}^3)=(-{a}^1,{a}^2,{a}^3)\,.
\]

Para saber que pasa con el vector ${\bf c}={\bf a}\times {\bf b}$, cuando lo sometemos a esta reflexión, estudiemos como se transforman sus componentes directamente de la definición del producto vectorial, miremos con respecto a la componente $x$ de ${\bf c}$. Entonces, para ${\bf a}$ y ${\bf b}$ vectores polares se tiene:
\begin{eqnarray*}
\tilde{\bf c}=\tilde{\bf a}\times \tilde{\bf b}&=& \left[
\left( \tilde{a}^2 \tilde{b}^3-\tilde{a}^3 \tilde{b}^2\right) \,,
\left(\tilde{a}^3 \tilde{b}^1-\tilde{a}^1 \tilde{b}^3\right) \,,
\left(\tilde{a}^1 \tilde{b}^2-\tilde{a}^2 \tilde{b}^1\right) \right] \\
&=&\left[
\left( {a}^2 {b}^3-{a}^3 {b}^2\right)\,,
\left({a}^3 (-{b}^1)-(-{a}^1) {b}^3\right) \,,
\left((-{a}^1) {b}^2-{a}^2 (-{b}^1)\right) \right]\\
&=&\left[
\left( {a}^2 {b}^3-{a}^3 {b}^2\right)\,, -
\left({a}^3 {b}^1-{a}^1 {b}^3\right) \,, -
\left({a}^1 {b}^2-{a}^2 {b}^1\right) \right]\,,
\end{eqnarray*}
es decir,  ${\bf c}$ es un vector axial por el hecho de obedecer a una ley de transformación diferente:
\[
{\bf e}_1 \rightarrow - {\bf e}_1 \,\, \Rightarrow \,\,
({\tilde c}^1,{\tilde c}^2,{\tilde c}^3)=({c}^1,-{c}^2,-{c}^3)\,.
\]

Supongamos que ahora queremos aplicar una reflexion al vector ${\bf c}={\bf a}\times {\bf b}$ pero con ${\bf a}$ axial y ${\bf b}$  polar. Veamos lo que sucede: 
\begin{eqnarray*}
\tilde{\bf c}=\tilde{\bf a}\times \tilde{\bf b}&=&\left[
\left( \tilde{a}^2 \tilde{b}^3-\tilde{a}^3 \tilde{b}^2\right) \,, 
\left(\tilde{a}^3 \tilde{b}^1-\tilde{a}^1 \tilde{b}^3\right) \,, 
\left(\tilde{a}^1 \tilde{b}^2-\tilde{a}^2 \tilde{b}^1\right) \right] \\
&=&\left[
\left((-{a}^2) {b}^3-(-{a}^3) {b}^2\right)\,,
\left((-{a}^3) (-{b}^1)-{a}^1 {b}^3\right) \,,
\left({a}^1 {b}^2-(-{a}^2) (-{b}^1)\right) \right] \\
&=&\left[
-\left({a}^2 {b}^3-{a}^3 {b}^2\right)\,,
\left({a}^3 {b}^1-{a}^1 {b}^3\right) \,,
\left({a}^1 {b}^2-{a}^2 {b}^1\right) \right] \,.
\end{eqnarray*}
Esto es:
\[
{\bf e}_1 \rightarrow - {\bf e}_1 \,\, \Rightarrow \,\,
({\tilde c}^1,{\tilde c}^2,{\tilde c}^3)=(-{c}^1,{c}^2,{c}^3)\,,
\]
por lo tanto, en este caso ${\bf c}$ es un vector polar. 
\end{enumerate}

\newpage
\subsection{{\color{red}Practicando con Maxima}} 
A  fines prácticos, las transformaciones de coordenadas del tipo rotaciones o reflexiones es de utilidad representarlas por matrices. Por ejemplo, las rotaciones alrededor del eje $z$ se puede representar como:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Rz:matrix([cos(theta),sin(theta),0],[-sin(theta),cos(theta),0],[0,0,1]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o1) }
\begin{pmatrix}\cos(\theta) & \sin(\theta) & 0 \\ 
-\sin  (\theta) & \cos(\theta) & 0 \\ 
0 & 0 & 1 
 \end{pmatrix}
\end{math}
\newline

De manera que un vector ${\bf a}$ transformará bajo esta rotación en un nuevo vector ${\bf a}'$. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:[a1,a2,a3];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
\left[ { a_1} , { a_2} , { a_3} \right]
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Rz.a;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
\begin{pmatrix}
{a_2}\,\sin(\theta)+{ a_1}\,\cos(\theta) \\ 
{ a_2}\,\cos(\theta)-{ a_1}\,\sin(\theta) \\ 
{ a_3}
 \end{pmatrix}
\end{math}
\newline

Si la rotación se hace al rededor del eje $x$ o $y$ las matrices correspondientes son las siguientes:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Rx:matrix([1,0,0],[0,cos(theta),-sin(theta)],[0,sin(theta),cos(theta)]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
\begin{pmatrix}1 & 0 & 0 \\ 
0 & \cos(\theta) & -\sin(\theta) \\ 
0 & \sin (\theta) & \cos (\theta)  
\end{pmatrix}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Ry:matrix([cos(theta),0,sin(theta)],[0,1,0],[-sin(theta),0,cos(theta)]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
\begin{pmatrix}
\cos(\theta) & 0 & \sin(\theta) \\ 
0 & 1 & 0 \\ 
 -\sin(\theta) & 0 & \cos(\theta) 
 \end{pmatrix}
\end{math}
\newline

Notemos que el determinante de éstas matrices es:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
determinant(Rx),trigsimp;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
\sin^2(\theta)+\cos^2(\theta)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
trigrat(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
1
\end{math}
\newline

Si la rotación es en un ángulo de $\theta=60^\circ$ entonces:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
sublis([theta=%pi/3], Rx);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
\begin{pmatrix}
1 & 0 & 0 \\ 
0 & \frac{1}{2} & -\frac{\sqrt{3}}{2}  \\ 
0 & \frac{\sqrt{3}}{2} & \frac{1}{2} 
 \end{pmatrix}
\end{math}
\newline

Si el eje de rotación se define a través de un vector unitario, digamos, 
${\hat {\bf u}}= u_x{\bf i}+u_y{\bf j}+u_z{\bf k}$, la matriz de rotación para un ángulo $\theta$ es:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i9) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
t:1-cos(theta)$
\end{verbatim}}
\end{minipage}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
R:matrix([cos(theta)+ux^2*t,ux*uy*t-uz*sin(theta),ux*uz*t+uy*sin(theta)],
[uy*ux*t+uz*sin(theta),cos(theta)+uy^2*t,uy*uz*t-ux*sin(theta)],
[uz*ux*t-uy*sin(theta),uz*uy*t+ux*sin(theta),cos(theta)+uz^2*t]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10) }
\begin{pmatrix}
\left(1-\cos (\theta)\right)\,{ux}^2+\cos(\theta) & 
\left(1-\cos(\theta)\right)\,{ux}\,{\it uy}-\sin (\theta)\,{uz} & 
\left(1-\cos (\theta)\right)\,{ ux}\, { uz}+\sin (\theta)\,{ uy} \\ 
\sin (\theta)\,{uz}+\left(1-\cos (\theta)\right)\,{ux}\,{uy} & 
\left(1-\cos (\theta) \right)\,{uy}^2+\cos(\theta) & 
\left(1-\cos (\theta)\right)\, {uy}\,{uz}-\sin (\theta)\,{ ux} \\ 
\left(1-\cos (\theta)\right)\,{ ux}\,{ uz}-\sin (\theta)\,{uy} & 
 \left(1-\cos (\theta)\right)\,{uy}\,{uz}+\sin (\theta)\, { ux} & 
 \left(1-\cos (\theta)\right)\,{ uz}^2+\cos (\theta)
\end{pmatrix}
\end{math}
\newline

Por ejemplo, si el eje de rotación coincide con el vector 
${\hat {\bf u}}= \frac{{\bf i}}{\sqrt{3}}+\frac{{\bf j}}{\sqrt{3}}+\frac{{\bf k}}{\sqrt{3}}$ y la rotación es en un ángulo de $\theta=60^\circ$, entonces:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
[ux,uy,uz]:1/sqrt(3)*[1,1,1]; theta:%pi/3$
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
\left[ \frac{1}{\sqrt{3}} , \frac{1}{\sqrt{3}} , \frac{1}{\sqrt{3}} \right] 
\end{math}
\newline

Al evaluar con el comando {\bf ev} podemos ver como queda la matriz $R$ con estos valores definidos

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i13) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Ru:ev(R);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
\begin{pmatrix}
\frac{2}{3} & -\frac{1}{3} & \frac{2}{3} \\ 
\frac{2}{3} & \frac{2}{3} & -\frac{1}{3} \\ 
-\frac{1}{3} & \frac{2}{3} &  \frac{2}{3} \\ 
 \end{pmatrix} 
\end{math}
\newline

De manera que un vector, por ejemplo, ${\bf a}= {\bf i}+2{\bf j}+3{\bf k}$ transformará bajo esta rotación de la manera siguiente:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i14) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:[1,2,3];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o14) }
\left[ 1 , 2 , 3 \right] 
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i15) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Ru.a;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o15) }
\begin{pmatrix}2 \\ 1 \\ 3  
\end{pmatrix}
\end{math}
\newline

Por otro lado, una reflexión en el plano $xy$ es más sencilla de representar porque es la matriz: 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i16) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Re:matrix([-1,0,0],[0,1,0],[0,0,1]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o16) }
\begin{pmatrix}-1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 
 \end{pmatrix}
\end{math}
\newline

De manera que bajo ésta reflexión el vector transforma como:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i17) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
Re.a;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o17) }
\begin{pmatrix}
-1 \\ 2\\ 3 \\ 
 \end{pmatrix}
\end{math}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}
\begin{enumerate}
\item Verifique las siguientes identidades:
\begin{enumerate}
\item 
$\mathbf{a}\times (\mathbf{b}\times \mathbf{c})+\mathbf{b}\times (\mathbf{c}\times \mathbf{a})
+ \mathbf{c}\times (\mathbf{a}\times \mathbf{b})={\bf 0}$.
\item $(\mathbf{a}\times \mathbf{b})\times(\mathbf{c}\times \mathbf{d})=
\mathbf{b}[\mathbf{a}\cdot(\mathbf{c}\times \mathbf{d})] -
\mathbf{a}[\mathbf{b}\cdot(\mathbf{c}\times \mathbf{d})]$.
\item $(\mathbf{a}\times \mathbf{b})\cdot(\mathbf{c}\times \mathbf{d})+
(\mathbf{b}\times \mathbf{c})\cdot(\mathbf{a}\times \mathbf{d})+
(\mathbf{c}\times \mathbf{a})\cdot(\mathbf{b}\times \mathbf{d})=0$.
\item $\mathbf{a}\cdot (\mathbf{b}\times\mathbf{a})=0$.
\item $(\mathbf{a}\times \mathbf{b})\cdot(\mathbf{a}\times \mathbf{b})=
a^2b^2-(\mathbf{a}\cdot \mathbf{b})^2$.
\item $(\mathbf{a}\times \mathbf{b})\cdot (\mathbf{c}\times \mathbf{d})=
\left|\begin{array}{cc}
\mathbf{a}\cdot \mathbf{c} & \mathbf{a}\cdot \mathbf{d}  \\ \\
\mathbf{b}\cdot \mathbf{c}  & \mathbf{b}\cdot \mathbf{d} 
\end{array}
\right|$
\end{enumerate}

\item Demuestre la siguiente tabla de relaciones:
\[
\begin{array}
[c]{ccccc}
\text{vector} & \cdot & \text{vector} & = & \text{escalar}\\
\text{vector} & \cdot & \text{pseudovector} & = & \text{pseudoescalar}\\
\text{pseudovector} & \cdot & \text{pseudovector} & = & \text{escalar}\\
\text{vector} & \times & \text{vector} & = & \text{pseudovector}\\
\text{vector} & \times & \text{pseudovector} & = & \text{vector}\\
\text{pseudovector} & \times & \text{pseudovector} & = & \text{pseudovector}
\end{array}
\]

\item Considere lo expuesto en la sección \ref{RotacionCoordenadas} y demuestre que:
\[
{\tilde A}^i_k A^j_i =\delta^j_k\,,
\]
y además, como un caso especial, establecer la relación con los cosenos directores que satisfacen:
\[
\cos(\alpha)^2+\cos(\beta)^2+\cos(\gamma)^2 =1 \,.
\]

\item Considere el radio vector posición $\mathbf{r} = x^i \mathbf{e}_{i} \equiv x \hat{\i} + y \hat{\j}$ en 2 dimensiones. Dado el conjunto de transformaciones que se indican a continuación, demuestre en cuales casos las componentes de $\mathbf{r}$ transforman como verdaderas componentes de vectores.
\[
 (x,y) \rightarrow (-y,x)\,,\quad  (x,y) \rightarrow  (x,-y)\,,\quad 
 (x,y) \rightarrow  (x-y,x+y)\,,\quad  (x,y) \rightarrow  (x+y,x-y) \,.
\]

\item Resuelva los ejercicios anteriores utilizando {\bf Maxima}.

\end{enumerate}


\section{Un comienzo a la derivación e integración de vectores}
\label{ComienzoDerivacionVectores}
\index{Vectores 3D!Derivación/integración}
\index{Derivación!Campos vectoriales}
\index{Integración!Campos vectoriales}
\index{Campos vectoriales!Comienzos de derivación/integración}
En esta penúltima sección de este capítulo abordaremos una introducción somera a las consecuencias que imponen la variación de un vector. Mostraremos, de manera funcional y como una ejercitación a los conceptos de derivación e integración de vectores y campos vectoriales\footnote{Un análisis más detallado lo presentaremos en el último capítulo \ref{CapAnalisisVectorial}}.   

\subsection{Vectores variables}
Los vectores podrán ser constantes o variables. Ahora bien, esta característica se verificará tanto en las componentes como en la base. Esto quiere decir que cuando un vector es variable podrá variar su módulo, su dirección, su sentido, o todo junto o por separado. Obviamente esta variabilidad del vector dependerá de la base en la cual se exprese, por lo cual un vector podrá tener una componente constante en una base y no constante en otra, vale decir:
\[
\mathbf{a}\left(t\right)  =a^{k}\left(t\right)  \mathbf{e}_{k}\left(t\right)  = {a}^{k'}\mathbf{e}_{k'}\left(t\right) \,.  
\]
Nótese que hemos utilizado una base $\left\{ \mathbf{e}_{k}\left(t\right)  \right\} $ de vectores variables a diferencia de la tradicional base de vectores cartesianos, los cuales \textbf{son constantes} en módulo, dirección y sentido (ver los cuadrantes I y II de la figura \ref{fig6vectcartes}). Más aún, tal y como se muestra en cuadrante II de la figura \ref{fig6vectcartes}, todo vector variable podrá ser expresado como la suma de uno variable, ${\boldsymbol \alpha}\left( t\right)$, más otro constante
${\bf c}$.
\[ 
\mathbf{a}(t)  ={\boldsymbol \alpha} (t)  + {\bf c} \,.
\]

\subsection{Derivación}
\label{DerivacionVectores3D}
\index{Derivación vectores 3D}
\index{Vectores 3D!Derivación}
De esta manera, cuando uno piensa en un vector variable  ${\bf a}\left( t\right)$  uno rápidamente  intenta establecer un cociente incremental:
\[
\lim_{\Delta t\rightarrow0}\frac{\mathbf{a}\left(t+\Delta t\right)-\mathbf{a}\left(t\right)}{\Delta t}= \lim_{\Delta t\rightarrow0}\frac{\Delta\mathbf{a}\left(t\right)  }{\Delta t}= \frac{\mathrm{d}\mathbf{a}\left(t\right)}{\mathrm{d}t }\,.
\]
El cuadrante IV de la figura \ref{fig6vectcartes} ilustra gráficamente este cociente incremental. 

Como siempre, las propiedades de esta operación derivación serán:
\begin{eqnarray*}
\frac{\mathrm{d}} {\mathrm{d}t} \left[  \mathbf{a}\left(t\right)  + \mathbf{b}(t)\right]  
&  =&   \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{a}(t)+\frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{b}\left( t\right) \, ,\\
\frac{\mathrm{d}} {\mathrm{d}t}    \left[ \alpha \left(t\right)  \mathbf{a}(t)\right]    
&  =& \left[ \frac{\mathrm{d}} {\mathrm{d}t}  \alpha (t)\right] \mathbf{a}\left(t\right)  + \alpha(t)
\left[ \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{a}\left( t\right) \right] \, , \\
\frac{\mathrm{d}} {\mathrm{d}t}    \left[    \mathbf{a} \left(t\right) \cdot  \mathbf{b}(t)\right]    
&  =& \left[ \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{a} (t)\right]\cdot \mathbf{b}\left(t\right)  + \mathbf{a}(t)\cdot
\left[ \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{b}\left( t\right) \right] \, , \\
\frac{\mathrm{d}} {\mathrm{d}t}    \left[ \mathbf{a} \left(t\right) \times \mathbf{b}(t)\right]    
&  =& \left[ \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{a} (t)\right] \times \mathbf{b}\left(t\right)  + \mathbf{a}(t) \times
\left[ \frac{\mathrm{d}} {\mathrm{d}t}  \mathbf{b}\left( t\right) \right] \, .
\end{eqnarray*}

\begin{figure}[t]
\begin{center}
\includegraphics[height=3.4in,width=5.8in]
{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_9.jpg}
\caption{Vectores variables}
\label{fig6vectcartes}
\end{center}
\end{figure}

Ahora bien, esto implica que:
\begin{equation}
\mathbf{a}(t)  =a^{k}(t)  \mathbf{e}_{k}\left(t\right)  \,\,   \Rightarrow \,\,  
\frac{\mathrm{d}  \mathbf{a}(t)  }{\mathrm{d}t}=
\frac{\mathrm{d}\left[  a^{k}(t) \mathbf{e}_{k}(t)  \right]  }{\mathrm{d}t}=
\frac{\mathrm{d} a^{k}(t)   } {\mathrm{d}t}\mathbf{e}_{k}\left(t\right)  + a^{k}(t)  \frac{\mathrm{d }  \mathbf{e}_{k}(t)  }{\mathrm{d}t} \,,
\label{dAdtvariable}
\end{equation}
con lo cual hay que tener cuidado al derivar vectores y cerciorarse de la dependencia funcional de la base y componentes. 

Habrá sistemas de coordenadas (bases de vectores) que serán constantes y otros en los cuales sus vectores bases cambiarán en su dirección. El primer término de (\ref{dAdtvariable}) representa la variación del módulo, y el segundo
muestra la contribución de los cambios en dirección del vector. Más aún, mostraremos apoyándonos en la ilustración de el cuadrante III de la figura \ref{fig6vectcartes} que, independientemente del sistema
de coordenadas, el cambio en el módulo apunta en la dirección del vector, mientras que las contribuciones en dirección apuntan en la dirección perpendicular al vector. Esto es:
\[
\frac{\mathrm{d}\mathbf{a}\left(t\right)}{\mathrm{d}t}=
\frac{\mathrm{d} \left|  \mathbf{a}(t)  \right| }{\mathrm{d}t}\hat{{\bf u}}_{\Vert} +\left|  \mathbf{a}\left(t\right)  \right| \hat{{\bf u}}_{\bot}\,, \quad \text{con }\hat{{\bf u}}_{\Vert} \cdot \hat{{\bf u}}_{\bot}=0\,.
\label{dAdt2}
\]

Es fácil convencernos de la forma del primer término. Siempre podemos representar un vector como su módulo y un vector unitario en la dirección apropiada. Esto es:
\[
\mathbf{a} (t)  =\left|  \mathbf{a}(t)  \right| \hat{\bf u}(t) \,\,  \Rightarrow \,\,   \frac{\mathrm{d} \mathbf{a} (t)}{\mathrm{d}t}=
\frac{\mathrm{d}\left[  \left|  \mathbf{a}\left(t\right)  \right|  \hat{\bf u}(t)  \right]  }{\mathrm{d}t}=
\frac{\mathrm{d }\left|  \mathbf{a}(t)  \right|  }{\mathrm{d}t}\hat{\bf u}(t)  +\left|  \mathbf{a}(t)\right|\frac{\mathrm{d}  \hat{\bf u}(t)}{\mathrm{d}t} \,.
\]
Por ser $|\hat{\bf u}(t)|=1$, resulta que $\hat{\bf u}(t)\cdot \frac{\mathrm{d}  \hat{\bf u}(t)}{\mathrm{d}t}=0$, es decir, son perpendiculares. 

Como podemos ver a continuación cuando multiplicamos por $\hat{\bf u}(t)$:

\[
\hat{\bf u}(t) \cdot \frac{\mathrm{d} \mathbf{a}\left(t\right)}{\mathrm{d}t}=
\hat{\bf u}(t)  \cdot\left[\frac{\mathrm{d}\left|  \mathbf{a}(t)  \right|  }{\mathrm{d}t} \hat{\bf u}(t)  +\left|  \mathbf{a}(t)  \right|\frac{\mathrm{d} \hat{\bf u}(t)   }{\mathrm{d}
t}\right] \,\,  \Rightarrow \,\,  
\left\{
\begin{array}
[c]{c}
\hat{\bf u}(t)  \cdot \dfrac{\mathrm{d} \mathbf{a}\left(t\right)   }{\mathrm{d}t}=\dfrac{\mathrm{d }\left| \mathbf{a}\left(t\right)  \right|  }{\mathrm{d}t}\\
\\
\hat{\bf u}(t)  \cdot\dfrac{\mathrm{d} \hat{\bf u}\left(t\right)  }{\mathrm{d}t}=0
\end{array}
\right.
\]

Es decir que el cambio en el módulo de un vector se manifiesta en la dirección del mismo vector, tal y como era intuitivo suponer. Adicionalmente,  vemos que el vector $\hat{\bf u}$ siempre será perpendicular a su derivada. Gráficamente
podemos apreciarlo en el cuadrante IV de la figura \ref{fig6vectcartes}, pero también surge analíticamente si derivamos el vector unitario en la dirección de $\mathbf{a}(t)$:
\[
\frac{\mathrm{d}\left[  \hat{\bf u}(t)  \cdot \hat{\bf u}\left(t\right)  \right]  }{\mathrm{d}t}\equiv
\frac{\mathrm{d}\left(  \left|  \hat{\bf u}(t)  \right|  ^{2}\right)  }{\mathrm{d}t}=
\frac{\mathrm{d}\left(  1\right)  }{\mathrm{d}t}\equiv 0 =
\hat{\bf u}\left(t\right)  \cdot \frac{\mathrm{d}  \hat{\bf u}(t) }{\mathrm{d}t}
\,\,  \Rightarrow \,\,   
\hat{\bf u}(t)  \ \bot \ \frac{\mathrm{d} \hat{\bf u}(t)   }{\mathrm{d}t} \,,
\]
es decir:
\[
\frac{\mathrm{d}  \mathbf{a}(t)  }{\mathrm{d}t}=
\frac{\mathrm{d}\left[  \left|  \mathbf{a}(t)  \right|  \hat{\bf u} (t)  \right]  }{\mathrm{d}t}=
\frac{\mathrm{d}\left| \mathbf{a}(t)  \right|  }{\mathrm{d}t}\hat{\bf u}(t) +\left|  \mathbf{a}(t)  \right|  \frac{\mathrm{d}  \hat{\bf u} (t)  }{\mathrm{d}t}=\frac{\mathrm{d}  \left| \mathbf{a}(t)  \right|   }{\mathrm{d}t} \hat{\bf u}_{\Vert}+\left|  \mathbf{a}(t)  \right|  \hat{\bf u}_{\bot}\,.
\]

Supongamos que ahora definimos un vector 
$ \Delta {\boldsymbol \theta} =\Delta \theta \ \hat{\bf v}$, 
con:
\[
\left.
\begin{array}
[c]{c}
\hat{\bf v}\ \bot\ \hat{\bf u}_{\Vert}\\
\\
\hat{\bf v}\ \bot\ \hat{\bf u}_{\bot}
\end{array}
\right\}  \,\,  \Rightarrow \,\,    \left\{
\begin{array}
[c]{c}
\hat{\bf v}\times\hat{\bf u}_{\Vert}=\hat{\bf u}_{\bot}\\
\\
\hat{\bf u}_{\bot}\times\hat{\bf v}=\hat{\bf u}_{\Vert}\\
\\
\hat{\bf u}_{\Vert}\times\hat{\bf u}_{\bot}=\hat{\bf v}
\end{array}
\right.
\]
donde $\Delta {\boldsymbol \theta} $ es el ángulo de rotación del vector ${\bf a}(t) $ (ver cuadrante V de la figura \ref{fig6vectcartes}). Claramente:
\begin{align*}
\Delta\mathbf{a}_{\bot}  &  =\left[a\left( t+\Delta t\right)  
\operatorname{sen}\left(  \Delta
\theta\right)\right]  \hat{\bf u}_{\bot}\approx \left[a\left(t+\Delta t\right)
\Delta\theta\right] \hat{\bf u}_{\bot} \,\,  \Rightarrow \,\,    \Delta \mathbf{a}_{\bot} = \Delta {\boldsymbol \theta} \times\mathbf{a}(t) \,,
\end{align*}
entonces:
\begin{equation*}
\dfrac{\Delta\mathbf{a}_{\bot}}{\Delta t}   \equiv\left[  \frac{\Delta\mathbf{a}
}{\Delta t}\cdot \mathbf{a}_{\bot}\right]  \mathbf{a}_{\bot}=
\frac{ \Delta {\boldsymbol \theta} }{\Delta t}\times\mathbf{a}\left(t\right) 
\,\,  \Rightarrow \,\,   
\left[  \frac{\mathrm{d}\mathbf{a}\left(t\right) }
{\mathrm{d}t}\cdot\hat{\bf u}_{\bot}\right]  \hat{\bf u}_{\bot}=\frac{\mathrm{d}
  \theta(t)  }{\mathrm{d}t}\hat{\bf v}\times
\mathbf{a}(t)  =  {\boldsymbol \omega} \times\mathbf{a}(t) \,,
\end{equation*}
donde hemos identificado ${\boldsymbol \omega}=\frac{\mathrm{d} \theta\left( t\right)}{\mathrm{d}t}\hat{\bf v}$. 

Podemos ir más allá observando el cuadrante V de la figura \ref{fig6vectcartes}, vemos que si suponemos que el módulo del vector es constante, entonces:
\[
\dfrac{\mathrm{d }\left| \mathbf{a}(t)  \right|  }{\mathrm{d}
t}=0 \quad  \Rightarrow \quad  \frac{\mathrm{d}  \mathbf{a}(t) }{\mathrm{d}t}=
\left|  \mathbf{a}(t)  \right|  \hat
{\bf u}_{\bot} \,\,  \Rightarrow \,\,    \left[  \frac{\mathrm{d}  \mathbf{a}\left(
t\right) }{\mathrm{d}t}\cdot\hat{\bf u}_{\bot}\right]  \hat{\bf u}_{\bot
}={\boldsymbol \omega} \times\mathbf{a}(t)\,.
\]

\subsection{Velocidades y aceleraciones}
\label{VelocidadesAceleraciones3D}
\index{Vectores 3D!Velocidades/Aceleraciones}
El radio vector posición de una partícula genera, como sabemos,  los vectores velocidad y aceleración:
\[
{\bf r}={\bf r}(t)  \,\,  \Rightarrow \,\, {\bf v}(t)=
\frac{\mathrm{d}  {\bf r} (t)  }{\mathrm{d}t} \,\,  \Rightarrow \,\, {\bf a}(t)  =\frac{\mathrm{d} {\bf v} (t)  }{\mathrm{d}t}=\frac{\mathrm{d}^{2}{\bf r}(t)  }{\mathrm{d}t^{2}}\,,
\]
ahora bien:
\[
{\bf r}=r\hat{\bf u}_{r}=x{{\bf i}}+y{{\bf j}}+z{{\bf k}}\,, \quad\text{con: } \ \hat{\bf u}
_{r}=\cos(\theta)\ {{\bf i}}+\operatorname{sen}(\theta)\ {{\bf j}} + z{{\bf k}}\,.
\]

Si suponemos que la partícula describe una trayectoria, entonces:
\[
\left.
\begin{array}
[c]{c}
r=r(t) \\
\\
\theta=\theta(t)\\
\\
z=z(t)
\end{array}
\right\}  \quad\Longleftrightarrow\quad\left\{
\begin{array}
[c]{c}
x=x(t) \\
y=y(t) \\
z=z(t)
\end{array}
\right.  ;\quad\hat{\bf u}_{r}=\hat{\bf u}_{r}\left(t\right)  ;\quad
\begin{array}
[c]{c}
{{\bf i}}=\text{const}\\
{{\bf j}}=\text{const}\\
{{\bf k}}=\text{const}
\end{array}
\]

Es muy común denotar a la derivada temporal sobre funciones de una variable con un punto, es decir, podemos utilizar la siguiente notación:
\[
 \dot{f}(t) \equiv \frac{\mathrm{d} f \left(t\right)}{\mathrm{d}t} \,,
\]
con lo cual, y en el caso de que  $z=z(t)=$ constante, se tiene:
\begin{eqnarray*}
\frac{\mathrm{d}  \hat{\bf u}_{r} }{\mathrm{d}t}  & =&
\frac{\mathrm{d}\left[  \cos(\theta\left(t\right))  {{\bf i}}
+\operatorname{sen}(\theta\left(t\right) ) {{\bf j}}\right]  }{\mathrm{d}t}=
\dot{\theta}(t) \underset{\hat{\bf u}_{\theta}
}{\underbrace{\left[  - \operatorname{sen}(\theta(t) )
{{\bf i}}+\cos(\theta(t) ) {{\bf j}
}\right]  }}=\dot{\theta}(t) \hat{\bf u}_{\theta}\,.
\end{eqnarray*}

Ya que:
\begin{align*}
\left|  \hat{\bf u}_{r}\right|   &  =\sqrt{\hat{\bf u}_{r}\cdot\hat{\bf u}_{r}}
=\sqrt{\left[  \cos(\theta(t))  \ {{\bf i}}+\operatorname{sen}
(\theta(t))  \ {{\bf j}}\right] \cdot \left[  \cos(
\theta(t))  \ {{\bf i}}+\operatorname{sen}(\theta(t))
\ {{\bf j}}\right]  }=1 \,,\\
& \\
\left|  \hat{\bf u}_{\theta}\right|   &  =\sqrt{\hat{\bf u}_{\theta}\cdot\hat
{\bf u}_{\theta}}=\sqrt{\left[  -  \operatorname{sen}(\theta(t))
\ {{\bf i}}+\cos(\theta(t) ) \ {{\bf j}
}\right]  \cdot \left[  -\left(  \operatorname{sen}(\theta(t)  \right))  {
{\bf i}}+\cos(\theta(t))  {{\bf j}}\right]  }=1 \,.
\end{align*}
Entonces:
\[
\hat{\bf u}_{\theta}\cdot\hat{\bf u}_{r}=\hat{\bf u}_{r}\cdot\hat{\bf u}_{\theta}=\left[
-  \operatorname{sen}(\theta(t))  \ {{\bf i}}
+\cos(\theta(t))  \ {{\bf j}}\right] \cdot \left[
\cos(\theta(t)) \ {{\bf i}}+\operatorname{sen}(\theta\left(
t\right))  \ {{\bf j}}\right]  =0 \,.
\]

Además:
\[
\frac{\mathrm{d}  \hat{\bf u}_{\theta} }{\mathrm{d}t}=\frac
{\mathrm{d} \left[ -\mbox{sen}(\theta(t)) 
\ {{\bf i}}+\cos(\theta(t))  \ {{\bf j}}\right]  }{\mathrm{d}t}= -\dot{\theta}(t) \left[\cos(\theta(t)) \ {{\bf i}}+\operatorname{sen}(\theta(t))  \ {{\bf j}}\right]
=-\dot{\theta}(t) \hat{\bf u}_{r} \,.
\]

Para una partícula que sigue un movimiento arbitrario, su trayectoria vendrá descrita, en coordenadas cartesianas, por:
\[
{\bf r}=x (t)  \ {{\bf i}}+y(t)\ {{\bf j}}+z(t) \ {{\bf k}}\,.
\]
\begin{itemize}
\item Su velocidad será:
\begin{align*}
{\bf v}(t)   &  =\frac{\mathrm{d}{\bf r}(t)}{\mathrm{d}t}=\frac{\mathrm{d}\left[ x(t)  {
{\bf i}}+y(t)  {{\bf j}}+z(t){{\bf k}}\right] }{\mathrm{d}t}=
\dot{x}(t) {{\bf i}}+\dot{y}(t){{\bf j}}+\dot{z}(t) {{\bf k}}
=v_{x}(t)  {{\bf i}}+v_{y}(t){{\bf j}}+v_{z}(t)  {{\bf k}} \,.
\end{align*}
\item Y su aceleración:
\[
{\bf a}(t)  =
\dot{v}_x(t) {{\bf i}}+\dot{v}_y(t)   {{\bf j}}+\dot{v}_z(t) {{\bf k}}=
a_{x}(t)  {{\bf i}}+a_{y}\left(t\right)  {{\bf j}}+a_{z}(t)  {{\bf k}}\,.
\]
\end{itemize}

Mientras que en coordenadas polares las ecuaciones son:
\[
{\bf r}(t)  =r(t)  \hat{\bf u}_{r}(t) \,.
\]
\begin{itemize}
\item Velocidad: 
\[
{\bf v}(t)  =\frac{\mathrm{d}\left[  r\left(t\right)\hat{\bf u}_{r}(t)  \right]  }{\mathrm{d}t}=
\dot{r}(t) \hat{\bf u}_{r}(t)  +r(t)\frac{\mathrm{d}\hat{\bf u}_{r}(t)  }{\mathrm{d}t}=
\dot{r}(t) \hat{\bf u}_{r}\left( t\right)  +r(t) \dot{\theta}(t)\hat{\bf u}_{\theta}(t) \,,
\]
\item Aceleración:
\begin{align*}
{\bf a}(t)   &  =\frac{\mathrm{d}{\bf v}(t) }{\mathrm{d}t}=
\frac{\mathrm{d}\left[  \dot{r}(t) \hat{\bf u}_{r}(t)  + 
r(t) \dot{\theta}(t)  \hat{\bf u}_{\theta}(t)  \right]  }{\mathrm{d}t}=
\frac{\mathrm{d}\left[\dot{r} \left(t\right)\hat{\bf u}_{r}(t)  \right]  }{\mathrm{d}t}+
\frac{\mathrm{d}\left[ r(t)\dot{\theta}(t)\hat{\bf u}_{\theta}\left(t\right)  \right]  }{\mathrm{d}t}\\
& \\
&  = \ddot{r}(t)
\hat{\bf u}_{r}\left(t\right)  +
\dot{r}(t) \frac{\mathrm{d}  \hat{\bf u}_{r}(t)   }{\mathrm{d}t}+
\dot{r}(t)\dot{\theta}(t)\hat{\bf u}_{\theta}\left(t\right)  +
r(t) \ddot{\theta}(t) \hat{\bf u}_{\theta}(t)  +
r(t) \dot{\theta}(t) \frac{\mathrm{d}  \hat{\bf u}_{\theta}(t)  }{\mathrm{d}t}\\
& \\
&  =
\left\{ \ddot{r}(t) -r (t)\left( \dot{\theta}(t) \right)^{2}\right\}  \hat{\bf u}_{r}(t)  +
\left\{2\ \dot{r}(t) \dot{\theta}(t) +r(t) \ddot{\theta}(t) \right\}  \hat{\bf u}_{\theta}(t) \,.
\end{align*}
\end{itemize}

Claramente para el caso de un movimiento circular, donde $r=R=\text{const}$, resulta:
\[
\frac{\mathrm{d}R}{\mathrm{d}t}=0\quad  \Rightarrow \quad  \left\{
\begin{array}
[c]{l}
{\bf r}(t)  =R\ \hat{\bf u}_{r}(t)\\
\\
{\bf v}(t)  =R\ \dot{\theta}(t) \hat{\bf u}_{\theta}\\
\\
{\bf a}(t)  =-R\  \dot{\theta}(t)^{2}\hat{\bf u}_{r}(t)  +R\ \ddot{\theta}(t)\hat{\bf u}_{\theta}(t)
\end{array}
\right.
\]

De aquí podemos ver que el vector velocidad ${\bf v}(t)$ y el vector  posición ${\bf r}(t) $ son ortogonales. La velocidad, ${\bf v}(t),$ siempre es tangente a la trayectoria $\bf {r}\left(t\right)$ y en este caso la trayectoria es una circunferencia. 

En general el vector:
\[
{\bf r}_{med}= \sum_{i} \Delta{\bf r}(t_{i})  = \sum_{i} \left({\bf r}\left(  t_{i}+\Delta t_{i}\right)  -{\bf r}(t_{i}) \right)  
\,\,  \Rightarrow \,\,  \lim_{\Delta t\rightarrow0} \sum_{i}\Delta{\bf r}(t_{i}) = 
\int\mathrm{d}{\bf r}(t)={\bf r}(t) \,,
\]
es decir, $\mathrm{d}{\bf r}(t)  =\lim_{\Delta t\rightarrow0} \sum_{i}\Delta\ {\bf r}(t_{i})$ es tangente a la trayectoria.
Es claro que:
\[
\mathrm{d}{\bf r}(t)  =\mathrm{d}\left[  x(t) {{\bf i}}+y(t)  {{\bf j}}+z(t)  {{\bf k}}\right]  \equiv
\frac{\mathrm{d} x(t)  }{\mathrm{d} t}{{\bf i}}+ \frac{\mathrm{d} y(t)  }{\mathrm{d} t}{{\bf j}}+ \frac{\mathrm{d} z(t)  }{\mathrm{d} t}{{\bf k}} \,.
\]

Tal y como mencionamos arriba, para el sistema de coordenadas cartesiano podemos definir un vector (en este caso) velocidad angular ${\boldsymbol \omega}$ tal que:
\[
\left.
\begin{array}
[c]{c}
\dfrac{ {\boldsymbol \omega} }{\left| {\boldsymbol \omega}  \right|  }\times\hat{\bf u}_{r}=
\hat{\bf u}_{v}\\
\\
\hat{\bf u}_{v} \times \dfrac{{\boldsymbol \omega}  }{\left| {\boldsymbol \omega} \right|}=
\hat{\bf u}_{r}\\
\\
\hat{\bf u}_{r} \times \hat{\bf u}_{v}=
\dfrac{{\boldsymbol \omega}  }{\left|{\boldsymbol \omega} \right|  }
\end{array}
\right\}  \quad  \Rightarrow \quad  {\bf v}(t)  ={\boldsymbol \omega}  \times {\bf r}(t) \,.
\]

Supongamos por simplicidad que elegimos el sistema de coordenadas cartesiano, donde  ${\bf r}$ está en el plano $xy$.  En este caso es inmediato comprobar que $v^{i}=\varepsilon^{ijk}\omega_{j}x_{k}$, y dado que ${\bf r}$ y ${\bf v}$ tienen únicamente componentes $1$ y $2$ entonces, necesariamente  ${\boldsymbol \omega} $ tiene únicamente  componente $3$,  Es decir:
\[
\left.
\begin{array}
[c]{c}
{\bf r}=r^{i} {\bf e}_{i}\\
\\
{\bf v}=v^{i} {\bf e}_{i}
\end{array}
\right\}  \,\,  \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
v^{1}=\varepsilon^{1j2}\omega_{j}x_{2}\\
\\
v^{2}=\varepsilon^{2j1}\omega_{j}x_{1}
\end{array}
\right\}  \,\,  \Rightarrow \,\,  {\boldsymbol \omega}=
\left| {\boldsymbol \omega} \right|   \mathbf{\textsf{e}}_{3}=
\omega {{\bf k}} \,,
\]
como ${\bf r}=x(t) {{\bf i}}+y(t) {{\bf j}}$, entonces:
\[
{\bf v}(t)  =\frac{\mathrm{d}  {\bf r}(t)  }{\mathrm{d}t}=v_{x}(t)   {{\bf i}}
+v_{y}(t)  {{\bf j}}={\boldsymbol \omega}  \times
{\bf r}(t)  =\dot{\theta}(t) {{\bf k}}\times\left[ x(t)
 {{\bf i}}+y(t)  {{\bf j}}\right] \,.
\]

Se verá más claro en coordenadas polares, esto es:
\begin{align*}
{\bf v}(t)  =\frac{\mathrm{d} {\bf r}(t) }{\mathrm{d}t}
=& r(t) \dot{\theta}(t) \hat{\bf u}_{\theta}(t)  =
\left[  \left|{\boldsymbol \omega} \right|  \hat{\bf u}_{n}(t)  \right]  \times\left[
r(t) \hat{\bf u}_{r}(t)  \right] \,, \quad \quad  \left|  {\bf r}(t)  \right|  =\mbox{const} \\
= & \underset{{\bf v}_{\bot}}{\underbrace{r(t) \dot{\theta}(t)} } \hat{\bf u}_{\theta}(t)   
=\left| {\boldsymbol \omega}  \right|  r(t)\hat{\bf u}_{\theta}(t) \,\,  \Rightarrow \,\,  \dot{\theta}(t) \equiv\left|  {\boldsymbol \omega}  \right| \,.
\end{align*}

\subsection{Vectores y funciones}
\label{VectoresFunciones}
Antes de continuar con la integración repensemos algunas funciones de tipo $\phi\left( x^i\right)$ y ${\bf A} (x^i)$. Estas funciones son sin duda funciones de varias variables, en el caso cartesiano:
\[
\phi =\phi(x,y,z) \,, \quad 
{\bf A} ={\bf A} (x,y,z) = {{\bf i}}A_{x}\left(x,y,z\right)  +{{\bf j}}A_{y}(x,y,z)  +{{\bf k}}A_{z}(x,y,z)\,.
\]

Un par de reflexiones se pueden hacer en este punto, primeramente, dado que hemos relacionado un punto del espacio con el radio vector posición, entonces:
\[
P_{(x,y,z)  }\leftrightarrow(x,y,z)  \leftrightarrow
{\bf r}=x\ {{\bf i}}+y\ {{\bf j}}
+z\ {{\bf k}}\,\,  \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
\phi=\phi(x,y,z)  \equiv\phi\left(  {\bf r}\right) \\
\\
{\bf A} ={\bf A} (x,y,z)  \equiv{\bf A} \left(  {\bf r}\right)
\end{array}
\right.
\]

La primera función, $\phi\left({\bf r}\right)$, será una función escalar de argumento vectorial o, simplemente un campo escalar y la segunda, ${\bf A} \left({\bf r}\right)$, se conoce como una función vectorial de argumento vectorial o campo vectorial. Como hemos dicho, este tipo de funciones y las operaciones que pueden ser realizadas con ellas, y su significado, serán analizadas en detalle más adelante durante el desarrollo de este  curso.

En segundo lugar, siempre podremos parametrizar las coordenadas y tendremos
\begin{align*}
\phi &  =\phi(t)  =\phi\left(  x(t)  ,y\left(t\right)  ,z(t)  \right) \,,\\
{\bf A} &  ={\bf A} (t)  ={\bf A} \left( x(t), y(t), z(t)  \right) =
A_{x}\left(  x(t), y\left(t\right)  , z(t)  \right){{\bf i}}  +
A_{y}\left(x(t)  ,y(t)  ,z(t)  \right){{\bf j}} +
A_{z}\left(  x(t)  ,y(t)  ,z\left(t\right)  \right){{\bf k}} \,.
\end{align*}

Este caso lo hemos encontrado en montones de situaciones, por ejemplo, el  movimiento parabólico viene descrito por  vectores velocidad y posición dados por:
\begin{align*}
{\bf v}(t) &  =- gt\ {{\bf k}} +{\bf v}_{0}=-gt\ {{\bf k}}  +
\left(  v_{0x}{{\bf i}} + v_{0y}{{\bf j}}+v_{0z} {{\bf k}} \right)  
\,\,  \Rightarrow \,\,  \left\{
\begin{array}
[c]{l}
v_{x}=v_{0x}\\
v_{y}=v_{0y}\\
v_{z}=v_{0z}-gt
\end{array}
\right. \\
& \\
{\bf r}(t)  &  =-\frac{g}{2}t^{2}\  {{\bf k}}  +{\bf v}_{0}t=
- \frac{g}{2}t^{2} \  {{\bf k}} +\left(  v_{0x}{{\bf i}} + v_{0y}{{\bf j}}+v_{0z} {{\bf k}} \right) t
\,\,  \Rightarrow \,\,  \left\{
\begin{array}
[c]{l}
x=v_{0x}t\\
y=v_{0y}t\\
z=v_{0z}t-\frac{g}{2}t^{2}
\end{array}
\right.
\end{align*}

\subsubsection{Derivada de funciones del tipo: $\phi\left(  {\bf r}(t)
\right)$}

Al derivar una función de argumento vectorial también se aplica la ``regla de la cadena''. Esto es, si
\[
\phi\left( {\bf r}(t)  \right)  = \phi \left(  x\left(t\right), y(t), z(t)  \right) \,,
\]
entonces:
\begin{align*}
\frac{\mathrm{d}\phi\left( {\bf r}(t)  \right)  }{\mathrm{d}t}  &  =
\frac{\partial \phi\left( x(t) ,y(t)  ,z(t)  \right)  }{\partial x} \frac{\mathrm{d }x(t)  }{\mathrm{d}t}+
\frac{\partial \phi\left( x(t), y(t), z(t)\right) }{\partial y}\frac{\mathrm{d}y(t)  }{\mathrm{d}t}+
\frac{\partial \phi\left(  x(t), y(t), z(t)  \right)  }{\partial z}\frac{\mathrm{d}z(t)}{\mathrm{d }t} \\
& \\
&  =\left[  \frac{\partial \phi\left(
x,y,z\right)  }{\partial x}{{\bf i}}+\frac{\partial
\phi(x,y,z)  }{\partial y}{{\bf j}+}\frac
{\partial \phi(x,y,z)  }{\partial z}{{\bf k}
}\right] \cdot \left[ 
\frac{\mathrm{d }x(t)  }{\mathrm{d }t}{{\bf i}}+
\frac{\mathrm{d }y(t)  }{\mathrm{d }t}{{\bf j}+
\frac{\mathrm{d }z(t)  }{\mathrm{d }t}{\bf k}}\right]\\
& \\
&  ={\boldsymbol \nabla}  \phi\left(  x(t)  ,y\left(t\right)  ,z(t)  \right)  
\cdot\frac{\mathrm{d }{\bf r}\left(t\right)  }{\mathrm{d }t} \,,
\end{align*}
donde hemos representado:
\[
{\boldsymbol \nabla}  \phi\left(  {\bf r}(t)  \right)  \equiv
\frac{\partial \phi(x,y,z)  }{\partial x}{{\bf i}}+
\frac{\partial \phi(x,y,z)  }{\partial y}{\bf j}+
\frac{\partial \phi(x,y,z)} {\partial z}{{\bf k}}=
\partial^{i}\phi\left(  x^j\right) {{\bf i}}_{i}=
\phi^{,i}\left(  x^j\right)  {{\bf i}}_{i} \,,
\]
y lo llamaremos el {\bf gradiente} de la función $\phi\left(  {\bf r}(t)  \right)$.

El gradiente de un campo escalar es uno de los objetos más útiles que encontraremos en el estudio de problemas de Física-Matemática, el cual lo utilizaremos por ahora de manera operacional. Es bueno recordar que emerge como consecuencia de una derivación contra un parámetro. El gradiente mide el cambio de la función $\phi\left( x,y,z\right) $.

La idea de gradiente nos lleva a considerar a ${\boldsymbol \nabla}$ como un operador vectorial que actúa sobre la función escalar de variable vectorial $\phi\left(  {\bf r}(t)  \right)$.  
\[
{\boldsymbol \nabla}\phi\left(  {\bf r}(t)  \right)   
\equiv\left(\frac{\partial}{\partial x}{{\bf i}}+\frac{\partial}{\partial y}{{\bf j}+}\frac{\partial}{\partial z}{{\bf k}}\right)
\phi(x,y,z) = \mathbf{i}_{i} \ \partial^{i} \phi(x,y,z)\,.
\]
Es decir, y  con un poquito de imaginación:
\[
{\boldsymbol \nabla} \left(  \circ\right)  =\left(  
\frac{\partial }{\partial x}{{\bf i}}+
\frac{\partial }{\partial y}{{\bf j}}+
\frac{\partial }{\partial z}{{\bf k}}\right)
\left(\circ\right)  =\mathbf{{i}}_{i}\partial^{i}\left(  \circ\right)\,.
\]

\subsubsection{Derivada de funciones del tipo: ${\bf A} \left({\bf r}(t)\right) $}
De modo que inspirados en la regla de la cadena de una función escalar de variable vectorial podemos comprobar que:
\[
\frac{\mathrm{d} {\bf A} }{\mathrm{d}t}=
\frac{\mathrm{d} A_{x}\left(x,y,z\right) }{\mathrm{d}t}{{\bf i}}+
\frac{\mathrm{d} A_{y}\left(x,y,z\right) }{\mathrm{d}t}{\bf j}+
\frac{\mathrm{d} A_{z}\left(x,y,z\right) }{\mathrm{d}t}{\bf k}=
\frac{\mathrm{d} A^{i}\left(x^j\right)  }{\mathrm{d}t}{{\bf i}}_{i} \,,
\]
por consiguiente, si ${\bf A} $, tiene por componentes cartesianas $\left( A_{x}, A_{y}, A_{z}\right)$ las componentes del vector derivado serán:
$\left(  \frac{\mathrm{d} A_{x}}{\mathrm{d}t},\frac{\mathrm{d} A_{y}
}{\mathrm{d}t},\frac{\mathrm{d} A_{z}}{\mathrm{d}t}\right)$.  Con lo cual, para cada componente:
\[
\frac{\mathrm{d}\left(A^{i}\left(  x(t), y(t), z(t)  \right) \right) }{\mathrm{d}t}=
\frac{\mathrm{d} \left(A^{i}\left(x^{j}(t)  \right) \right) }{\mathrm{d}t}=
\frac{\partial \left(A^{i}\left(x^{j}\right) \right) }{\partial x^{k}}\frac{\mathrm{d} x^{k}(t)}{\mathrm{d}t}=
\left(  \frac{\mathrm{d }{\bf r}(t)}{\mathrm{d }t}\cdot {\boldsymbol \nabla}  \right)  A^{i}(x,y,z)\,.
\]
En términos vectoriales es:
\[
\frac{\mathrm{d} {\bf A} }{\mathrm{d}t}=\left(  \frac{\mathrm{d}{\bf r}(t)  }{\mathrm{d}t}\cdot {\boldsymbol \nabla}  \right)  {\bf A}  \equiv 
\left(  {\bf v}\cdot {\boldsymbol \nabla}  \right)  {\bf A} \,\,  \Rightarrow \,\,
\frac{\mathrm{d} \left(  \circ\right)  }{\mathrm{d}t}=\left(  {\bf v} \cdot {\boldsymbol \nabla}  \right)  \left(  \circ\right)  \equiv v^{i}\partial_{i}\left(  \circ\right)\,,
\]
con ${\bf v}$ la derivada del radio vector posición ${\bf r}\left( t\right)$, es decir, la velocidad. Entonces, 
estamos viendo que el cambio del vector ${\bf A} $ respecto al tiempo es el cambio de sus componentes en la dirección de la velocidad.

Si se nos ocurre calcular la derivada del vector velocidad para encontrar la aceleración tendremos que nos quedará expresada como:
\[
{\bf a}=\frac{\mathrm{d} {\bf v}}{\mathrm{d}t}=\left(  {\bf v}\cdot
{\boldsymbol \nabla} \right)  {\bf v}\,\,  \Rightarrow \,\, a^{i}=\left(  {\bf v}\cdot
{\boldsymbol \nabla}\right)  v^{i} \,,
\]
donde las componentes cartesianas de los vectores velocidad y aceleración son: 
$v^{i}=v^{i}\left(  x\left(t\right)  ,y(t)  ,z\left( t\right)  \right)  $ y $\ a^{i}=a^{i}\left(  x(t)  ,y\left(t\right)  ,z(t)  \right)$, respectivamente.

\subsection{El operador ${\boldsymbol \nabla}$}
\label{VectorGradiente}

El operador vectorial ${\boldsymbol \nabla}\left(\circ\right)$ merece un poco de atención en este nivel. Tal y como hemos visto cuando construimos: 

{\bf El Gradiente}:
\begin{eqnarray}
{\boldsymbol \nabla}\phi(x,y,z)   &=&
 \frac{\partial\phi(x,y,z)  }{\partial x} {\bf i} +
\frac{\partial\phi(x,y,z)  }{\partial y}{\bf j}+
\frac{\partial\phi(x,y,z)  }{\partial z} {\bf k} \nonumber \\
& = & 
\partial^{1}\phi(x,y,z) {\bf i}_{1} + 
\partial^{2}\phi(x,y,z) {\bf i}_{2}  + 
\partial^{3}\phi(x,y,z) {\bf i}_{3} = 
\partial^{i} \phi\left(  x^j\right) {\bf i}_{i}\,.
\end{eqnarray}

Podemos ver ahora que existen otras posibilidades:

{\bf El Rotor}: Se puede construir la siguiente operación: ${\boldsymbol \nabla} \times{\bf A}$, que denominaremos  {\bf rotor} de ${\bf A}$, y  vendrá dado por la siguiente expresión:
\begin{eqnarray}
{\boldsymbol \nabla} \times{\bf A}  & = &
\left( \frac{\partial}{\partial x} {\bf i}+ \frac{\partial}{\partial y}{\bf j}+ \frac{\partial}{\partial z} {\bf k} \right)  
\times\left(  A_{x} {\bf i}+A_{y} {\bf j}+A_{z} {\bf k}\right) \nonumber \\
&  = &
\left(  \frac{\partial A_{z}}{\partial y}-\frac{\partial A_{y}}{\partial z}\right)  {\bf i} +
\left(\frac{\partial A_{x}}{\partial z}-\frac{\partial A_{z}}{\partial x}\right){\bf j}+
\left(  \frac{\partial A_{y}}{\partial x}-\frac{\partial A_{x}}{\partial y}\right) {\bf k} = \varepsilon^{ijk}\partial_{j}A_{k}\ {\bf i}_i \,.
\end{eqnarray}

{\bf La Divergencia}: También podemos hablar del ``producto escalar'' de nabla por un vector ${\bf A}$. 
A esta operación la llamaremos {\bf divergencia} de ${\bf A}$:
\[
{\boldsymbol \nabla} \cdot{\bf A}=\frac{\partial A^{i}\left(  x^{j}\right)}
{\partial {x}^{i}}\equiv\partial_{i}A^{i}\left(  x^{j}\right)
\equiv\frac{\partial A_{x}(x,y,z)  }{\partial x}+\frac{\partial
A_{y}(x,y,z)}{\partial y}+\frac{\partial A_{z}\left(
x,y,z\right)  }{\partial z} \,,
\]
pero por ahora consideremos nabla ${\boldsymbol \nabla}$ como un vector. 


De este modo habrá una gran cantidad de relaciones vectoriales  que involucran a ${\boldsymbol \nabla}$, las cuales se podrán demostrar.


\subsection{Integración}
\label{IntegracionCartesianas}
\index{Integración vectores 3D}
\index{Vectores 3D!Integración}

Después de haber diferenciado campos escalares y vectoriales, el siguiente paso es integrarlos. Encontraremos algunos objetos vectoriales a integrar y serán:

\begin{itemize}
\item Integración de un vector por un escalar: 
\[
\int{\bf A} \left(  u\right)  \ \mathrm{d} u
\]
\item Integración de un escalar a lo largo de un vector:
\[
\int_{c}\phi(x,y,z)  \ \mathrm{d}{\bf r}
\]
\item Integración de un vector a lo largo de otro vector:
\[
\int_{c}{\bf A} (x,y,z)  \cdot\mathrm{d} {\bf r}
\]
\end{itemize}

El primero de los casos es el tipo de integral que siempre hemos utilizado para encontrar la posición a partir de la velocidad. Los siguientes tres casos se conocen con el nombre de integrales de línea por cuanto es importante la ``ruta'' o trayectoria que sigamos al integrar. Esto aparece indicado por la letra $C$ en la integral y será evidente más adelante. En general la integral de línea dependerá de la trayectoria.

\subsubsection{Un vector por un escalar: $\int{\bf A} \left(  u\right)  \ \mathrm{d} u$}

El primer caso de este tipo integrales es el trivial que ya sabemos calcular:
\[
\int{\bf A} \left(u\right)  \ \mathrm{d}u= 
{\bf i} \int A_{x}\left(u\right) \mathrm{d} u+
{\bf j} \int A_{y}\left(u\right)   \mathrm{d} u+
{\bf k} \int A_{z}\left(u\right)  \mathrm{d} u=\left(  \int A^{i}\left(  u\right) \mathrm{d} u\right) \mathbf{{i}}_{i} \,.
\]
La integral de un vector (en un sistema de coordenadas cartesianas) por un escalar se convierte en la suma de tres integrales, cada una a lo largo de las componentes cartesianas del vector.

Recordemos que así integramos la aceleración en un movimiento parabólico:
\[
\frac{\mathrm{d}{\bf v}}{\mathrm{d}t}={\bf a}=-g \ \mathbf{{k}}
\,\,  \Rightarrow \,\,   {\bf v}=\int{\bf a}\ \mathrm{d}t=\mathbf{{k}}\
\int-g\ \mathrm{d}t=-\mathbf{{k}}\ gt\ +{\bf v}_{0}=-\mathbf{{k}}gt\ +\mathbf{{i}}v_{0x}+\mathbf{{j}}v_{0y}+\mathbf{{k}}v_{0z} \,.
\]

Ahora bien, existen sutilezas en este caso que debemos tener en cuenta. Por ejemplo, considere la integral:
\[
\int\mathrm{d}t\ \left(  {\bf a}\times\frac{\mathrm{d}^{2}{\bf a}
}{\mathrm{d}t^{2}}\right)  =\int\mathrm{d}t \left(  \frac{\mathrm{d}
 }{\mathrm{d}t}\left(  {\bf a}\times\frac{\mathrm{d} {\bf a}}{\mathrm{d}
t}\right)  -\frac{\mathrm{d} {\bf a}}{\mathrm{d}t}\times\frac{\mathrm{d}
 {\bf a}}{\mathrm{d}t}\right)  =\int\mathrm{d}t\ \frac{\mathrm{d}
 }{\mathrm{d}t}\left(  {\bf a}\times\frac{\mathrm{d} {\bf a}}{\mathrm{d}
t}\right)  ={\bf a}\times\frac{\mathrm{d}{\bf a}}{\mathrm{d}t}+{\bf c} \,.
\]

Pero en general los casos quedan resueltos integrando componente a componente con la ayuda de la notación de índices:
\[
\int\mathrm{d}t\ \left(  {\bf a}\times{\bf b}\right)  =\left[  \int
\mathrm{d}t\ \left(  \varepsilon^{ijk}a_{j}b_{k}\right)  \right]  \mathbf{i}_{i}\,.
\]

\subsubsection{Un escalar a lo largo de un vector: $\int_{C}\phi\left(  {\bf r}\right)\mathrm{d}{\bf r}$}

El segundo objeto que ``tropezaremos'' es la integración de funciones de varias variables a lo largo de  una curva determinada. Esto es:
\[
\int_{C}\phi\left(x,y,z\right)  \mathrm{d}{\bf r}=
\int_{C}\phi(x^i)  \left(  
\mathrm{d}x {\bf i} +\mathrm{d}y {\bf j}+\mathrm{d}z {\bf k}\right)  =
{\bf i}\int_{C}\phi(x^i)  \mathrm{d}x+{\bf j}
\int_{C}\phi(x^i)  \mathrm{d} y+ 
{\bf k} \int_{C}\phi(x^i)  \mathrm{d} z\,.
\]

La integral se nos ha convertido en tres integrales, las cuales son ahora componentes de un vector. Esto es posible dado que la base $\left( {\bf i}, {\bf j}, {\bf k} \right)  $ es una base constante. Ahora bien, cada una de estas integrales son interdependientes, dado que hay que seguir la misma curva $C$. 


\subsubsection{Un vector a lo largo de otro vector: $\int_{C}{\bf F} \left({\bf r}\right)  \cdot\mathrm{d}{\bf r}$}
 
Quizá la integral de línea más conocida sea una del tipo $\int _{C}{\bf F}\left(  {\bf r}\right) \cdot \mathrm{d}{\bf r}$ 
por cuanto nos la hemos ``tropezado'' en el cálculo del trabajo que realiza una fuerza. Todo lo que hemos considerado al parametrizar la curva en el caso anterior, sigue siendo válido.
\[
\int_{C}{\bf F}\left(  {\bf r}\right) \cdot \mathrm{d}{\bf r}=\int_{C}
F_{x}(x,y,z)  \ \mathrm{d}x+\int_{C}F_{y}(x,y,z)
\ \mathrm{d}y+\int_{C}F_{z}(x,y,z)  \ \mathrm{d}z=\int_{C}
F^{i}\left(  x^{j}\right)  \ \mathrm{d}x_{i} \,.
\]


\subsection{{\color{Fuchsia}Ejemplos}}
\label{EjemDerVectores}
\begin{enumerate}
\item Si una partícula se mueve a lo largo de una curva descrita por: 
\[
x(t) = 3 t^{2} \,, \quad y(t) = 4t^{3} -t\,, \quad z(t) = t \,.
\]
Entonces, las expresiones para los vectores: posición, velocidad y aceleración de esa partícula son:
\[
{\bf r}(t) = 3 t^{2} {\bf i} + (4t^{3} -t ){\bf j} + t{\bf k} \,,\quad 
{\bf{v}} = 6 t {\bf i} + (12t^{2} -1 ){\bf j} + {\bf k} \,, \quad
{\bf a} = 6  {\bf i} + 24t {\bf j} \,.
\]

Si nos proponemos encontrar las expresiones, más generales, de los vectores tangentes y perpendiculares a todo punto de la trayectoria de la partícula podemos ver que el vector  tangente a todo punto de la trayectoria es el vector velocidad
\[
 {\bf v} = 6 t {\bf i} + (12t^{2} -1 ){\bf j} + {\bf k}\,,
\]

El vector perpendicular a todo punto, será un vector ${\bf b} =b_{x} {\bf i} + b_{y}{\bf j} + b_{z}{\bf k}$, tal que:
\[
( 6 t {\bf i} + (12t^{2} -1 ){\bf j} + {\bf k})\cdot (b_{x} {\bf i} + b_{y}{\bf j} + b_{z}{\bf k}) =
6 t b_{x} + (12t^{2} -1 )b_{y} + b_{z} =0\,,
\]
con lo cual:
\[
{\bf b} = b_{x} {\bf i} + b_{y}{\bf j} - (6 t b_{x} + (12t^{2} -1 )b_{y}){\bf k}\,.
\]


\item  La trayectoria de un punto en el plano vista por un observador $(1)$ es la siguiente:
\[
{\bf r}_{1} ( t )  =5 \cos(3t^{2})\ {\bf i} +5\operatorname{sen}(3t^{2})\ {\bf j} \,.
\]

Queremos expresar las aceleraciones radiales y tangenciales de esta partícula ya que es claro que la partícula describe un movimiento circular, donde $\theta(t) = 3t^{2}$. Entonces:
\[
{\bf r}(t) = 5 \hat{\bf u}_{r} \,\, \Rightarrow \,\, {\bf v}(t) = \frac{\mathrm{d}{\bf r}(t)}{\mathrm{d}t} = 5  \frac{\mathrm{d} \theta(t)}{\mathrm{d}t}  \hat{\bf u}_{\theta} = 30 t \; \hat{\bf u}_{\theta} \,\, \Rightarrow \,\,
{\bf a}(t) = \frac{\mathrm{d}{\bf a}(t)}{\mathrm{d}t} = 30 \; \hat{\bf u}_{\theta}  -30t \; \hat{\bf u}_{r} \,.
\]

Consideremos ahora un segundo observador $(2)$, el cual describe una trayectoria respecto al primero representada por:
\[
{\bf r}_{21}(t)  = (  t^{3}- 4t) {\bf i}+ (  t^{2}+4t )  \ {\bf j}\,.
\]

Y queremos encontrar las expresiones para los vectores posición, velocidad y aceleración de la partícula medidos respecto al segundo observador.

Por lo tanto, la trayectoria de la partícula respecto al segundo observador será:
\[
{\bf r}_{2}(t) = {\bf r}_{1}(t) - {\bf r}_{21}(t) = 5 \cos(3t^{2})\ {\bf i} +5\operatorname{sen}(3t^{2})\ {\bf j} -((  t^{3}- 4t) {\bf i}+ (  t^{2}+4t )  \ {\bf j}) \,,
\]
con lo cual:
\[
{\bf r}_{2}(t) = \left[5\cos(3t^{2}) - t^{3}+ 4t\right] {\bf i} + 
\left[5\operatorname{sen}(3t^{2}) - t^{2}-4t\right] {\bf j} \,,
\]
entonces:
\[
{\bf v}_{2}(t) =\frac{\mathrm{d}{\bf r}_{2}(t)}{\mathrm{d}t} = 
-\left[30\,\mbox{sen} \left( 3\,{t}^{2} \right) t+3\,{t}^{2}-4 \right] {\bf i} + 
\left[30\,\cos\left( 3\,{t}^{2} \right) t-2\,t-4\right] {\bf j} \,,
\]
y
\[
{\bf a}_{2}(t) =\frac{\mathrm{d}{\bf v}_{2}(t)}{\mathrm{d}t} = 
-6\left[30\cos\left( 3{t}^{2} \right){t}^{2}+5\mbox{sen}\left(3{t}^{2} \right) 
+t\right] {\bf i} - 
2\left[90\mbox{sen}\left( 3{t}^{2} \right) {t}^{2}-15\cos\left( 3{t}^{2} \right) +1\right] {\bf j} \,.
\]

\item Demostrar que: 
\[
{\boldsymbol \nabla}\left(  {\bf a}\cdot{\bf b} \right) =\left({\bf a}
\cdot{\boldsymbol \nabla}\right)  {\bf b}+\left(  {\bf b}\cdot{\boldsymbol \nabla}\right)
{\bf a}+{\bf a}\times\left(  {\boldsymbol \nabla}\times{\bf b}\right)  +{\bf b}
\times\left(  {\boldsymbol \nabla}\times{\bf a}\right) \,.
\]

El resultado es un gradiente, es decir un vector. El lado izquierdo será:
\[
\left({\boldsymbol \nabla}\left({\bf a}\cdot{\bf b}\right)\right)^{i}=\mathbf{\partial}^{i}\left(  {\bf a}\cdot{\bf b}\right)
=\mathbf{\partial}^{i}\left(  a_{j}b^{j}\right)  =\left(  \mathbf{\partial
}^{i}a_{j}\right)  b^{j}+\left(  \mathbf{\partial}^{i}b_{j}\right)  a^{j} \,.
\]

Mientras que el lado derecho:
\begin{align*}
\left({\boldsymbol \nabla}\left({\bf a}\cdot{\bf b}\right)\right)^{i}  &
=\left(  a_{j}\mathbf{\partial}^{j}\right)  b^{i}+\left(  b_{j}
\mathbf{\partial}^{j}\right)  a^{i}+\varepsilon^{ijk}a_{j}
\left(  {\boldsymbol \nabla} \times{\bf b}\right)  _{k}+\varepsilon^{ijk}b_{j}\left(  {\boldsymbol \nabla}
\times{\bf a}\right)  _{k}\\
&  =\left(  a_{j}\mathbf{\partial}^{j}\right)  b^{i}+\left(  b_{j}
\mathbf{\partial}^{j}\right)  a^{i}+\varepsilon^{ijk}a_{j}\varepsilon
_{kmn}\partial^{m}b^{n}+\varepsilon^{ijk}b_{j}\varepsilon_{kmn}\partial
^{m}a^{n}\\
&  =\left(  a_{j}\mathbf{\partial}^{j}\right)  b^{i}+\left(  b_{j}
\mathbf{\partial}^{j}\right)  a^{i}+\varepsilon^{ijk}\varepsilon_{mnk}
a_{j}\partial^{m}b^{n}+\varepsilon^{ijk}\varepsilon_{mnk}b_{j}\partial
^{m}a^{n}\\
&  =\left(  a_{j}\mathbf{\partial}^{j}\right)  b^{i}+\left(  b_{j}
\mathbf{\partial}^{j}\right)  a^{i}+\left(  \delta_{m}^{i}\delta_{n}
^{j}-\delta_{m}^{j}\delta_{n}^{i}\right)  a_{j}\partial^{m}b^{n}+  
\left(  \delta_{m}^{i}\delta_{n}^{j}-\delta_{m}^{j}\delta
_{n}^{i}\right)  b_{j}\partial^{m}a^{n}\\
&  =a_{j}\mathbf{\partial}^{j}b^{i}+b_{j}\mathbf{\partial}^{j}a^{i}+\delta
_{m}^{i}\delta_{n}^{j}a_{j}\partial^{m}b^{n}-\delta_{m}^{j}\delta_{n}^{i}
a_{j}\partial^{m}b^{n}+   \delta_{m}^{i}\delta_{n}^{j}b_{j}\partial^{m}a^{n}-\delta
_{m}^{j}\delta_{n}^{i}b_{j}\partial^{m}a^{n}\\
&  =a_{j}\mathbf{\partial}^{j}b^{i}+b_{j}\mathbf{\partial}^{j}a^{i}
+a_{n}\partial^{i}b^{n}-a_{m}\partial^{m}b^{i}+b_{n}\partial^{i}a^{n}
-b_{m}\partial^{m}a^{i}\\
&  =\underset{=0}{\underbrace{a_{j}\mathbf{\partial}^{j}b^{i}-a_{m}
\partial^{m}b^{i}}}+\underset{=0}{\underbrace{b_{j}\mathbf{\partial}^{j}
a^{i}-b_{m}\partial^{m}a^{i}}}+a_{n}\partial^{i}b^{n}+b_{n}\partial^{i}a^{n}\\
&  =a_{n}\partial^{i}b^{n}+b_{n}\partial^{i}a^{n}=\mathbf{\partial}^{i}\left(
a_{j}b^{j}\right)  =\mathbf{\partial}^{i}\left(  {\bf a}\cdot{\bf b}\right) \,.
\end{align*}

\item Demostrar la siguiente identidad:
\[
{\boldsymbol \nabla}\times\left(  {\bf a}\cdot{\boldsymbol \nabla}\right)  
{\bf a}=\left(  {\boldsymbol \nabla}\cdot{\bf a}\right)  \left(  {\boldsymbol \nabla}\times{\bf a}\right)  -\left[  {\boldsymbol \nabla}\cdot\left(  {\boldsymbol \nabla}\times{\bf a}\right)  \right]  {\bf a}+\left(  {\bf a}\cdot{\boldsymbol \nabla}\right)  \left(
{\boldsymbol \nabla}\times{\bf a}\right)  -\left[  \left(  {\boldsymbol \nabla}\times{\bf a}\right)  \cdot{\boldsymbol \nabla}\right]  {\bf a}\,.
\]

Iniciamos la traducción a índices por el lado izquierdo de la ecuación, así:
\begin{align*}
{\boldsymbol \nabla}\times\left(  {\bf a}\cdot{\boldsymbol \nabla}\right)  {\bf a}  &
=\epsilon^{ijk}\partial_{j}\left(  a_{m}\partial^{m}\right)  a_{k}
=\epsilon^{ijk}\left(  \partial_{j}a_{m}\right)  \partial^{m}a_{k}
+\epsilon^{ijk}a_{m}\partial_{j}\partial^{m}a_{k}\\
&  =\epsilon^{ijk}\left(  \partial_{j}a_{m}\right)  \partial^{m}a_{k}
+a_{m}\partial^{m}\left(  \epsilon^{ijk}\partial_{j}a_{k}\right) \,.
\end{align*}

El lado derecho lo traduciremos término por término:
\begin{align*}
\left(  {\boldsymbol \nabla}\cdot{\bf a}\right)  \left(  {\boldsymbol \nabla}\times
{\bf a}\right)   &  =\left(  \partial^{m}a_{m}\right)  \left(  \epsilon
^{ijk}\partial_{j}a_{k}\right) \\
-\left[  {\boldsymbol \nabla}\cdot\left(  {\boldsymbol \nabla}\times{\bf a}\right)  \right]
{\bf a}  &  =-\left[  \partial_{m}\epsilon^{mjk}\partial_{j}a_{k}\right]
a^{i}=-\left[  \epsilon^{mjk}\partial_{m}\partial_{j}a_{k}\right]  a^{i}=0\\
\left(  {\bf a}\cdot{\boldsymbol \nabla}\right)  \left(  {\boldsymbol \nabla}\times
{\bf a}\right)   &  =a_{m}\partial^{m}\left(  \epsilon^{ijk}\partial_{j}
a_{k}\right) \\
-\left[  \left(  {\boldsymbol \nabla}\times{\bf a}\right)  \cdot{\boldsymbol \nabla}\right]
{\bf a}  &  =-\left[  \left(  \epsilon^{mjk}\partial_{j}a_{k}\right)
\partial_{m}\right]  a^{i} \,.
\end{align*}

El segundo término se anula por cuanto $\epsilon^{mjk}$ es antisimétrico respecto a los índices $m, j$, mientras que $\partial_{m}\partial_{j}$ es simétrico. El tercer término del desarrollo del lado derecho corresponde con el segundo del desarrollo del lado izquierdo. Por lo tanto, llegamos a la siguiente igualdad:
\[
\epsilon^{ijk}\left(  \partial_{j}a_{m}\right)  \partial^{m}a_{k}=\left(
\partial^{m}a_{m}\right)  \left(  \epsilon^{ijk}\partial_{j}a_{k}\right)
-\left[  \left(  \epsilon^{mjk}\partial_{j}a_{k}\right)  \partial_{m}\right]
a^{i}\,. \qquad (\divideontimes)
\]

Para verificar la igualdad tendremos que evaluar componente a componente, esto es, para $i=1$,  el lado izquierdo de $(\divideontimes)$ resulta en:
\begin{align*}
\epsilon^{1jk}\left(  \partial_{j}a_{m}\right)  \partial^{m}a_{k}  &
=\epsilon^{123}\left(  \partial_{2}a_{m}\right)  \partial^{m}a_{3}
+\epsilon^{132}\left(  \partial_{3}a_{m}\right)  \partial^{m}a_{2} 
 =\left(  \partial_{2}a_{m}\right)  \partial^{m}a_{3}-\left(  \partial
_{3}a_{m}\right)  \partial^{m}a_{2}\\
&  =\left(  \partial_{2}a_{1}\right)  \partial^{1}a_{3}+\left(  \partial
_{2}a_{2}\right)  \partial^{2}a_{3}+\left(  \partial_{2}a_{3}\right)
\partial^{3}a_{3} -  \left(  \partial_{3}a_{1}\right)  \partial^{1}a_{2}-\left(
\partial_{3}a_{2}\right)  \partial^{2}a_{2}-\left(  \partial_{3}a_{3}\right)
\partial^{3}a_{2} \,.
\end{align*}

Para el primer término del lado derecho de $(\divideontimes)$:
\begin{align*}
\left(  \partial^{m}a_{m}\right)  \left(  \epsilon^{1jk}\partial_{j}
a_{k}\right)   &  =\left(  \partial^{m}a_{m}\right)  \left(  \epsilon
^{123}\partial_{2}a_{3}\right)  +\left(  \partial^{m}a_{m}\right)  \left(
\epsilon^{132}\partial_{3}a_{2}\right) \\
&  =\underset{\alpha}{\underbrace{\partial_{2}a_{3}\partial^{1}a_{1}}
}+\partial_{2}a_{3}\partial^{2}a_{2}+\partial_{2}a_{3}\partial^{3}a_{3} -   \underset{\beta}{\underbrace{\partial_{3}a_{2}\partial
^{1}a_{1}}}-\partial_{3}a_{2}\partial^{2}a_{2}-\partial_{3}a_{2}\partial
^{3}a_{3}  \,,
\end{align*}
y el segundo término de $(\divideontimes)$ se escribe como:
\begin{align*}
-\left[  \left(  \epsilon^{mjk}\partial_{j}a_{k}\right)  \partial_{m}\right]
a^{i}  &  =-\left(  \epsilon^{1jk}\partial_{j}a_{k}\right)  \partial_{1}
a^{1}-\left(  \epsilon^{2jk}\partial_{j}a_{k}\right)  \partial_{2}
a^{1}-\left(  \epsilon^{3jk}\partial_{j}a_{k}\right)  \partial_{3}a^{1}\\
&  =-\left(  \partial_{2}a_{3}-\partial_{3}a_{2}\right)  \partial_{1}
a^{1}-\left(  \partial_{3}a_{1}-\partial_{1}a_{3}\right)  \partial_{2}a^{1}-\left(  \partial_{1}a_{2}-\partial_{2} a_{1}\right)  \partial_{3}a^{1}\\
&  =\underset{\beta}{\underbrace{\partial_{3}a_{2}\partial_{1}a^{1}}}-
\underset{\alpha}{\underbrace{\partial_{2}a_{3}\partial_{1}a^{1}}}
+\partial_{1}a_{3}\partial_{2}a^{1}-\underset{\gamma}{\underbrace{\partial
_{3}a_{1}\partial_{2}a^{1}}} +\underset{\gamma}{\underbrace{\partial_{2}
a_{1}\partial_{3}a^{1}}}-\partial_{1}a_{2}\partial_{3}a^{1} \,.
\end{align*}

Al sumar ambos términos se eliminan los sumandos indicados con letras griegas, y queda como:
\begin{align*}
\left(  \partial^{m}a_{m}\right)  \left(  \epsilon^{1jk}\partial_{j}
a_{k}\right)  -\left[  \left(  \epsilon^{mjk}\partial_{j}a_{k}\right)
\partial_{m}\right]  a^{i}  &  =\underset{\Xi}{\partial_{2}a_{3}\partial
_{2}a_{2}}+\underset{\Upsilon}{\partial_{2}a_{3}\partial_{3}a_{3}}\\
&  \underset{\Omega}{-\partial_{3}a_{2}\partial_{2}a_{2}}\underset{\Psi
}{-\partial_{2}a_{2}\partial_{3}a_{3}} +\underset{\Lambda}{\partial_{1}a_{3}\partial_{2}a_{1}}\underset{\Sigma
}{-\partial_{1}a_{2}\partial_{3}a_{1}} \,, 
\end{align*}
y al compararlo con el desarrollo del lado derecho de $(\divideontimes)$ e identificar término a término queda demostrada la igualdad:
\[
\epsilon^{1jk}\left(  \partial_{j}a_{m}\right)  \partial^{m}a_{k}= \underset{\Lambda}{\left(  \partial_{2}a_{1}\right)  \partial_{1}a_{3}}+\underset{\Xi}{\left(  \partial_{2}a_{2}\right)  \partial_{2}a_{3}}+\underset{\Upsilon}{\left(  \partial_{2}a_{3}\right)  \partial_{3}a_{3}}
-\underset{\Sigma}{\left(  \partial_{3}a_{1}\right)  \partial
_{1}a_{2}}\underset{\Omega}{-\left(  \partial_{3}a_{2}\right)  \partial
_{2}a_{2}}\underset{\Psi}{-\left(  \partial_{3}a_{3}\right)  \partial_{3}a_{2}} \,.
\]

De igual manera se procede con $i=2$ e $i=3$.

 
\item Utilizando la notación de índices muestre si se cumple la siguiente identidad:
\[
{\boldsymbol \nabla} \times\left(  {\bf a}\times{\bf b}\right)  ={\bf a}\left( {\boldsymbol \nabla}\cdot{\bf b}\right)  -{\bf b}\left(  {\boldsymbol \nabla} \cdot {\bf a}\right)  +\left(  {\bf b}\cdot{\boldsymbol \nabla}\right)  {\bf a}-\left(   {\bf a}\cdot{\boldsymbol \nabla}\right)  {\bf b} \,.
\]
 
Desarrollemos en índices el lado izquierdo:
\[
{\boldsymbol \nabla}\times\left(  {\bf a}\times{\bf b}\right)  = \epsilon^{ijk} \partial_{j}(\epsilon_{klm} a^{l}b^{m}) =
(\delta^{i}_{l}\delta^{j}_{m}-\delta^{i}_{m}\delta^{j}_{l}) \partial_{j} (a^{l}b^{m}) 
= \partial_{m} (a^{i}b^{m}) - \partial_{l} (a^{l}b^{i})  \,,
\]
expandiendo la derivada:
\[
{\boldsymbol \nabla}\times (  {\bf a}\times{\bf b})  = b^{m} \partial_{m} (a^{i}) + a^{i} \partial_{m} (b^{m}) - b^{i} \partial_{l} (a^{l}) - a^{l} \partial_{l} (b^{i}) \equiv  ({\bf b}\cdot {\boldsymbol \nabla}) {\bf a} + ({\boldsymbol \nabla} \cdot {\bf b}) {\bf a} -  ({\boldsymbol \nabla} \cdot {\bf a}) {\bf b} -  ({\bf a}\cdot {\boldsymbol \nabla}) {\bf b}\,.
\]


\item Tal vez, uno de los problemas que ilustra mejor el uso del álgebra vectorial y la derivación de vectores es el movimiento bajo fuerzas centrales. La ley de gravitación de Newton nos dice que para un sistema de dos masas, $m$ y $M$ se tiene:
\[
\sum {\bf F}=m\ {\bf a}  \,\, \Rightarrow \,\,
m G\frac{M}{r_{mM}^{2}}\mathbf{\hat{u}}_{r} = m\ \frac{\mathrm{d} {\bf v}}{\mathrm{d}t} 
\,\, \Rightarrow \,\, 
\frac{\mathrm{d} {\bf v}}{\mathrm{d}t}= \frac{G M}{r_{mM}^{2}}\mathbf{\hat{u}}_{r} \,.
\]

Es costumbre definir la \textit{velocidad areolar}$, {\bf v}_{a}$, como el área barrida por el radio vector posición, ${\bf r}(t)$, que describe la trayectoria de la partícula:
\[
2{\bf v}_{a}\equiv {\bf r}\times\frac{\mathrm{d}{\bf r}}{\mathrm{d}t}
=r\ \mathbf{\hat{u}}_{r}\times\frac{\mathrm{d} \left(  r\ \mathbf{\hat{u}}_{r}\right)  }
{\mathrm{d}t}=r \mathbf{\hat{u}}_{r}\times\left(
\frac{\mathrm{d} r}{\mathrm{d}t}\mathbf{\hat{u}}_{r}+r\frac{\mathrm{d}
 \mathbf{\hat{u}}_{r}}{\mathrm{d}t}\right)  =r\ \mathbf{\hat{u}}_{r}\times
r\frac{\mathrm{d} \mathbf{\hat{u}}_{r}}{\mathrm{d}t}=r^{2}\mathbf{\hat{u}}_{r}\times\frac{\mathrm{d}
 \mathbf{\hat{u}}_{r}}{\mathrm{d}t} \,.
\]

Nótese que:
\[
\frac{\mathrm{d} }{\mathrm{d}t}\left(  \mathbf{\hat{u}}_{r}\times
\frac{\mathrm{d}\mathbf{\hat{u}}_{r}}{\mathrm{d}t}\right)  =0
\,\, \Rightarrow \,\, 
\mathbf{\hat{u}}_{r}\times\frac{\mathrm{d} \mathbf{\hat{u}}_{r}}{\mathrm{d}t}={\bf c} \,\, \Rightarrow \,\,  2{\bf v}_{a}=r^{2}
\mathbf{\hat{u}}_{r}\times\frac{\mathrm{d} \mathbf{\hat{u}}_{r}}{\mathrm{d}t}= \mbox{const} \,,
\]
donde ${\bf c}$ es un vector constante, con lo cual:
\begin{eqnarray*}
\frac{\mathrm{d} }{\mathrm{d}t}\left(  {\bf v}\times{\bf v}_{a}\right)&=&
\frac{\mathrm{d} {\bf v}}{\mathrm{d}t}\times{\bf v}_{a}=
\frac{GM}{r_{mM}^{2}}\mathbf{\hat{u}}_{r}\times{\bf v}_{a}=\frac{GM}{2}\left\{  \mathbf{\hat{u}}_{r}\times\left(  \mathbf{\hat{u}}_{r}\times\frac{\mathrm{d}\mathbf{\hat{u}}_{r}}{\mathrm{d}t}\right)  \right\} \\
&=& 
\frac{GM}{2}\left\{  \left(  \mathbf{\hat{u}}_{r}\cdot\frac{\mathrm{d}
\mathbf{\hat{u}}_{r}}{\mathrm{d}t}\right)  \mathbf{\hat{u}}_{r}-\left(
\mathbf{\hat{u}}_{r}\cdot\mathbf{\hat{u}}_{r}\right)  \frac{\mathrm{d}
 \mathbf{\hat{u}}_{r}}{\mathrm{d}t}\right\}  =\frac{GM}{2}\frac
{\mathrm{d} \mathbf{\hat{u}}_{r}}{\mathrm{d}t}\,.
\end{eqnarray*}

Integrando:
\[
{\bf v}\times{\bf v}_{a}=\frac{GM}{2}\mathbf{\hat{u}}_{r}+{\bf p}\,,
\]
donde ${\bf p}$ es un vector arbitrario que aparece como constante de integración. 

Finalmente nos damos cuenta que:
\begin{eqnarray*}
{\bf r}\cdot\left(  {\bf v}\times{\bf v}_{a}\right) &=& 
r\ \mathbf{\hat{u}}_{r}\cdot\left(  \frac{GM}{2}\mathbf{\hat{u}}_{r}+{\bf p}\right)  =\frac{GM}{2}r+r p\cos(\theta)\\
&=&\varepsilon^{ijk}r_{i}v_{j}v_{ak}\equiv{\bf v}_{a}\cdot\left(  {\bf r}\times {\bf v}\right)  ={\bf v}_{a}\cdot{\bf v}_{a}=v_{a}^{2}\,,
\end{eqnarray*}
y entonces:
\[
v_{a}^{2}=\frac{GM}{2}r+rp\cos(\theta) \,\, \Rightarrow \,\,  
r=\frac{v_{a}^{2}}{\frac{GM}{2}+p\cos(\theta)}\equiv\frac{\frac{2v_{a}^{2}}{GM}}{1+\frac{2p}{GM}\cos(\theta)}\,,
\]
que constituye la ecuación de una curva cónica ¿Cuál curva?


\item Consideremos la siguiente función:
\[
\phi\left(  x,y\right)=3x^{2}+2y \,.
\]

Queremos calcular la siguiente integral de línea: 
\[
\int_{\left(0,0\right)}^{\left(  1,2\right)  }\left(  3x^{2}+2y\right)   \mathrm{d}{\bf r}={\bf i} \int_{\left(  0,0\right)  }^{\left(  1,2\right)}\left(  3x^{2}+2y\right)  \mathrm{d} x+{\bf j} \int_{\left(0,0\right)}^{\left(  1,2\right)}\left(  3x^{2}+2y\right)  \mathrm{d}y\,.
\]

Se requiere especificar la curva $C$ a lo largo de la cual integraremos, en este caso, desde el punto $P_{1}\rightarrow\left(0,0\right)$ al punto $P_{2} \rightarrow \left(1,2\right)$.  Podemos ir por diferentes  recorridos:

\begin{itemize}
\item Si recorremos la ruta $C_{1}$: $\left(0,0\right)
\rightarrow\left(1,0\right)  \rightarrow\left(  1,2\right) $ podemos hacerlo de la manera más sencilla:
\begin{align*}
\left(0,0\right)   &  \rightarrow\left(  1,0\right) \,\, \Rightarrow \,\, 
y=\mbox{cte}=0 \,\, \Rightarrow \,\,  
\int_{\left(  0,0\right)  }^{\left(  1,0\right)}\left(  3x^{2}+2y\right)  \mathrm{d}{\bf r}={\bf i}
\int_{\left(  0,0\right)  }^{\left(  1,0\right)  }\left(  3x^{2}+2y\right)
\mathrm{d}x={\bf i}\int_{0}^{1}\left(  3x^{2}\right)
\mathrm{d}x={\bf i} \\
& \\
\left(  1,0\right)   &  \rightarrow\left(  1,2\right)  \,\, \Rightarrow \,\, 
x=\mbox{cte}=1 \,\, \Rightarrow \,\,   \int_{\left(  0,0\right)  }^{\left(1,0\right)}\left(  3x^{2}+2y\right)  \mathrm{d}{\bf r}={\bf j}
\int_{\left(  0,0\right)  }^{\left(  1,2\right)  }\left(  3x^{2}+2y\right)
\mathrm{d}y={\bf j} \int_{0}^{2}\left(  3+2y\right)\mathrm{d}y=10{\bf j}
\end{align*}
con lo cual:
\[
C_{1}\longleftrightarrow\underset{C_{1}^{A}}{\underrightarrow{\left(
0,0\right)  \rightarrow}}\left(  1,0\right)  \underset{C_{1}^{B}
}{\underrightarrow{\rightarrow\left(  1,2\right)}}\,\, \Rightarrow \,\,  
\int_{\left(  0,0\right)  }^{\left(  1,2\right)  }\left(  3x^{2}+2y\right)
\ \mathrm{d}{\bf r}={\bf i}+10{\bf j}\,.
\]

\item Si hubiéramos seleccionado la recta que une a estos dos puntos como la curva $C_{2}$ entonces:
\[
C_{2}:   \quad  y=2x \,\,  \Rightarrow \,\,  \mathrm{d} y=2\mathrm{d} x \,,
\]
esto es:
\begin{align*}
\int_{\left(  0,0\right)  }^{\left(  1,2\right)  }\left(  3x^{2}+2y\right)
 \mathrm{d}{\bf r} &  ={\bf i} \int_{\left(  0,0\right)}^{\left(  1,2\right)}\left(  3x^{2}+2y\right)  \mathrm{d}x+{\bf j} \int_{\left(  0,0\right)}^{\left(1,2\right)}\left(3x^{2}+2y\right)  \mathrm{d}y\\
&  ={\bf i} \int_{0}^{1}\left(3x^{2}+2\left(  2x\right)  \right)  \mathrm{d}x+{\bf j}\int_{0}^{1}\left(  3x^{2}+2\left(  2x\right)  \right)  2\mathrm{d}x=3{\bf i} + 6{\bf j}\,.
\end{align*}
\end{itemize}

En general la curva $C$ se puede parametrizar  y las integrales en varias variables se convertirán en integrales a lo largo del parámetro que caracteriza la curva. 
\[
C: \left\{ x=x\left(  \tau\right) , 
y=y\left(  \tau\right) , z=z\left(  \tau\right) \right\}
\]
Por lo tanto:
\begin{align*}
\int_{C}\phi\left(x,y,z\right)  \ \mathrm{d}{\bf r}  &  =\int_{C}\phi\left(
x\left(  \tau\right)  ,y\left(  \tau\right)  ,z\left(  \tau\right)  \right)
\left(  \frac{\partial x\left(  \tau\right)  }{\partial\tau}\mathrm{d}
\tau\ {\bf i} +\frac{\partial y\left(  \tau\right)  }
{\partial\tau}\mathrm{d}\tau\ {\bf j}+\frac{\partial z\left(
\tau\right)  }{\partial\tau}\mathrm{d}\tau\ {\bf k}\right) \\
&  =
{\bf i} \int_{C}\phi\left(  x\left(  \tau\right)  ,y\left(  \tau\right)  ,z\left(
\tau\right)  \right)  \frac{\partial x\left(  \tau\right)  }{\partial\tau
}\mathrm{d}\tau+{\bf j}
\int_{C}\phi\left(  x\left(  \tau\right),y\left(  \tau\right)  ,z\left(  \tau\right)  \right)  \frac{\partial y\left(
\tau\right)  }{\partial\tau}\mathrm{d}\tau\\
& \ +{\bf k}
\int_{C}\phi\left(  x\left(  \tau\right)  ,y\left(
\tau\right)  ,z\left(  \tau\right)  \right)  \frac{\partial z\left(
\tau\right)  }{\partial\tau}\mathrm{d}\tau \,.
\end{align*}

Las parametrización de las curvas anteriores es muy simple:
\[
C_{1}^{A}=\left\{
\begin{array}
[c]{c}
x=\tau\\
\\
y=0
\end{array}
\right.  ;\quad C_{1}^{B}=\left\{
\begin{array}
[c]{c}
x=2\\
\\
y=\tau
\end{array}
\right.  ;\quad C_{2}=\left\{
\begin{array}
[c]{c}
x=\tau\\
\\
y=2\tau
\end{array}
\right.
\]

Con esta manera de parametrizar, la integral  que resolvimos anteriormente tomando el camino $C_{2}$:
\[
\int_{\left(  0,0\right)  }^{\left(  1,2\right)  }\left(  3x^{2}+2y\right)
 \mathrm{d}{\bf r} ={\bf i} \int_{\left(  0,0\right)}^{\left(  1,2\right)}\left(3x^{2}+2y\right)  \mathrm{d}x+{\bf j} \int_{\left(  0,0\right)}^{\left(1,2\right)}\left(3x^{2}+2y\right)  \mathrm{d}y \,.
\]

Queda ahora como:
\[
\int_{\left(0,0\right)  }^{\left(  1,2\right)  }\left(3x^{2}+2y\right) \mathrm{d}{\bf r} =
{\bf i} \int_{0}^{1}\left(3\tau^{2}+4 \tau \right)  \mathrm{d}\tau+
{\bf j}\int_{0}^{1}\left( 3\tau^{2}+4\tau  \right)  2\mathrm{d}\tau=3{\bf i} + 6{\bf j}\,.
\]

Ya que: $0\leq \tau\leq 1$. 

\item Consideramos el siguiente campo vectorial: 
\[
{\bf F}\left(  {\bf r}\right) =\left(  3x^{2}+2xy^{3}\right){\bf i}+6xy \ {\bf j} \,.
\]

Queremos evaluar la siguiente integral:
\begin{align*}
\int_{\left(  0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }{\bf F}\left(  {\bf r}\right)\cdot \mathrm{d}{\bf r}  &  =\int_{\left(  0,0\right)}^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }\left(  \left(  3x^{2}
+2xy^{3}\right)  {\bf i}+6xy\ {\bf j} \right)
\left(  \mathrm{d}x\ {\bf i}+\mathrm{d}y\ {\bf j} \right) \\
&  =\int_{\left(  0,0\right)}^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }\left(  3x^{2}+2xy^{3}\right)
 \mathrm{d}x+\int_{\left(  0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }6xy\ \mathrm{d}y\,.
\end{align*}

Consideremos  que la curva que une esos puntos viene parametrizada por:  
\[
x=2\tau^{2}\,,\,\, y=\tau^{3}+\tau \,\, \Rightarrow \,\,
\frac{\partial x\left(\tau\right)  }{\partial\tau}=4\tau \,,
\frac{\partial y\left(\tau\right)  }{\partial\tau}=3\tau^{2}+1 \,,
\]
entonces, la primera de las integrales resulta:
\begin{align*}
\int_{\left(0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }\left(
3x^{2}+2xy^{3}\right)  \ \mathrm{d}x  &  =\int_{0}^{\frac{\sqrt{2}}{2}}\left(  3\left(  2\tau
^{2}\right)  ^{2}+2\left(  2\tau^{2}\right)  \left(  \tau^{3}+\tau\right)
^{3}\right)  \left(  4\tau\right)  \mathrm{d}\tau\\
&  =\int_{0}^{\frac{\sqrt{2}}{2}} \left(
16\,{\tau}^{12}+48\,{\tau}^{10}+48\,{\tau}^{8}+16\,{\tau}^{6}+48\,{
\tau}^{5}\right)  \mathrm{d}\tau= 1+\frac{9305}{24024}\sqrt{2} \,.
\end{align*}
Y la segunda:
\[
\int_{\left(  0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt{2}\right)}6xy\ \mathrm{d}y=\int_{0}^{\frac{\sqrt{2}}{2}}6\left(  2\tau^{2}\right)\left(  \tau^{3}+\tau\right)  \left(  3\tau^{2}+1\right)  \mathrm{d}\tau \,,
=\frac{65}{32} \,,
\]
con lo cual:
\[
\int_{\left(  0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }{\bf F}\left(  {\bf r}\right) \cdot
\mathrm{d}{\bf r}=\int_{\left(  0,0\right)
}^{\left(  1,\frac{3}{4}\sqrt{2}\right)  }\left(  3x^{2}+2xy^{3}\right)
\ \mathrm{d}x+\int_{\left(  0,0\right)  }^{\left(  1,\frac{3}{4}\sqrt
{2}\right)  }6xy\ \mathrm{d}y=\frac{97}{32}+\frac{9305}{24024}\sqrt{2}\,.
\]

\item  El campo de fuerzas de un oscilador anisótropo bidimensional se escribe como:
\[
{\bf F} = -k_{1}x^{2} {\bf i} + k_{2}y {\bf j}\,.
\]
Encontremos el trabajo realizado 
\[
\int^{(x_{2},y_{2})}_{(x_{1},y_{1})} {\bf F} \cdot \mathrm{d}{\bf r} \,,
\] 
a  lo largo de las siguientes trayectorias:

\begin{enumerate}
\item $(1,1) \rightarrow (4,1) \rightarrow (4,4)$
\[
\int^{(4,1)}_{(1,1)} \; ({\bf i}\mathrm{d}x ) \cdot (-k_{1}x^{2} {\bf i} + k_{2}{\bf j}) + 
\int^{(4,4)}_{(4,1)} \; ({\bf j}\mathrm{d}y ) \cdot (-k_{1}16 {\bf i} + k_{2}y {\bf j})  = 
-21k_{1} +\frac{15k_{2}}{2} \,.
\]   
     
\item $(1,1) \rightarrow (1,4) \rightarrow (4,4)$ 
\[
\int^{(1,4)}_{(1,1)} \; ({\bf j}\mathrm{d}y ) \cdot (-k_{1} {\bf i} + k_{2}y {\bf j})  +
\int^{(4,4)}_{(1,4)} \; ({\bf i}\mathrm{d}x ) \cdot (-k_{1}x^{2} {\bf i} + k_{2} 4 {\bf j}) = 
-21k_{1} +\frac{15k_{2}}{2} \,.
\] 

\item $(1,1) \rightarrow (4,4)$ siguiendo la recta $x=y$ 
\[
\int^{(4,4)}_{(1,1)} \; ({\bf i}\mathrm{d}x + {\bf j}\mathrm{d}x ) \cdot (-k_{1}x^{2}  {\bf i} + k_{2}x {\bf j}) =
\int^{(4,4)}_{(1,1)} \;  (-k_{1}x^{2}  + k_{2}x )\mathrm{d}x  =
-21k_{1} +\frac{15k_{2}}{2} \,.
\] 
\end{enumerate}

Dejamos al lector que calcule el trabajo para la trayectoria $y=x^2$.

\end{enumerate}

\newpage

\subsection{{\color{red}Practicando con Maxima}}
\begin{enumerate}
\item {\bf Maxima} nos permite hacer cálculos con el operador ${\boldsymbol \nabla} $ en coordenadas cartesianas, más adelante veremos que también es posible en otros sistemas de coordenadas. Los operadores que se pueden expresar son: {\bf grad}(gradiente), {\bf div} (divergencia), {\bf curl} (rotacional), {\bf laplacian} (laplaciano). Debemos hacer uso de la librería {\bf vect} para poder utilizar los operadores diferenciales. 

Por otro lado, se debe usar también de función {\bf express}(expr) para transformar los nombres de los operadores diferenciales en expresiones que contienen derivadas parciales y con la función {\bf ev} evaluamos la expresión. Veamos como se hace si queremos calcular el gradiente de la siguiente función:

\[
f=\frac{x^2+y^2}{(x^2+y^2+z^2)^{1/2}}\,.
\]

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
load(vect)$
\end{verbatim}}
\end{minipage}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
f:(x^2+y^2)/(x^2+y^2+z^2)^(1/2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
grad(f);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
\mbox{grad}\left(\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}\right)
\end{math}
\newline

Estaremos haciendo uso del  símbolo $\%$ que representa la última 
expresión de salida, de esta manera nos ahorramos estar escribiendo nuevamente el último resultado en la nueva linea de entrada.  

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
express(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
\left[ \frac{d}{d\,x}\,\left(\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}
 \right) , \frac{d}{d\,y}\,\left(\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}
 \right) , \frac{d}{d\,z}\,\left(\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}
 \right) \right] 
\end{math}
\newline

Notemos que el resultado anterior es una lista del tipo $[x,y,z]$, que es la manera como el programa maneja los vectores. En este caso, el primer elemento de la lista es la componente $x$ del vector gradiente. De la misma manera para las componentes $y$ y $z$. Evaluamos las derivadas de la última salida:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ev(%, diff);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
\left[ \frac{2\,x}{\sqrt{z^2+y^2+x^2}}-\frac{x\,\left(y^2+x^2
 \right)}{\left(z^2+y^2+x^2\right)^{\frac{3}{2}}} , \frac{2\,y}{
 \sqrt{z^2+y^2+x^2}}-\frac{y\,\left(y^2+x^2\right)}{\left(z^2+y^2+x^2
 \right)^{\frac{3}{2}}} , -\frac{\left(y^2+x^2\right)\,z}{\left(z^2+y
 ^2+x^2\right)^{\frac{3}{2}}} \right] 
\end{math}
\newline

En este punto podemos intentar simplificar las expresiones anteriores, esto lo hacemos con el comando {\bf ratsimp} y así obtener finalmente el vector gradiente:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ratsimp(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
\left[ \frac{\sqrt{z^2+y^2+x^2}\,\left(2\,x\,z^2+x\,y^2+x^3\right)
 }{z^4+\left(2\,y^2+2\,x^2\right)\,z^2+y^4+2\,x^2\,y^2+x^4} , \frac{
 \sqrt{z^2+y^2+x^2}\,\left(2\,y\,z^2+y^3+x^2\,y\right)}{z^4+\left(2\,
 y^2+2\,x^2\right)\,z^2+y^4+2\,x^2\,y^2+x^4} , -\frac{\left(y^2+x^2
 \right)\,z}{\left(z^2+y^2+x^2\right)^{\frac{3}{2}}} \right] 
\end{math}
\newline

Hagamos uso de los otros operadores. Por ejemplo, dado el vector:
\[
{\bf a} = \frac{x^2}{x^2+y^2}{\bf i}+\frac{y^2}{x^2+y^2}{\bf j}+\frac{z^2}{x^2+y^2}{\bf k}\,,
\]
calculemos la divergencia, ${\boldsymbol \nabla} \cdot {\bf a}$. Esta vez combinaremos algunos comandos en una misma linea.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:[x^2/(x^2+y^2),y^2/(x^2+y^2),z^2/(x^2+y^2)];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
\left[ \frac{x^2}{y^2+x^2} , \frac{y^2}{y^2+x^2} , \frac{z^2}{y^2+x
 ^2} \right]
\end{math}
\newline

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
express(div (a));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
\frac{d}{d\,z}\,\left(\frac{z^2}{y^2+x^2}\right)+\frac{d}{d\,y}\,
 \left(\frac{y^2}{y^2+x^2}\right)+\frac{d}{d\,x}\,\left(\frac{x^2}{y^
 2+x^2}\right)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i9) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ev (%, diff),ratsimp;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o9) }
\frac{\left(2\,y^2+2\,x^2\right)\,z+2\,x\,y^2+2\,x^2\,y}{y^4+2\,x^2
 \,y^2+x^4}
\end{math}
\newline

Calculemos ahora el rotor de {\bf a}, ${\boldsymbol \nabla} \times {\bf a}$, pero combinado más comandos en una sola instrucción:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ev(express(curl(a)),diff);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10) }
\left[ -\frac{2\,y\,z^2}{\left(y^2+x^2\right)^2} , \frac{2\,x\,z^2
 }{\left(y^2+x^2\right)^2} , \frac{2\,x^2\,y}{\left(y^2+x^2\right)^2}
 -\frac{2\,x\,y^2}{\left(y^2+x^2\right)^2} \right]
\end{math}
\newline

Intentemos simplificar nuevamente para ver lo que ocurre:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ratsimp(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
\left[ -\frac{2\,y\,z^2}{y^4+2\,x^2\,y^2+x^4} , \frac{2\,x\,z^2}{y^
 4+2\,x^2\,y^2+x^4} , -\frac{2\,x\,y^2-2\,x^2\,y}{y^4+2\,x^2\,y^2+x^4
 } \right] 
\end{math}
\newline

Finalmente, calculemos  el laplaciano de $f$, ${\boldsymbol \nabla}^2  f$, todo en una sola instrucción 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i12) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ratsimp(ev(express(laplacian(f)),diff));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o12) }
\frac{4\,z^2}{\left(z^2+y^2+x^2\right)^{\frac{3}{2}}}
\end{math}
\newline

Podemos verificar rapidamente que: ${\boldsymbol \nabla}^2  f={\boldsymbol \nabla} \cdot {\boldsymbol \nabla} f$

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i13) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
div(grad(f));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
\mbox{div}\left(\mbox{grad}\left(\frac{y^2+x^2}{\sqrt{z^2+y^2+x^2}}
 \right)\right)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i14) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ratsimp(ev(express((%)),diff));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o14) }
\frac{4\,z^2}{\left(z^2+y^2+x^2\right)^{\frac{3}{2}}}
\end{math}
\newline

\item {\bf Maxima} integra simbólicamente funciones por medio del comando {\bf integrate}$(expr, x, a, b)$. Esto es, calcula la integral definida de la  $expr$ respecto de $x$ con los límites de integración $a$ y $b$. Si se omiten los límites de integración se calcula la integral indefinida. 

Por ejemplo, si queremos calcular la integral:
\[
\int a \ \mbox{sen}(x+b)^3 \mathrm{d}x \,.
\]
Escribimos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i15) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
integrate(a*sin(x+b)^3,x);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o15) }
a\,\left({{\cos ^3\left(x+b\right)}\over{3}}-\cos \left(x+b\right) \right)
\end{math}
\newline

Calculemos ahora  el área de la región comprendida entre las funciones:
\[ 
f(x) = x^3-3x^2 + 1 \quad \mbox{y} \quad g(x) = -x+ 1 \,.
\]
Es decir, vamos a calcular la integral:
\[
\int_{a}^b [f(x)- g(x)] \mathrm{d}x \,.
\]

Aprovecharemos este ejercicio para aprender, entre otras cosas, a graficar y definir funciones. Primero que todo, debemos introducir al programa las dos funciones y a diferencia de los cálculos anteriores, usaremos $:=$ para definirlas.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i16) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
f(x):=x^3-3*x^2+1; g(x):=-x+1;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o16) }
f(x):=x^3-3*x^2+1
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o17) }
g(x):=-x+1
\end{math}
\newline

La diferencia de estas dos funciones la podemos llamar la función $d(x)$. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i18) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
d(x):=f(x)-g(x);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o18) }
d(x):=f(x)-g(x)
\end{math}
\newline

Haremos la gráfica de las dos funciones. {\bf Maxima} permite hacer gráficos en 2D con el comando {\bf plot2d}. Pero aquí utilizaremos una variante y haremos el gráfico con el comando  {\bf wxplot2d} para que la figura aparezca embebida dentro de nuestra hoja de cálculo. 

Es necesario introducir las funciones como una lista, es decir, dentro de corchetes. Por otra parte, le pediremos al programa que grafique para los valores comprendidos de: $-1\leq x\leq3$. 

Posteriormente, necesitaremos encontrar los puntos donde las funciones se interceptan. Para este fin, utilizaremos el comando {\bf solve}, que resuelve la ecuación algebraica  y devuelve una lista de igualdades con las variables despejadas. Si la expresión a resolver no es una igualdad, se supone que se quiere resolver la ecuación ya igualada a cero. 

Entonces, para graficar las funciones $f(x)$ y $g(x)$ entre $[-1,3]$ escribimos el siguiente comando:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i19) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
wxplot2d([f(x),g(x)],[x,-1,3]);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o19) }
\end{math}
\begin{figure}[h]
\begin{center}
\includegraphics[height=2.6in,width=4.5in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_9aMax}
\end{center}
\end{figure}
\newline

Calculemos los puntos donde se interceptan las curvas:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i20) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
solve(f(x)-g(x),x);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o20) }
\left[ x=-\frac{\sqrt{5}-3}{2} , x=\frac{\sqrt{5}+3}{2} , x=0 \right] 
\end{math}
\newline

Los valores numéricos son:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i21) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
float(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o21) }
\left[ x=0.3819660112501051 , x=2.618033988749895 , x=0.0 \right] 
\end{math}
\newline

Procedemos ahora sí a integrar la función diferencia para encontrar el área contenida dentro de las dos funciones. En este caso será la integral:
\[
A=\int_{0}^{-\frac{\sqrt{5}-3}{2}} d(x) \ \mathrm{d}x + 
\int_{-\frac{\sqrt{5}-3}{2}}^{\frac{\sqrt{5}-3}{2}} (-d(x)) \ \mathrm{d}x \,.
\]

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i22) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
integrate(d(x),x,0,-(sqrt(5)-3)/2)+integrate(-d(x),x,-(sqrt(5)-3)/2,(sqrt(5)+3)/2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o22) }
\frac{5^{\frac{3}{2}}+11}{8}+\frac{5^{\frac{3}{2}}-11}{4}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i23) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
float(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o23) }
2.817627457812107
\end{math}
\newline

\item Calculemos ahora las dos integrales que aparecen en el ejemplo 8 de \ref{EjemDerVectores}. Es decir las integrales:
\[
\int_{\left(0,0\right)}^{\left(1,\frac{3}{4}\sqrt{2}\right)}
\left(3x^{2}+2xy^{3}\right)  \ \mathrm{d}x \,,\qquad 
\int_{\left(0,0\right)}^{\left(1,\frac{3}{4}\sqrt{2}\right)}6xy\ \mathrm{d}y\,.
\]
donde hicimos los cambio de variables: $
x=2\tau^{2}\,,\,\, y=\tau^{3}+\tau \,\, \Rightarrow \,\,
\mathrm{d}x =4\tau \mathrm{d}\tau \,, \,\,
\mathrm{d}y=(3\tau^{2}+1) \mathrm{d}\tau \,.
$

Escribiremos primero los dos integrandos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i24) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
int1:(3*x^2+2*x*y^3)*dx; int2:6*x*y*dy;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o24) }
{\it dx}\,\left(2\,x\,y^3+3\,x^2\right)
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o25) }
6\,{\it dy}\,x\,y
\end{math}
\newline

Realizaremos el cambio de variable a través de comando {\bf subst} que nos permite sustituir expresiones dentro de otras:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i26) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
e1:subst([x=2*t^2,dx=4*t,y=t^3+t,dy=3*t^2+1],int1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o26) }
4\,t\,\left(4\,t^2\,\left(t^3+t\right)^3+12\,t^4\right)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i27) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
e2:subst([x=2*t^2,dx=4*t,y=t^3+t,dy=3*t^2+1],int2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o27) }
12\,t^2\,\left(3\,t^2+1\right)\,\left(t^3+t\right)
\end{math}
\newline

Podemos introducir las integrales sin evaluarlas en el momento, esto se consigue mediante el operador de comilla simple. En este caso la función no es evaluada y devuelve una expresión simbólica o imagen pictórica. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i28) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
int1:'integrate(e1,t,0,sqrt(2)/2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o28) }
4\,\int_{0}^{\frac{1}{\sqrt{2}}}{t\,\left(4\,t^2\,\left(t^3+t
 \right)^3+12\,t^4\right)\;dt}
\end{math}
\newline

Ahora si evaluamos la integral:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i29) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ev(int1,integrate),expand;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o29) }
\frac{9305}{3003\,2^{\frac{5}{2}}}+1
\end{math}
\newline

Y para la segunda integral:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i30) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
int2:'integrate(e2,t,0,sqrt(2)/2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o30) }
12\,\int_{0}^{\frac{1}{\sqrt{2}}}{t^2\,\left(3\,t^2+1\right)\,
 \left(t^3+t\right)\;dt}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i31) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ev(int2,integrate),expand;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o31) }
\frac{65}{32}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i32) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
kill(all)$
\end{verbatim}}
\end{minipage}
\newline

\item Para finalizar, aclaremos la diferencia entre asignar  una expresión a una variable y la definición de funciones. 
Consideremos el movimiento de una partícula que sigue la trayectoria: 
\[
x=x_0+v_0 t +\frac12 at^2 \,.
\]

Primero escribiremos la expresión y se la asignamos a una variable que llamaremos $x$.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x:x0+v0*t+a*t^2/2;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o1) }
{ x_0}+t\,{v_0}+\frac{a\,t^2}{2}
\end{math}
\newline

Si queremos evaluarla para algún valor de la variable $t$, digamos $t=1$, entonces podemos escribir:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
subst(t=1,x);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
{ x_0}+{ v_0}+\frac{a}{2}
\end{math}
\newline

Si queremos evaluar la expresión con el resto de parámetros, entonces:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i3) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
subst([t=1,a=-9.8,x0=0,v0=10],x);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
5.1
\end{math}
\newline

Las sustituciones se realizan pero no se asignan a las variables.  Podemos ver que $x$ sigue siendo lo que le asignamos originalmente.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
{ x_0}+t\,{ v_0}+\frac{a\,t^2}{2}
\end{math}
\newline

Ahora definamos la expresión anterior pero como la función $x(t)$.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x(t):=x0+v0*t+a*t^2/2;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
x(t):=x_0+v_0 t+a \frac{t^2}{2}
\end{math}
\newline

Evaluarla es ahora más sencillo:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x(1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
{ x_0}+{ v_0}+\frac{a}{2}
\end{math}
\newline

También podemos escribir:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
subst([a=-9.8,x0=0,v0=10],x(1));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
5.1
\end{math}
\newline

Si queremos asignarle los valores a los parámetros de manera global, entonces escribimos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:-9.8$ x0:0$ v0:10$
\end{verbatim}}
\end{minipage}
\newline

De manera que:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x(1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
5.1
\end{math}
\newline

Para limpiar los parámetros que acabamos de asignar hacemos lo siguiente:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i12) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
kill(a,v0,x0)$
\end{verbatim}}
\end{minipage}
\newline

Por lo tanto:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i13) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
x(1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
{ x_0}+{ v_0}+\frac{a}{2}
\end{math}
\newline

La velocidad y la aceleración son funciones fáciles de calcular:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i14) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
'diff(x(t),t)=diff(x(t),t);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o14) }
\frac{d}{d\,t}\,\left({ x_0}+t\,{ v_0}+\frac{a\,t^2}{2}
 \right)={ v_0}+a\,t
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i15) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
'diff(x(t),t,2)=diff(x(t),t,2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o15) }
\frac{d^2}{d\,t^2}\,\left({ x_0}+t\,{ v_0}+\frac{a\,t^2}{2} \right)=a
\end{math}
\newline

En el caso de que estemos interesados en definir una nueva función a partir de algún cálculo anterior podemos utilizar la función  {\bf define}. 

Entonces, lo que vamos a hacer, en las siguientes lineas de comandos, es definir la función velocidad a partir de la derivada de la posición. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i16) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
diff(x(t),t);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o16) }
{v_0}+a\,t
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i17) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
define(v(t),%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o17) }
v(t):=v0+at
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i18) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
v(1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o18) }
v0+a
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i19) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
subst([a=-9.8,x0=0,v0=10],v(1));
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o19) }
0.1999999999999993
\end{math}
\newline

\item Cuando necesitemos manejar campo vectoriales podemos utilizar las listas. Veamos el primer ejemplo de \ref{EjemDerVectores} donde:
\[ 
{\bf r}=3t^2 {\bf i}+(4t^3-t){\bf j}+t{\bf k} \,.
\]

Escribamos el vector posición:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i20) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
[x,y,z]:[3*t^2,4*t^3-t,t];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o20) }
\left[ 3\,t^2 , 4\,t^3-t , t \right]
\end{math}
\newline

La velocidad:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i21) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
v:diff([x,y,z],t);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o21) }
\left[ 6\,t , 12\,t^2-1 , 1 \right] 
\end{math}
\newline

La aceleración:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i22) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
a:diff([x,y,z],t,2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o22) }
\left[ 6 , 24\,t , 0 \right]
\end{math}
\newline

Podemos facilmente calcular: 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i23) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
v.[bx,by,bz];
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o23) }
{ by}\,\left(12\,t^2-1\right)+6\,{ bx}\,t+{ bz}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i24) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
solve(%,bz);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o24) }
\left[ { bz}=-12\,{ by}\,t^2-6\,{ bx}\,t+{ by} \right] 
\end{math}

\end{enumerate}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}
\begin{enumerate}
\item Demuestre que:
\begin{enumerate}
\item 
$
\frac{\mathrm{d}}{\mathrm{d} t}\left[ \mathbf{a} \cdot \left( \mathbf{b}\times \mathbf{c} \right) \right] = 
 \frac{\mathrm{d}\mathbf{a} }{\mathrm{d} t}\cdot\left( \mathbf{b}\times \mathbf{c} \right)  + \mathbf{a}\cdot \left( \frac{\mathrm{d}\mathbf{b} }{\mathrm{d} t}\times \mathbf{c} \right) +\mathbf{a}\cdot \left(\mathbf{b} \times \frac{\mathrm{d}\mathbf{c} }{\mathrm{d} t} \right)
$
\item 
$
\frac{\mathrm{d}}{\mathrm{d} t}\left[ \mathbf{a} \cdot \left( \frac{\mathrm{d}\mathbf{a} }{\mathrm{d} t}\times 
\frac{\mathrm{d}^2\mathbf{a} }{\mathrm{d} t^2}  \right) \right] = 
\mathbf{a}\cdot \left( \frac{\mathrm{d}\mathbf{a} }{\mathrm{d} t}\times 
\frac{\mathrm{d}^3\mathbf{a} }{\mathrm{d} t^3}  \right) 
$
\item 
$
{\boldsymbol \nabla}\times ({\boldsymbol \nabla}\times {\bf a}) =
{\boldsymbol \nabla}{\boldsymbol \nabla}\cdot {\bf a}-
{\boldsymbol \nabla}\cdot {\boldsymbol \nabla}{\bf a}
$
\item 
$
{\boldsymbol \nabla}\times (\phi{\boldsymbol \nabla}\phi)=0
$
\item 
$
{\boldsymbol \nabla}\times [ {\bf a}\times
({\boldsymbol \nabla}\times {\bf a})]=0
$, si $ {\bf a}= a_x(y,z){\bf i}$.
\end{enumerate}

\item Considere que: 
   \begin{itemize}
  \item ${\bf r}  =x\ \mathbf{{\bf i}}+y\ \mathbf{{\bf j}}+z\ \mathbf{{\bf k}}= x^{i}\mathbf{{i}}_{i}$,
  \item ${\bf a} = {\bf a}({\bf r}) = {\bf a}(x,y,z) = a^{i}(x,y,z) {\bf i}_{i} \,\, $  \mbox{y} $ {\bf b} = {\bf b}({\bf r}) =  {\bf b}(x,y,z) = b^{i}(x,y,z) {\mathbf{{i}}}_{i}$,
  \item $\phi = \phi({\bf r}) = \phi(x,y,z) \quad$ y $\,\, \psi = \psi({\bf r}) = \psi(x,y,z)$. 
\end{itemize} 

Utilizando la notación de índices, e inspirándose en las secciones: \ref{ParCalculos}, \ref{VectorGradiente} y \ref{EjemDerVectores}, demuestre las siguientes identidades vectoriales: 
  \begin{enumerate}
  \item ${\boldsymbol \nabla}(\phi \psi) = \phi {\boldsymbol \nabla}\psi + \psi {\boldsymbol \nabla}\phi$.
  \item ${\boldsymbol \nabla} \cdot (\phi {\bf a}) = \phi {\boldsymbol \nabla} \cdot {\bf a}  + ({\boldsymbol \nabla}\phi)  \cdot {\bf a} $.
  \item ${\boldsymbol \nabla} \times {\boldsymbol \nabla}\phi = 0 $.
  \item $ {\boldsymbol \nabla} \cdot ({\boldsymbol \nabla} \times {\bf a})$  ¿Qué puede decir de $ {\boldsymbol \nabla} \times ({\boldsymbol \nabla}  \cdot {\bf a})$?
  \item ${\boldsymbol \nabla} \cdot ( {\bf a} \times {\bf b}) = ({\boldsymbol \nabla}  \times {\bf a})  \cdot {\bf b} -   {\bf a} \cdot  ({\boldsymbol \nabla}  \times {\bf b})$.
  \item ${\boldsymbol \nabla} \times ( {\boldsymbol \nabla} \times  {\bf a} ) = {\boldsymbol \nabla}(  {\boldsymbol \nabla}  \cdot {\bf a} ) - {\boldsymbol \nabla}^{2} {\bf a} $ .   
\end{enumerate}

\item Para los vectores dados a continuación, encuentre $d{\bf r}/ds$
\begin{enumerate}
\item ${\bf r} = t{\bf i}+3t^2{\bf j}-(t -1){\bf k}$, y $t = \ln(1+s^2)$.
\item ${\bf r} = \mbox{sen}(t){\bf i}+\cos(t){\bf j}+\tan(t){\bf k}$,  y $t = 2+s^2$.
\end{enumerate}

\item Una partícula describe un movimiento dado por el vector posición ${\bf r}$. Encuentre la componente de su velocidad en la dirección del vector indicado:
\begin{enumerate}
\item ${\bf r} = t^2{\bf i}+4\cos(2t){\bf j}+3\mbox{sen}(2t){\bf k},\quad$  
$2{\bf i}+{\bf j}+2{\bf k}$.
\item ${\bf r} = 3\cos(t){\bf i}+3\mbox{sen}(t){\bf j}+(t^2-2){\bf k},\quad$   
${\bf i}+2{\bf j}-{\bf k}$.
\end{enumerate}

\item Si {\bf u}, {\bf v} y {\bf w} son funciones que dependen del parámetro $t$, demuestre que:
\begin{enumerate}
\item 
$\frac{\mathrm{d}}{\mathrm{d}t}\left[{\bf u}\cdot({\bf v}\times{\bf w})\right] ={\bf u}\cdot \left({\bf v}\times \frac{\mathrm{d}{\bf w}}{\mathrm{d}t} \right)+{\bf u}\cdot \left(\frac{\mathrm{d}{\bf v}}{\mathrm{d}t}\times {\bf w} \right)+\frac{\mathrm{d}{\bf u}}{\mathrm{d}t}\cdot({\bf v}\times{\bf w})$.  
\item $\frac{\mathrm{d}}{\mathrm{d}t}\left[{\bf u}\times({\bf v}\times{\bf w})\right] ={\bf u}\times \left({\bf v}\times \frac{\mathrm{d}{\bf w}}{\mathrm{d}t} \right)+{\bf u}\times \left(\frac{\mathrm{d}{\bf v}}{\mathrm{d}t}\times {\bf w} \right)+\frac{\mathrm{d}{\bf u}}{\mathrm{d}t}\times({\bf v}\times{\bf w})$.
\end{enumerate}

\item Si ${\bf u} = 2t{\bf i}-t^2{\bf j}+{\bf k}$, ${\bf v}= 2{\bf i}+3t{\bf j}+t{\bf k}$ y ${\bf w} = t{\bf i}+2t{\bf j}-t{\bf k}$. Utilice el resultado del ejercicio (a) anterior para encontrar: $\frac{\mathrm{d}}{\mathrm{d}t}\left[{\bf u}\cdot({\bf v}\times{\bf w})\right]$.

\item Si ${\bf u} = t{\bf i}-t{\bf j}+t^2{\bf k}$, ${\bf v}= -t{\bf i}+2t{\bf j}-t^2{\bf k}$ y ${\bf w} = 2t{\bf i}-2t{\bf j}+t{\bf k}$. Utilice el resultado del ejercicio (b) anterior para encontrar: $\frac{\mathrm{d}}{\mathrm{d}t}\left[{\bf u}\times({\bf v}\times{\bf w})\right]$.


\item Encuentre el gradiente de los siguientes campos:
\begin{enumerate}
\item $\phi(x,y,z)= x^2+3xyz-yz^2 $.
\item $\phi(x,y,z)= \left(x^2 + 2y^2 + 4z^2\right)^{-1} $.
\end{enumerate}

\item Encuentre la divergencia de los siguientes campos:
\begin{enumerate}
\item ${\bf a} (x,y,z)=x^2y{\bf i}+y^2z^2{\bf j}+xz^3{\bf k} $.
\item ${\bf a} (x,y,z)=(1-x^2){\bf i}+\mbox{sen}(yz){\bf j}+e^{xyz}{\bf k}$.
\end{enumerate}

\item Encuentre el rotor de los siguientes campos:
\begin{enumerate}
\item ${\bf a} (x,y,z)=xyz^2{\bf i}+x^2yz{\bf j}+xy^2{\bf k} $.
\item ${\bf a} (x,y,z)=\mbox{senh}(xy){\bf i}+\cosh(yz){\bf j}+xyz{\bf k} $.
\end{enumerate}

\item Evalúe las siguientes integrales:
\begin{enumerate}
\item $\int \left(t \mbox{sen}(t){\bf i}+2t^2{\bf j}-7t{\bf k}\right) \mathrm{d}t$.
\item $\int \left( \mbox{cosh}^2(t){\bf i}+2\mbox{sen}^2(2t){\bf j}-{\bf k}\right) \mathrm{d}t$.
\end{enumerate}


\item Un campo de fuerza: 
\[
{\bf F}= -kx{\bf i}-ky{\bf j} \,,
\]
actúa sobre un oscilador.  Compare el trabajo hecho al moverse en contra de este campo al ir desde el punto $(1,1)$ al punto $(4,4)$, siguiendo los siguientes caminos:
\[
{a)} \,\, (1,1) \rightarrow (4,1) \rightarrow (4,4).\quad 
{b)} \,\, (1,1) \rightarrow (1,4) \rightarrow (4,4).\quad 
{c)} \,\, (1,1) \rightarrow (4,4), \,\, \mbox{siguiendo el camino:}  \,\, x=y.
\]

\item Dado el campo de fuerza:  
\[
{\bf F}= -\frac{y}{x^2+y^2}{\bf i}+\frac{x}{x^2+y^2}{\bf j}\,. 
\]
Calcule el trabajo hecho en contra de este campo de fuerza  al moverse al rededor de un circulo de radio uno y en el plano $x-y$.
\begin{enumerate}
\item desde $0$ a $\pi$ en sentido contrario a la agujas del reloj.
\item desde $0$ a $-\pi$ en sentido de las agujas del reloj. 
\end{enumerate}

\item Evaluar la siguiente integral:
\[
\oint {\bf r}\cdot \mathrm{d}{\bf r}\,.
\]

 \item Una partícula se mueve bajo la ley ${\bf r}(t) = x(t){\bf i} + y(t){\bf j} +z(t){\bf k}$, con: 
 \[
 x(t) = 2t^{2}; \quad  y(t) = t^{2} -4t; \quad  z(t) = 3t -5.
 \]
El parámetro $t$ representa el tiempo. 

Encuentre las expresiones para la aceleración y la velocidad de la partícula, para $t=1$ y en la dirección del vector ${\bf i} -3{\bf j}+2{\bf k}$. 

\item Suponga ahora el caso general de una partícula que se mueve en una curva descrita por: 
\[
{\bf r}(t) = x(t){\bf i} + y(t){\bf j} +z(t){\bf k}\,.
\]
Muestre que el vector velocidad es tangente a la trayectoria descrita. 
 
 \item Encuentre la ecuación vectorial para una trayectoria recta que pasa por los puntos $P \rightarrow (1, 2, 3)$ y $Q \rightarrow (1, 1, 1)$.

\item Encuentre el ángulo entre los siguientes planos: $x + y +z = 9$ y  $x + y -z = 3$.  

\item Un fluido se considera irrotacional si su campo de velocidades ${\bf v}={\bf v}({\bf r}) ={\bf v}(x,y,z)$ cumple con la  ecuación: $ {\boldsymbol \nabla} \times  {\bf v} =0$. Suponga, ahora que: ${\bf v} = (x +2y +az){\bf i} +(bx -3y -z){\bf j} +(4x +cy +2z){\bf k}$.
 \begin{enumerate}
  \item Encuentre el valor de $a, b$ y $c$ para que este campo de velocidades sea irrotacional.
  
  \item Es intuitivo convencerse que si $ {\boldsymbol \nabla} \times  {\bf v} =0 \,\, \Rightarrow \,\, {\bf v} = {\boldsymbol \nabla} \psi $. Encuentre la expresión para la función potencial $ \psi = \psi({\bf r}) = \psi(x,y,z)$.
  
  \item Considere la siguiente integral: $I = \int_{\mathcal{C}} \; \mathrm{d} {\bf r} \cdot {\bf v}$. Donde $\mathcal{C}$ es el circuito a recorrer. 
  \begin{enumerate}
  \item Calcule el valor de la integral $I$ a lo largo del  trayecto: $(0,0,0) \rightarrow (1,1,0)$ mediante una segmento de recta. Luego, de $ (1,1,0) \rightarrow (2,0,0)$ a lo largo de otro segmento de recta. Finalmente regresando $(2,0,0) \rightarrow (0,0,0)$ también siguiendo una recta.
  \item Calcule el valor de la integral $I$ de $ (0,0,0) \rightarrow (2,0,0)$ a lo largo de un arco de circunferencia que cumple con la ecuación: $(x-1)^{2} + y^{2} =1$. Ahora regresando de $(2,0,0) \rightarrow (0,0,0)$ también a través de una recta.
  \item ¿Qué puede concluir del campo ${\bf v}$?
\end{enumerate}
\end{enumerate}

\item Resuelva todos los problemas anteriores utilizando {\bf Maxima}.

\end{enumerate}

\section{Vectores y números complejos}
\label{VectoresNumerosComplejos}
\index{Números complejos!Vectores 2D}
\index{Vectores 2D!Números complejos}
Desde los primeros cursos de matemática nos hemos tropezado con las llamadas raíces imaginarias o complejas de
polinomios. La solución a un polinomio cúbico: 
\[
x^{3}-3x^{2}+4x-12=0\,\, \Rightarrow \,\,  \left\{
\begin{array}
[c]{c}
x=2i\\
x=-2i\\
x=3
\end{array}
\right\}  \,\, \Rightarrow \,\,  \left(  x+2i\right)  \left(  x-2i\right)
\left(  x-3\right)  =0 \,,
\]
o cuadrático:
\[
x^{2}+4=0\,\, \Rightarrow \,\,   \left\{
\begin{array}
[c]{c}
x=2i\\
x=-2i
\end{array}
\right\} \,\, \Rightarrow \,\,  \left( x+2i\right)  \left(  x-2i\right)=0\,.
\]
nos lleva a definir un número $i^{2}\equiv-1$. 

De lo anterior podemos ver que al multiplicar el número imaginario $i$ por cualquier número real obtendremos el número imaginario puro  $i b$, con $b \in \mathds{R}$. La nomenclatura  de números imaginarios surgió de la idea de que estas cantidades no representaban mediciones físicas. Esa idea ha sido abandonada pero el nombre quedó\footnote{Los números complejos comienzan a aparecer en los trabajos de Cardano (1501-1576) y Bombelli (1526-1672) mientras estudiaban las raíces de la ecuación cúbica . Pero es a René Descartes (1596-1650) a quién se le atribuye la afirmación: ``ciertas ecuaciones algebraicas sólo tienen solución en nuestra imaginación'' y utilizó el término ``números imaginarios''. 
Caspar Wessel en 1799 y Jean-Robert Argand en 1806 proponen la estructura del plano complejo y la representación de la unidad imaginaria como el punto $(0,1)$ del eje vertical de dicho plano. Pero el término, hoy usado de ''números complejos'' se debe a Johann Carl Friedrich Gauss (1777-1855).}.

Es importante señalar aquí, que suele tomarse de la definición $i^{2}\equiv-1$ que $i=\sqrt{-1}$. Pero si hacemos esto, sin pensarlo bien, llegamos a que: $-1=i^{2}=i i=\sqrt{-1}\sqrt{-1}=\sqrt{1}=1$. La contradicción surge por el hecho de que aquí el $-1$ no es un número real sino un número complejo y será evidente más adelante cuando desarrollemos el algebra de los números complejos.


\subsection{Los números complejos y su álgebra}
\label{NumerosComplejosAlgebra}
\index{Números complejos!Álgebra}
\index{Álgebra de números complejos}
Un número complejo, $z,$ es la generalización de los números imaginarios (puros), $ib$. Esto es:
\[
z=a+ib\quad\quad\text{con }a,b \in \mathds{R} \,\,  \Rightarrow \,\,  
\left\{
\begin{array}
[c]{l}
a\rightarrow\quad\text{parte real}\\
b\rightarrow\quad\text{parte imaginaria}
\end{array}
\right.
\]

Obviamente los números reales serán $a+i0$ números complejos con su parte imaginaria nula. Los números imaginarios puros serán números complejos con su parte real nula, esto es, $0+ib.$ Por ello, en general diremos que:
\[
z=a+ib \,\,  \Rightarrow \,\, a=\operatorname{Re}\left(  z\right)  \quad
\wedge\quad b=\operatorname{Im}\left(  z\right)\,,
\]
es decir, $a$ corresponde a la parte real de $z$ y $b$ a su parte imaginaria. 

Cada número complejo, $z$ tendrá asociado un número complejo conjugado,
$z^{\ast}$ tal que:
\begin{gather*}
z=a+ib\quad\rightleftharpoons\quad z^{\ast}=a-ib \,, \\
\Downarrow\\
\left(  z^{\ast}\right)  ^{\ast}=z\quad\wedge\quad z\cdot z^{\ast}=a^{2}+b^{2}\,,
\end{gather*}
claramente:
\[
z\cdot z^{\ast}\geq0 \,\,  \Rightarrow \,\, \left|  z\right|  ^{2}=\left|
z^{\ast}\right|  ^{2}=z\cdot z^{\ast}=a^{2}+b^{2} \,.
\]

Es importante señalar que, en general, no existe relación de orden entre los números complejos. Vale decir, que no sabremos si un número complejo es mayor que otro. No está definida esta operación.
\[
z_{1}\ngtr z_{2}\quad\vee\quad z_{1}\nless z_{2} \,.
\]

Las relaciones de orden sólo se podrán establecer entre módulos de números complejos y no números complejos en general.

Rápidamente recordamos el álgebra de los números complejos:

\begin{itemize}
\item  Dos números complejos serán iguales si sus partes reales e
imaginarios lo son:
\[
z_{1}=z_{2} \,\, \Rightarrow \,\, \left(  a_{1}+ib_{1}\right)  =\left(
a_{2}+ib_{2}\right)  \,\, \Rightarrow \,\, a_{1}=a_{2}\quad\wedge\quad
b_{1}=b_{2} \,.
\]

\item  Se suman dos números complejos sumando sus partes reales y sus partes imaginarias:
\[
z_{3}=z_{1}+z_{2} \,\,  \Rightarrow \,\, \left(  a_{1}+ib_{1}\right)  +\left(
a_{2}+ib_{2}\right)  ={{\left( a_{1}+a_{2}\right)
}}+i{{\left(  b_{1}+b_{2}\right)  }}=a_{3}+ib_{3} \,,
\]
claramente $z+z^{\ast}=2\operatorname{Re}z$, también $z-z^{\ast
}=2\operatorname{Im}z.$ Igualmente es inmediato comprobar que:
\[
\left(  z_{1}+z_{2}\right)  ^{\ast}=z_{1}^{\ast}+z_{2}^{\ast}\,.
\]

\item  Se multiplican números complejos por escalares multiplicando el escalar por sus partes reales e imaginarias:
\[
z_{3}=\alpha z_{1} \,\, \Rightarrow \,\, \alpha\left(  a_{1}+ib_{1}\right)
= \alpha a_{1}  +i\left(  \alpha b_{1}\right)\,.
\]

\item  Se multiplican números complejos entre si, multiplicando los dos binomios y teniendo cuidado que $i^{2}=-1$:
\[
z_{3}=z_{1}z_{2}\,\, \Rightarrow \,\, \left(  a_{1}+ib_{1}\right)  \cdot\left(
a_{2}+ib_{2}\right)  =\left(  a_{1}a_{2}-b_{1}b_{2}\right)  +i\left(
a_{1}b_{2}+b_{1}a_{2}\right)\,,
\]
también es inmediato comprobar que $\left(  z_{1}z_{2}\right)  ^{\ast }=z_{1}^{\ast}z_{2}^{\ast}$.

\item  Se dividen números complejos siguiendo la estrategia de
racionalización de fracciones irracionales. Esto es:
\[
z_{3}=\frac{z_{1}}{z_{2}} \,\, \Rightarrow \,\, \frac{\left(  a_{1}
+ib_{1}\right)  }{\left(  a_{2}+ib_{2}\right)  }=\frac{\left(  a_{1}
+ib_{1}\right)  }{\left(  a_{2}+ib_{2}\right)  }\frac{\left(  a_{2}
-ib_{2}\right)  }{\left(  a_{2}-ib_{2}\right)  }=\frac{a_{1}a_{2}+b_{1}b_{2}
}{\left(  a_{2}^{2}+b_{2}^{2}\right)  }+i\frac{b_{1}a_{2}-a_{1}b_{2}}{\left(
a_{2}^{2}+b_{2}^{2}\right)  }\,,
\]
es claro que el divisor será cualquier número complejo excepto el cero complejo: $0+i0$.
\end{itemize}

\subsection{Vectores y el plano complejo}
Mirando con cuidado el álgebra de números complejos nos damos cuenta que un número complejo puede ser representado por una \textit{dupla} de números, es decir:
\[
z=\left( a+ib\right) \quad \leftrightharpoons \quad z=\left( a,b\right)\,.
\]

Las propiedades entre números complejos de igualdad, suma y multiplicación por un escalar arriba expuestas se cumplen de forma inmediata con esta nueva representación. Hay que definir las operaciones de multiplicación y
división entre números complejos de forma que:
\[
\left( a_{1},b_{1}\right) \left( a_{2},b_{2}\right) =\left(
a_{1}a_{2}-b_{1}b_{2},a_{1}b_{2}+b_{1}a_{2}\right) \quad \wedge \quad \frac{
\left( a_{1},b_{1}\right) }{\left( a_{2},b_{2}\right) }=\left( \frac{
a_{1}a_{2}+b_{1}b_{2}}{\left( a_{2}^{2}+b_{2}^{2}\right) },\frac{
b_{1}a_{2}-a_{1}b_{2}}{\left( a_{2}^{2}+b_{2}^{2}\right) }\right)\,.
\]

Con está definición para la multiplicación de números complejos podemos ver que si la unidad compleja viene representa por el par $i=(0,1)$, entonces ahora si:
\[
i^2=ii=(0,1)(0,1)=(-1,0)=-1 \,.
\]
\newpage

%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\begin{minipage}{7.4cm}
La asociación de un número complejo con una pareja de números inmediatamente nos lleva a imaginar un punto $(x,y)$ en
un plano (complejo) en el cual la primera componente (horizontal) representa la parte real y la segunda
componente (vertical) representa la parte imaginaria. 

De esta forma asociamos a un número complejo a un vector
que une a ese punto $\left( x,y\right) $ con el origen del plano complejo. 

Como mencionamos con anterioridad, todo número complejo $z$ tiene asociado su complejo conjugado $z^*$. La representación geométrica de $z^*$ no es otra cosa que la reflexión de $z$ respecto al eje real. 

Por otro lado, $|z|=\sqrt{zz^*}$ viene a ser la distancia del punto $(0, 0)$ al punto $(x, y) $, es decir,  la longitud o norma  del vector $(x, y)$.

\end{minipage} \hfill 
\begin{minipage}{8.0cm} 
\includegraphics[width=2.4in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_10}
\caption{ Representación del plano complejo. El eje horizontal recibe el nombre de eje real, y el eje vertical el nombre de eje imaginario.}
\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%

Esta representación de números complejos como vectores en el plano (complejo) se conoce con el nombre de Diagrama de Argand\footnote{Jean Robert Argand (Ginebra, Suiza, 18 Julio 1768; París, Francia 13 agosto 1822). Contador pero matemático aficionado, propuso esta interpretación de números complejos como vectors en un plano complejo en un libro autoeditado con sus reflexiones que se perdió y fue rescatado 7 años después, fecha a partir de la cual Argand
comenzó a publicar en Matemáticas.} a pesar que no fue Jean
Argand, sino Caspar Wessel\footnote{Caspar Wessel (Vestby, Noruega 8 junio 1745; 25 marzo 1818, Copenhagen,Dinamarca) Matemático noruego que se dedicó principalmente al levantamiento topográfico de Noruega. Su trabajo sobre la interpretación de números complejos permaneció desconocido por casi 100 años.} el primero en proponerlo. Por cierto, esta interpretación fue tres veces redescubierta, primero por Caspar Wessel en 1799, luego por Jean Argand en 1806 y finalmente por Gauss\footnote{Johann Carl Friedrich  Gauss (30 abril 1777, Brunswick, Alemania; 23 febrero 1855, Göttingen, Alemania). Uno de los matemáticos más geniales y precoces de la Historia. Desde los 7 años comenzó a mostrar sus condiciones de genialidad. Sus contribuciones en Astronomía y Matemáticas son múltiples y diversas.} en 1831.

De esta manera, como un recordatorio al plano real podemos ver que:
\[
z=x+iy\quad\leftrightharpoons\quad z=r\left( \cos(\theta)+i\operatorname{sen}(\theta)\right)\,, \quad\text{con: }\left\{
\begin{array}{l}
r=\sqrt{zz^{\ast}}=\left| z\right| =\sqrt{x^{2}+y^{2}} \\
\\
\tan(\theta)=\dfrac{y}{x}\quad\text{donde }-\pi\leq\theta\leq\pi
\end{array}
\right.
\]

Con esta interpretación tendremos:
\begin{center}
\begin{tabular}{lll}
$x={Re}\ z$ & $\rightleftharpoons$ & componente real del vector $z$ o
parte real de $z$ \\
$y={Im} \ z$ & $\rightleftharpoons$ & componente imaginaria del vector $z$
o parte imaginaria de $z$ \\
$r=\sqrt{zz^{\ast}}=\left| z\right| $ & $\rightleftharpoons$ & módulo,
magnitud o valor absoluto de $z$ \\
$\theta$ & $\rightleftharpoons$ & ángulo polar o de fase del número
complejo $z$
\end{tabular}
\end{center}

La interpretación vectorial de números complejos permite que la suma de números complejos: $z_1=x_1 + iy_1$ y $z_2 = x_2 + i y_2$ sea representada por la ``regla del paralelogramo'', es decir, en la representación gráfica de la suma es fácil ver que $z_1$ y $z_2$ limitan un  paralelogramo cuya diagonal es $z_1+z_2$. 

Mientras que los productos escalar y vectorial nos llevan a:
\[
z_{1}\cdot z_{2}= {Re}\left( z_{1}z_{2}^{\ast}\right) = {Re}\left( z_{1}^{\ast}z_{2}\right) \quad\wedge\quad
z_{1}\times z_{2}= {Im}\left( z_{1}^{\ast}z_{2}\right) =-{Im}\left( z_{1}z_{2}^{\ast}\right) \,.
\]

Volviendo nuevamente a la relación $\left| z\right|=\sqrt{zz^{\ast}}$, observemos que:
\begin{itemize}
\item $\left| z_1 z_2\right|=\left| z_1\right| \left| z_2\right|$.

Ya que si $\left| z_1 z_2\right|$, $\left| z_1\right|$ y $\left| z_2\right|$ son cantidades positivas, entonces:
\[
\left| z_1 z_2\right|^2= \left(z_1z_2\right) \left(z_1z_2\right)^*
= z_1 z_2 z_1^* z_2^*= z_1z_1^* z_2 z_2^*=
\left| z_1\right|^2 \left| z_2\right|^2 =\left( \left| z_1\right| \left| z_2\right|\right)^2 \,.
\]

\item $\left| z_1+ z_2\right| \leq  \left| z_1\right|+ \left| z_2\right|$.

Veamos:
\begin{eqnarray*}
\left| z_1+ z_2\right|^2 &=&
\left( z_1+ \ z_2 \right)\left( z_1+ \ z_2 \right)^*=
\left( z_1+ z_2 \right)\left( z_1^*+ \ z_2^* \right)=
z_1z_1^* + z_2 z_2^* + z_1z_2^* + z_1^*z_2 = \\
&=&
\left| z_1\right|^2+\left| z_2\right|^2+2{Re}( z_1z_2^*) \leq 
\left| z_1\right|^2+\left| z_2\right|^2+2\left|{Re}( z_1z_2^*)\right| \\ 
&\leq&
\left| z_1\right|^2+\left| z_2\right|^2+2\left| z_1z_2^*\right| =
\left| z_1\right|^2+\left| z_2\right|^2+2\left| z_1\right| \left| z_2^*\right|=
\left| z_1\right|^2+\left| z_2\right|^2+2\left| z_1\right| \left| z_2\right| \\
&=&
\left(\left| z_1\right|+ \left| z_2\right|\right)^2 \,.
\end{eqnarray*}
Notemos que la igualdad $\left| z_1+ z_2\right|= \left| z_1\right|+ \left| z_2\right|$ se satisface si, y sólo si,  ${Re}(z_1z_2^*)=\left| z_1z_2^*\right|$.

\end{itemize}

\paragraph{Producto escalar:}
El producto escalar definido con anterioridad para vectores puede ser redefinido al caso de vectores con componentes complejas.

Dados los vectores: ${\bf a}=a^i {\bf e}_i$ y ${\bf b}=b^i {\bf e}_i$, con $\{a^i\}$ y  $\{b^i\}$ $\in \mathds{C}$, entonces 
\[
{\bf a} \cdot {\bf b}= \left(a^i\right)^* b_i  \,.
\]
Notemos que con esta definición, el producto ${\bf a} \cdot {\bf a}= \left(a^i\right)^* a_i$ siempre será un número real. Por lo tanto, $|{\bf a}|=\sqrt{{\bf a} \cdot {\bf a}}$ $\in \mathds{R}$.

Esta definición hace que ahora cambien algunas de las propiedades del producto escalar.

\begin{itemize}
\item ${\bf a} \cdot {\bf b}=\left({\bf b} \cdot {\bf a}\right)^*$.
\item $\left(\lambda {\bf a}\right) \cdot {\bf b}= 
\lambda^* \ {\bf a} \cdot {\bf b}$.
\item $ {\bf a} \cdot (\lambda{\bf b})= 
\lambda \ {\bf a} \cdot {\bf b}$.
\end{itemize}



\subsection{Fórmulas de Euler y De Moivre}
\label{FormulaEulerMoivre}
\index{Fórmulas de Euler}
\index{Euler!Fórmulas de }
\index{Fórmulas de De Moivre}
\index{De Moivre!Fórmulas de}
\index{Taylor!Brook Taylor}
\index{Números complejos!Fórmulas de Euler y De Moivre}
En cursos anteriores, nos hemos tropezado con la expansión en Taylor\footnote{Brook Taylor (18 agosto 1685, Edmonton, Inglaterra; 29 diciembre 1731, Londres, Inglaterra) Físico y Matemático inglés contemporáneo de Newton y Leibniz y junto con ellos participó profundamente en el desarrollo del cálculo diferencial e integral. Además de sus aportes al estudio del magnetismo,
capilaridad y termometría, desarrolló el área de diferencias finitas que hasta hoy utilizamos para cálculos en computación. Inventó la integración por partes y descubrió la serie que lleva su nombre.} de funciones, ésta serie permite expresar cualquier función analítica\footnote{Básicamente, una función analítica es una función que puede expresarse como una serie de potencias convergente.} alrededor de un punto $x_{0}$ como una serie infinita de potencias del argumento de la función, esto es:
\[
f\left( x\right) =f(x_{0})+\left. \frac{\mathrm{d }f\left( x\right) }{\mathrm{d
}x}\right| _{x=x_{0}}\left( x-x_{0}\right) +\frac{1}{2}\left. \frac{\mathrm{d
}^{2}\mathrm{ }f\left( x\right) }{\mathrm{d }x^{2}}\right|
_{x=x_{0}}\left( x-x_{0}\right) ^{2}+\frac{1}{3!}\left. \frac{\mathrm{d}^{3}
\mathrm{ }f\left( x\right) }{\mathrm{d }x^{3}}\right| _{x=x_{0}}\left(
x-x_{0}\right) ^{3}+\cdots \cdots
\]
O de manera equivalente:
\[
f\left( x\right)  =C_{n}\left( x-x_{0}\right) ^{n}\qquad \text{con }\,\, 
C_{n}=\frac{1}{n!}\left. \frac{\mathrm{d}^{n}\mathrm{\ }f\left( x\right) }{\mathrm{d\ }x^{n}}\right| _{x=x_{0}} \quad \text{y }\,\,  n=0,1,2,3, \dots
\]

Si consideramos que $x_{0}=0$, podremos ver a continuación algunos desarrollos en series de funciones elementales:
\begin{eqnarray*}
e^{x}&=&1+x+\frac{1}{2}x^{2}+\frac{1}{6}x^{3}+\frac{1}{24}x^{4}+\frac{1}{120} x^{5}+\frac{1}{720}x^{6}+\frac{1}{5040}\allowbreak x^{7}+\cdots \cdots  \\
\cos(x)& =& 1-\frac{1}{2}x^{2}+\frac{1}{24}x^{4}-\frac{1}{720}x^{6}+\cdots \cdots  \\
\operatorname{sen}(x)& =&x-\frac{1}{6}x^{3}+\frac{1}{120}x^{5}-\frac{1}{5040}x^{7}+\cdots \cdots
\end{eqnarray*}

Es fácil convencerse que para la serie de $e^{x}$ se tiene:
\[
e^{i\theta }=1+i\theta -\frac{1}{2}\theta ^{2}+\left( -\frac{1}{6}i\right)
\theta ^{3}+\frac{1}{24}\theta ^{4}+\frac{1}{120}i\theta ^{5}-\frac{1}{720}
\theta ^{6}+\left( -\frac{1}{5040}i\right) \theta ^{7}+\cdots \cdots
\]
y que puede arreglarse como: 
\[
e^{i\theta} =\underset{\cos(\theta) }{\underbrace{\left( 1-\frac{1}{2}
\theta ^{2}+\frac{1}{24}\theta ^{4}-\frac{1}{720}\theta ^{6}+\cdots \cdots
\right) }}+i\underset{\operatorname{sen}(\theta) }{\underbrace{\left( \theta -\frac{1}{6}\theta ^{3}+\frac{1}{120}\theta ^{5}-\frac{1}{5040}\theta ^{7} +\cdots \cdots \right)}}
\]
obteniéndose  la importante relación: 
\[
e^{i\theta} =\cos(\theta) +i\operatorname{sen}( \theta)\,,
\]
conocida como la relación de Euler\footnote{Leonhard Euler (15 abril 1707, Basilea, Suiza; 18 septiembre 1783, San Petersburgo, Rusia). Uno de los matemáticos más prolíficos de todos los tiempos. Desarrolló inmensamente campos como la geometría analítica y trigonometría, siendo el primero que consideró el coseno y el seno como funciones. Hizo aportes significativos en el desarrollo del cálculo diferencial e integral así como también, astronomía, elasticidad y mecánica de medios continuos.}. La fórmula de Euler, para  $-\pi < \theta < \pi$ resulta en los siguientes simpáticos resultados:
\[
i=e^{i\frac{\pi}{2}}\,,\quad -1=e^{i\pi}\,,\quad -i=e^{-i\frac{\pi}{2}} \,,\quad 1=e^{i2k\pi} \quad \, \mbox{con  }  k=0, \pm 1,\pm 2 , \pm 3 \dots
\] 

Entonces, tenemos tres formas de representar un número complejo:
\[
z=x+iy\quad \leftrightharpoons \quad z=|z|\left( \cos(\theta) +i\operatorname{sen} (\theta)\right) \quad \leftrightharpoons \quad
z=|z| e^{i\theta } \,.
\]

La expresión $z=x+iy$ se conoce como forma cartesiana de representación de un número complejo, la forma $z=r\left(\cos(\theta) +i\operatorname{sen}(\theta) \right) $ será la forma trigonométrica o polar y la expresión $z=r e^{i\theta}$ será la forma de Euler.  

Es importante notar una sutileza implícita en esta notación. La forma cartesiana representa unívocamente a un número complejo, mientras que la forma polar (y la de Euler), es ambigua, ya que:
\[
z=r\left(
\cos(\theta) +i\mbox{sen}(\theta) \right)= r\left(\cos(\theta +2n\pi)
+i\mbox{sen}(\theta +2n\pi)\right)\,, \quad n=0,\pm1, \pm 2, \pm 3, \dots 
\]
Es decir, existen varios valores del argumento que definen el mismo número complejo. Por ejemplo, el número $z=1+\sqrt{3} i$ lo podemos representar de las siguientes maneras:
\begin{eqnarray*}
z =1+\sqrt{3} i &=& 2e^{\frac{\pi}{3}i}= 2\left[ \cos\left(\frac{\pi}{3}\right)+i\mbox{sen}\left(\frac{\pi}{3}\right)\right] \\
&=&  2e^{\left(\frac{\pi}{3}+2n\pi\right)i}= 2\left[ \cos\left(\frac{\pi}{3}+2n\pi\right)+i\mbox{sen}\left(\frac{\pi}{3}+2n\pi\right)\right]\,.
\end{eqnarray*}

Analicemos estas situaciones con más detalle. Primero es importante notar que $r$ es siempre positivo, mientas que el ángulo $\theta$ puede tomar infinitos valores incluyendo valores negativos. Como ya vimos, $\theta$ se relaciona con las coordenadas cartesianas por la ecuación $\tan(\theta)=y/x$, y donde es necesario especificar el cuadrante para su cálculo. A cada valor del ángulo se le denomina el {\it argumento de} $z$. 

Por lo tanto, si tenemos un número complejo $z$ denotaremos por $\mbox{arg}(z)$ a:
\[
\mbox{arg}(z)=\{ \theta \in \mathds{R} \,\, /  \,\,  |z| (\cos(\theta) +i\mbox{sen}(\theta) ) \}\,.
\]
Esto significa que dos números complejos $z_1$ y $z_2$ serán iguales si: $|z_1|=|z_2|$ y $\mbox{arg}(z_1)=\mbox{arg}(z_2)$.

Dado un número complejo, $z \neq 0$, existe un único argumento $\Theta$ que se encuentra en el intervalo $[-\pi, \pi]$, y  lo representaremos por $\mbox{Arg}(z)$, el {\it argumento principal} o {\it valor principal}, de manera que:
\[
\mbox{arg}(z)=\mbox{Arg}(z)+2n\pi \,,  \qquad n=0,\pm1, \pm 2, \pm 3, \dots 
\]

Un número complejo, digamos $z=-1-i$ (tercer cuadrante) tendrá como valor principal: 
\[
\tan(\Theta)=\frac{y}{x}= 1 \,\, \Rightarrow \,\, 
\mbox{Arg}(-1-i)=-\frac{3\pi}{4}\,.
\]
Nota: no debe tomarse el valor $-\frac{5\pi}{4}$, ya que $-\pi \leq\Theta\leq \pi$. 

Lo que si es cierto es que:
\[
\mbox{arg}(-1-i)=-\frac{3\pi}{4}+2n\pi \,, \qquad n=0,\pm1, \pm 2, \pm 3, \dots
\]
%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\begin{minipage}{7.4cm}
Otro aspecto a rescatar de la forma de Euler o exponencial, es que la ecuación: 
\[
z= r e^{i \theta} \,,\qquad 0\leq \theta \leq 2\pi \,,
\]
no es más que una representación paramétrica del círculo $|z|=r$, es decir, de un círculo de radio $r$ y centrado en el origen. 

Por lo tanto, un círculo centrado en $z_0$ y de radio $R$ tendrá como ecuación paramétrica:
\[
|z-z_0|=R \,\, \Rightarrow \,\  z= z_0 +R e^{i \theta} \,,
\]
con  $ 0\leq \theta \leq 2\pi$. Como podemos apreciar en la figura \ref{circuloparametrico}.

\end{minipage} \hfill 
\begin{minipage}{8.0cm} 
\includegraphics[width=2.3in]{VOLUMEN_1/01_Vectores_Cartesianos/Figuras/Figura1_11}
\caption{Representación en el plano complejo del círculo $|z-z_0|=R$.}
\label{circuloparametrico}
\end{minipage}
\end{figure}
%%%%%%%%%%%%%%%%%

Es claro que las sumas de números complejos se plantean más fácilmente en su forma cartesiana. Mientras las multiplicación y división serán directas en la forma de Euler. Si $z_{1}=|z_{1}| e^{i\theta _{1}}$ y $z_{2}=|z_{2}| e^{i\theta _{2}}$, entonces: 
\begin{equation}
z_{1}z_{2}=|z_{1}| e^{i\theta_{1}} |z_{2}|  e^{i\theta_{2}}=
|z_{1}| |z_{2}| e^{i\left(\theta_{1}+\theta_{2}\right)}=|z_{1}z_{2}|\left( \cos \left( \theta_{1}+\theta_{2}\right) +i\mbox{sen} \left( \theta_{1}+\theta_{2}\right) \right) \,.
\label{z1porz2}
\end{equation}

Esto significa que para multiplicar dos números complejos se debe, por un lado, multiplicar sus módulos y por el otro, sumar sus argumentos. Geométricamente, al sumarse los argumentos, la multiplicación es en realidad un giro en el plano complejo por el producto de sus módulos, es decir, si multiplicamos un número por $i$, el resultado es un giro de un cuarto de vuelta hacia la izquierda, es por eso, que $i^2=-1=e^{i \pi}$.

Mientras que para la división: 
\[
\frac{z_{1}}{z_{2}}=
\frac{|z_{1}|e^{i\theta_{1}}}{|z_{2}| e^{i\theta_{2}}}=
\frac{|z_{1}| }{|z_{2}| }e^{i\left(\theta_{1}-\theta_{2}\right)}=
\frac{|z_{1}| }{|z_{2}| }\left( \cos \left( \theta_{1}-\theta_{2}\right) +i\mbox{sen} \left( \theta_{1}-\theta_{2}\right) \right) \,.
\]

Podemos notar de esta última expresión que el inverso de un número complejo diferente se cero es:
\begin{equation}
z^{-1}=\frac{1}{z}=\frac{1}{|z| }e^{-i\theta} \,.
\label{invz}
\end{equation}	

Se puede mostrar que a partir de (\ref{z1porz2}) y de  (\ref{invz}) resulta que:
\begin{eqnarray*}
\mbox{arg}(z_1z_2)&=&\mbox{arg}(z_1)+\mbox{arg}(z_2) \,, \\
\mbox{arg}\left(\frac{z_1}{z_2} \right)&=
&\mbox{arg}(z_1)-\mbox{arg}(z_2) \,.
\end{eqnarray*}


Por otro lado, notemos lo siguiente. Si $z=x+iy$, entonces: 
\[
e^{z}=e^{\left(x+iy\right)}=e^{x}e^{i y}=e^{x}\left( \cos(y)+i\mbox{sen}(y)\right)\,,
\]
y a partir de la relación o fórmula de Euler se puede demostrar:
\[
z^n=|z|^n \left(e^{i\theta }\right) ^{n}=|z|^n e^{in\theta }
\,\, \Rightarrow \,\,  
|z|^n\left( \cos( \theta) +i\mbox{sen} (\theta)\right) ^{n}=
|z|^n\left( \cos \left( n\theta \right) +i\mbox{sen} \left(n\theta \right)\right)\,,
\]
con $n$ entero.  

De manera que llegamos a la fórmula de  De Moivre:\footnote{Abraham De Moivre  (26 mayo 1667 en Vitry-le-Fran\c{c}ois, Francia; 27 noviembre 1754, Londres, Inglaterra) Matemático francés que tuvo que emigrar a Inglaterra por razones religiosas. Contemporáneo de Newton, Leibniz y Halley, fue pionero con sus contribuciones en geometría analítica y teoría de probabilidades.}
\[
\left( \cos( \theta) +i\mbox{sen} (\theta)\right) ^{n}=
\cos \left( n\theta \right) +i\mbox{sen} \left(n\theta \right) \,, \quad \text{con }n\text{ entero}.
\]


\subsection{Algunas aplicaciones inmediatas}
\index{Números complejos!Aplicaciones fórmulas de Euler y De Moivre} Presentaremos algunas aplicaciones inmediatas la fórmula de De Moivre en diferentes  ámbitos. 

\subsubsection{Identidades trigonométricas}
\index{Fórmulas de De Moivre!Identidades trigonométricas}

La primera de las aplicaciones de la fórmula de De Moivre es
para construir identidades trigonométricas en las cuales se expresa el coseno, o el seno, de factores de un ángulo. Veamos las siguientes (nada triviales) identidades trigonométricas:
\[
\cos(3\theta)=4\cos^{3}(\theta)-3\cos(\theta)\qquad\text{o}\qquad\operatorname*{sen}
(3\theta)=3\operatorname*{sen}(\theta)-4\mbox{sen}^{3}(\theta)\,.
\]

Para demostrar estas (y otras) identidades utilizamos la
fórmula de De Moivre, es decir:
\begin{align*}
\cos(3\theta)+i\operatorname*{sen(}3\theta) &  =\left(
\cos(\theta)+i\operatorname{sen}(\theta)\right)^{3}\\
&  =\cos^{3}(\theta)-3\cos(\theta)\operatorname{sen}^{2}(\theta)+i\left(
3\cos^{2}(\theta) \operatorname{sen}(\theta)-\operatorname{sen}^{3}(\theta)\right) \,.
\end{align*}

Igualando ahora parte real e imaginaria tendremos:
\begin{eqnarray*}
\cos(3\theta)&=&\cos^{3}(\theta)-3\cos(\theta)\operatorname{sen}^{2}(\theta)=\cos^{3}(\theta)-3\cos(\theta)\left(  1-\cos^{2}(\theta)\right)
=4\cos^{3}(\theta)-3\cos(\theta)\,, \\ 
\mbox{sen}(3\theta) &=&3\cos^{2}(\theta)\mbox{sen}(\theta)-\mbox{sen}^{3}(\theta) =3\left(  1-\mbox{sen}^{2}(\theta)\right)  \mbox{sen}(\theta)-\mbox{sen}^{3}(\theta)=3\mbox{sen}(\theta)-4\mbox{sen}^{3}(\theta)\,.
\end{eqnarray*}

El método puede extenderse a expresiones de senos y cosenos de $n\theta$.

Igualmente podemos desarrollar un método para encontrar expresiones de potencias de funciones trigonométricas en término de funciones de factores de ángulo del tipo $\left(  \cos(\theta)\right)  ^{n}=F\left( \cos(n\theta),\operatorname*{sen}(n\theta)\right)$.  Para empezar, supongamos que tenemos un número complejo de módulo $1$, de tal forma que:
\[
z=e^{i\theta}=\cos(\theta)+i\operatorname{sen}(\theta) \,\, \Rightarrow \,\,  \left\{
\begin{array}
[c]{l}
z^{n}+\dfrac{1}{z^{n}}=2\cos (n\theta)\\
\\
z^{n}-\dfrac{1}{z^{n}}=2i\operatorname*{sen}(n\theta)
\end{array}
\right.
\]

Estas identidades surgen de manera inmediata a partir de:
\begin{align*}
z^{n}+\frac{1}{z^{n}}  & =\left(  \cos(\theta)+i\operatorname{sen}(\theta)\right)
^{n}+\left( \cos(\theta)+i\operatorname{sen}(\theta)\right)  ^{-n}=\left(  \cos
(n\theta)+i\operatorname{sen} (n\theta) \right)  +\left(  \cos\left(
-n\theta\right)  +i\operatorname{sen}\left(  -n\theta\right)
\right)  \\
& =\cos (n\theta)+i\operatorname{sen} (n\theta)+\cos (n\theta)-i\operatorname{sen} (n\theta) =2\cos (n\theta) \,,
\end{align*}
igualmente puede demostrarse la segunda de las afirmaciones
anteriores. 

Supongamos además que $n=1,$ con lo cual se cumple que:
\[
z+\dfrac{1}{z}=e^{i\theta}+e^{-i\theta}=2\cos(\theta)\qquad\text{y}\qquad
z-\dfrac{1}{z}=e^{i\theta}-e^{-i\theta}=2i\operatorname{sen}(\theta)\,,
\]
que también lo sabíamos desde la más temprana edad de nuestros cursos de bachillerato. 

Ahora bien, lo que quizá no sabíamos en ese entonces (y quizá ahora tampoco) es que a partir de aquí podemos construir, expresiones como:
\[
\cos(\theta)=\frac12 \left(z+\dfrac{1}{z}\right) \,\, \Rightarrow \,\, 
\cos^{5}(\theta)=\frac{1}{2^{5}}\left(  z+\dfrac{1}{z}\right)^{5}=
\frac{1}{2^{5}}\left[  \left(  z^{5}+\frac{1}{z^{5}}\right)  +\left(5z^{3}
+\frac{5}{z^{3}}\right)  +\left(  10z+\frac{10}{z}\right)  \right]\,,
\]
es decir:
\[
\cos^{5}(\theta)=\frac{1}{2^{5}}\left[
2\cos(5\theta)+10\cos(3\theta)+20\cos( \theta)\right]\,.
\]

De la misma manera se puede proceder con otras potencias y con potencias de la función seno.

\subsubsection{Raíces de polinomios}
\index{Fórmulas de De Moivre!Raíces de polinomios}

Las raíces de un número complejo se obtienen de la relación:
\[
z^{1/n}= \left[|z| \left(\cos\left( \theta \right)+i\ \mbox{sen}\left(\theta \right) \right) \right]^{1/n}= |z|^{1/n} \left[\cos\left( \frac{\theta+2k\pi}{n} \right)+i\ \mbox{sen}\left(\frac{\theta+2k\pi}{n} \right) \right] \,,
\]
donde $k=0,1, \dots n-1$. De manera que la fórmula de De Moivre nos puede ayudar para encontrar raíces de polinomios. 

Supongamos, para empezar, que queremos encontrar las $n$ raíces de la ecuación:
\[
z^{n}=1 \,.
\]  

Para ello procedemos con el siguiente artificio:
\[
z^{n}=1=e^{i\left( 2\pi k \right)} =
\cos\left( 2\pi k \right) +i\mbox{sen}\left( 2\pi k \right) \,, 
\quad \text{donde  } k=0,1,2,....
\]
con lo cual las $n$ raíces de la ecuación $z^{n}=1$ serán:
\begin{equation}
z^{n}=1= e^{i\left( 2\pi k \right)} \,\,  \Rightarrow \,\,  
z=e^{i\left(\frac{2\pi k}{n}\right)}\,,
\label{zetaalan}
\end{equation}
esto es:
\[
z_{0}=1;\quad z_{1}=e^{2\pi i\left(  \frac{1}{n}\right)};
\quad z_{2}=e^{2\pi i\left(  \frac{2}{n}\right)  };
\quad z_{3}=e^{2\pi i\left(\frac{3}{n}\right)  };\cdots
\quad z_{n-2}=e^{2\pi i\left(  \frac{n-2}{n}\right)  };
\quad z_{n-1}=e^{2\pi i\left(  \frac{n-1}{n}\right)  } \,,
\]
es decir, $n$ raíces corresponderán a los $n$ valores de
$k=0,1,2,\cdots n-2,n-1$. Mayores valores de $k$ no proveen nuevas raíces.

Las raíces de la ecuación $z^{3}=1$ serán entonces: 
\[
z=e^{i\left(  \frac{2\pi k}{3}\right)} \,\,  \Rightarrow \,\,  
z_0=1\,, \,\,  z_1=e^{i\left(  \frac{2\pi }{3}\right)} \,, \,\, 
z_2= e^{i\left(  \frac{4\pi}{3}\right)}\,. 
\]

Como veremos más adelante, estas propiedades pueden extenderse a raíces de polinomios que contengan más términos. 

Una afirmación que nos han dicho, y que quizá no sepamos de dónde viene, es que \textit{si un polinomio con coeficientes reales tiene raíces complejas, ellas serán complejas conjugadas unas de otras}. Vale decir, si $z^{5}-z^{4}+2z-2=0$ tiene como raíz $ \left( 1+i \right)$, también tendrá como raíz $ \left(1 -i \right)$.

Esta afirmación se prueba de forma general si suponemos que tenemos la siguiente ecuación:
\[
a_{k}\ z^{k}=0\,,\quad\text{con }k=0,1,2,\cdots n-1,n \,\, \Rightarrow \,\,   
a_{0}+a_{1}\ z+a_{2}\ z^{2}\cdots+a_{n-1}\ z^{n-1}+a_{n}\ z^{n}=0\,,
\]
donde los coeficientes $a_{0}, a_1, a_{2},\cdots,a_{n-1}, a_{n}$ los
suponemos reales, esto es: $a_{k}=a_{k}^{\ast}$ para todos los
valores del índice $k$. 

Al tomar el complejo conjugado nos queda:
\[
a_{0}^{\ast}+a_{1}^{\ast}\ z^{\ast}+a_{2}^{\ast }\left(  z^{\ast}\right)
^{2}\cdots+a_{n-1}^{\ast}\left(  z^{\ast}\right)^{n-1}+a_{n}^{\ast}\left(z^{\ast}\right)^{n}=0 \,,
\]
y como los coeficientes son reales tenemos que:
\[
a_{0}+a_{1} z^{\ast}+a_{2}\left(  z^{\ast}\right) ^{2}\cdots+a_{n-1}\left(
z^{\ast}\right)  ^{n-1}+a_{n}\left(  z^{\ast }\right)  ^{n}=0\,,
\]
esto nos dice que si $z$ es solución también lo será $z^{\ast}$ ya que la ecuación es la misma por tener los mismos coeficientes (reales).


\subsubsection{Logaritmos y potencias de números complejos}
\index{Fórmulas de De Moivre!Logaritmos y potencias de números complejos}

La motivación surge cuando queremos resolver la ecuación:
\begin{equation}
e^{w}=z=re^{i\Theta} \,,\quad \mbox{con}\quad w,z \in \mathds{C} \quad \mbox{y}\quad   -\pi <\Theta <\pi\,.
\label{expw}
\end{equation}

Notemos que al despejar $w$ en realidad lo que tenemos es la función logarítmica, que como veremos en su debido tiempo puede escribirse de la forma $w=u+iv$. Por lo tanto:
\[
e^{u+iv}=e^{u}e^{iv}=re^{i\Theta} \,\, \Rightarrow \,\, 
e^{u}=r \,\, \wedge \,\, v=\Theta +2\pi n \,.
\]
donde $n$ es un entero. Por lo tanto, es claro que: 
\[
e^{u}=r \,\, \Rightarrow \,\, u=\ln(r)\,,
\]
y que la ecuación (\ref{expw}) se satisface si y sólo si:
\[
w=\ln(r)+i\left(\Theta +2\pi n\right) \,,\quad \mbox{con}\quad 
n=0,\pm1, \pm2,\pm3, \dots 
\]
Por lo tanto, si definimos la función multivaluada: 
\begin{equation}
\mbox{Log}(z)\equiv \ln|r|+i\left(\Theta +2\pi n\right) \,,\quad 
\mbox{con}\quad  n=0,\pm1, \pm2,\pm3, \dots 
\label{logz}
\end{equation}
podemos escribir la relación:
\[
e^{\mbox{Log}(z)}=z \quad  \mbox{con}\quad z\neq0 \,.
\]

Llamaremos {\it valor principal} de $\mbox{Log}(z)$ al valor que se obtiene cuando $n=0$ en la ecuación (\ref{logz}) y lo denotaremos con $\mbox{Ln}(z)$.
\begin{equation}
\mbox{Ln}(z)= \ln|r|+i\Theta \,.
\label{Lnz}
\end{equation}

Notemos que ésta es una función univaluada cuando $z\neq0$, y además, si combinamos (\ref{logz}) y (\ref{Lnz}) obtenemos:
\[
\mbox{Log}(z)=\mbox{Ln}(z)+i\ 2\pi n \,,\quad 
\mbox{con}\quad  n=0,\pm1, \pm2,\pm3, \dots 
\]

Podemos ver que cuando $z$ es un número real positivo, es decir, $z=re^{i 0}$, entonces recobramos la función logarítmica usual:
\[
\mbox{Ln}(z)=\mbox{Ln}(r)= \ln(r) \,.
\]

En consecuencia, podemos ver que: 
\begin{eqnarray*}
\mbox{Log}(1)&=&\ln(1)+i\left(0 +2\pi n\right) \quad 
 \,\, \wedge \,\, \quad\mbox{Ln}(1)=0 \\
\mbox{Log}(-1)&=&\ln(1)+i\left(\pi +2\pi n\right)\quad 
  \,\, \wedge \,\, \quad \mbox{Ln}(-1)=i \pi 
\end{eqnarray*}
con $n=0,\pm1, \pm2,\pm3, \dots$

Por otro lado, podemos ver también: 
\begin{eqnarray*}
\ln(z^n)&=&\ln\left[\left\{|z|\left(\cos(\theta) + i \ \mbox{sen}(\theta) \right) \right\}^n\right]=n \ln\left[|z|\left(\cos(\theta) + i \ \mbox{sen}(\theta) \right) \right]= n \ln\left[|z| \ e^{i \theta}  \right] \\ 
&=& n \ln\left(|z|\right) + n (\theta+2k\pi)i = 
n \ln\left(|z|\right) + (n \theta) i + (2nk \pi) i \,, \quad \mbox{con }  k \,\, 
\mbox{entero}\,.
\end{eqnarray*}



\subsection{{\color{Fuchsia}Ejemplos}}

\begin{enumerate}

\item En la sección \ref{FormulaEulerMoivre}, vimos que para el número complejo $z=-1-i$, resultaba que:
\[
\mbox{arg}(-1-i)=-\frac{3\pi}{4}+2n\pi \qquad n=0,\pm1, \pm 2, \pm 3, \dots
\]

Si lo queremos escribir en la forma exponencial tenemos que hacer lo siguiente:
\[
|z|=\sqrt{(-1)^2+(-1)^2}= \sqrt{2}\,\, \Rightarrow \,\,
-1-i= \sqrt{2}e^{-i\left(\frac{3\pi}{4}\right)}\,.
\]
Pero en realidad hay infinitas posibilidades para la forma exponencial de $z=-1-i$:
\[
-1-i= \sqrt{2}e^{i\left(-\frac{3\pi}{4}+2n\pi\right)} \,,\qquad n=0,\pm1, \pm2, \dots
\]

\item Consideremos el número $z=2+2 i$, para representarlo en la forma polar debemos calcular primeramente su módulo:
\[
|z|=\sqrt{x^2+y^2}=\sqrt{2^2+2^2}=\sqrt{8}=2\sqrt{2}\,.
\]
y luego el argumento:
\[
\tan(\theta)=\frac{y}{x}=\frac{2}{2} \,\, \Rightarrow \,\, \theta=\arctan(1)= \frac{\pi}{4}\,. 
\]

Por lo tanto, $z=2+2 i=2\sqrt{2}\left(\cos(\pi/4)+i\ \mbox{sen}(\pi/4) \right)$, es un punto ubicado en el primer cuadrante cuyo radio vector hace un ángulo de $45^{\circ}$ con respecto al eje $x$. 

En cambio, para el número complejo $z=-\sqrt{3}+i$, resulta:
\[
|z|=\sqrt{(-\sqrt{3})^2+1^2}=\sqrt{4}=2\,, \quad 
\theta=\arctan\left(-\frac{1}{\sqrt{3}}\right)= -\frac{\pi}{6}\,.
\]
Aquí debemos tener cuidado, pues el argumento principal en realidad es:
\[
\theta= \pi-\frac{\pi}{6}=\frac{5\pi}{6}\,.
\]
 $z=-\sqrt{3}+i=2\left(\cos(5\pi/6)+i\ \mbox{sen}(5\pi/6) \right)$, es un punto ubicado en el segundo cuadrante cuyo radio vector hace un ángulo de $150^{\circ}$ con respecto al eje $x$.

\item Supongamos la siguiente ecuación polinómica con sus raíces:
\[
z^{5}-z^{4}+2z-2=0 \,\, \Rightarrow \,\,
\left( z^{4}+2\right)  \left(
z-1\right) =0 \,\, \Rightarrow \,\, \left\{
\begin{array}
[c]{l}
z^{4}+2=0\,\, \Rightarrow \,\,  z^{4}=-2\\
\\
z-1=0 \,\, \Rightarrow \,\, z=1
\end{array}
\right.
\]
Entonces, de la ecuación (\ref{zetaalan}) podemos ver que:
\begin{align*}
z^{4}  & =-2(1)=-2\left(e^{i\left( 2\pi k \right)  }\right)
\,\, \Rightarrow \,\, 
z= \left[ -2\left(e^{i\left( 2\pi k \right)  }\right) \right]^{1/4}
= (-2)^{1/4}e^{i\left(  \frac{2\pi k}{4}\right)}
= \frac{{2}^{3/4}}{2} \left( 1+i \right)  e^{i\left(  \frac{2\pi k}{4}\right) } \,,
\end{align*}
donde hemos utilizado el hecho de que: $(-1)^{1/4}=i^{1/2}= \left(e^{i\frac{\pi}{2}}\right)^{1/2}= e^{i\frac{\pi}{4}}=
\frac{\sqrt{2}}{2}(1+i)$\,.

Por lo tanto:
\begin{eqnarray*}
z_0&=&\frac{1}{{2}^{1/4}} \left( 1+i \right)  \,, 
\qquad\qquad\qquad\qquad\qquad\quad 
z_1=\frac{1}{{2}^{1/4}} \left( 1+i \right) e^{i\left(  \frac{\pi}{2}\right) } =
\frac{i}{{2}^{1/4}}\left( 1+i \right)  \\
z_2&=&\frac{1}{{2}^{1/4}} \left( 1+i \right) e^{i\left( {\pi}\right) } =
-\frac{1}{{2}^{1/4}} \left( 1+i \right) \,, \quad
z_3=\frac{1}{{2}^{1/4}} \left( 1+i \right)e^{i\left(  \frac{3\pi }{2}\right) } =
-\frac{i}{{2}^{1/4}} \left( 1+i \right)\,.
\end{eqnarray*}

Entonces, la ecuación $z^{5}-z^{4}+2z-2=0$, tendrá las siguientes cinco raíces:
\[
z_0=\frac{1}{{2}^{1/4}} \left( 1+i \right) \,, \quad 
z_1=-\frac{1}{{2}^{1/4}}\left(1- i \right) \,, \quad 
z_2=-\frac{1}{{2}^{1/4}} \left( 1+i \right) \,, \quad 
z_3=\frac{1}{{2}^{1/4}} \left(1 -i \right)\,, \quad 
z_4=1\,.
\]

\item
Ahora consideremos el siguiente polinomio complejo: 
\[
P(z)=z^{6} -z^{5} +4z^{4} -6z^{3} +2z^{2} -8z +8 = 0\,.
\]
Si por algún método comprobamos que $(z^{3} -2)$ es uno de sus factores, entonces podremos encontrar las raíces del polinomio $P(z)$.  

Veamos,  claramente si $(z^{3} -2)$ es un factor, entonces  podemos expresar:
\[
P(z)=z^{6} -z^{5} +4z^{4} -6z^{3} +2z^{2} -8z +8 = (z^{3} -2)(z^{3} - z^{2} + 4z - 4)= (z^{3} -2)(z -1)({z}^{2}+4)\,,
\]
con lo cual, como $z$ es complejo, hay que tener cuidado con las raíces encubiertas. Entonces, la raíces son:
\[
z^{3}=2\,,\quad z=1\,, \quad z^2=-4\,.
\]

\begin{itemize}
\item Para  $z^2=-4\,\, \Rightarrow \,\,  z= \pm 2i$\,.

\item Para  $z^{3}=2 \,\, \Rightarrow \,\,  z^{3} =2\left(e^{i\left( 2\pi k \right) }\right) \,\, \Rightarrow \,\, 
z= \left[ 2\left(e^{i\left( 2\pi k \right)  }\right) \right]^{1/3}
= 2^{1/3}e^{i\left(  \frac{2\pi k}{3}\right)}$.

Por lo tanto:
\[
z_0=2^{1/3} \,, \quad 
z_1=2^{1/3}e^{i\left(  \frac{2\pi }{3}\right)} =
-\frac{2^{1/3}}{2}\left[1-\sqrt{3} i  \right]  \,, \quad 
z_2=2^{1/3}e^{i\left(  \frac{4\pi }{3}\right)} =
-\frac{2^{1/3}}{2}\left[1+\sqrt{3} i  \right]  \,.
\]
\end{itemize}

La ecuación: $z^{6} -z^{5} +4z^{4} -6z^{3} +2z^{2} -8z +8 = 0$, tendrá las siguientes seis raíces:
\[
z=\sqrt[3]{2} \,, \quad 
z=-\frac{1}{\sqrt[3]{4}}\left[1\pm \sqrt{3}\ i  \right]  \,, \quad 
z = 1 \,, \quad z = \pm 2i \,.
\]


\item Consideremos:
\[
\mbox{Log}\left(  -3i\right) =\mbox{Log}\left[
3e^{i\left(-\frac{\pi}{2}+2n\pi\right)  }\right]  =\ln(3)+i\left(  -\frac{\pi}{2}
+2n\pi\right)  \quad\text{con }n=0,1,2,\cdots
\]
decimos que el valor principal de $\mbox{Log}\left(-3i\right)$ será $\mbox{Ln}=\ln(3)-i\frac{\pi}{2}$\,.

Con la misma intuición se procede con las potencias de números complejos. 

Si queremos evaluar $z=i^{-5i}$ tendremos que proceder como sigue:
\[
z=i^{-5i}\,\, \Rightarrow \,\,\mbox{Log}\left( z\right) =\mbox{Log}
\left(  i^{-5i}\right)  =-5i\mbox{Log}\left(i\right)
=-5i\mbox{Log}\left[  e^{i\left(
\frac{\pi}{2}+2n\pi\right)  }\right] = {5\left(\frac{\pi}{2}+2n\pi\right)} \,,
\]
con lo cual $z=i^{-5i}$  ¡es un número real!

Para finalizar consideremos otro par de casos de potencias y logaritmos: $i^{i}$ y 
$\mbox{Log} \left[ \left\{ \sqrt{3} + i \right\}^{3} \right]$. 
\begin{itemize}
\item 
$
 i^{i} =\left[ e^{i\left( \frac{\pi}{2} +2n \pi \right)} \right]^{i} =  e^{i^{2} \left( \frac{\pi}{2} +2n \pi \right)} =
    e^{-\left( \frac{\pi}{2} +2n \pi \right)}\,.
$
\item 
$
\mbox{Log} \left[ \left( \sqrt{3} + i \right)^{3} \right] = 3 \mbox{Log}\left[ 2 e^{i\left(\arctan\left( \frac{1}{\sqrt{3}} \right)\right)} \right] =
    3 \left[\ln(2) +  i\left(\arctan \left(\frac{1}{\sqrt{3}}\right) +2n\pi \right) \right] = \ln(8) + i\left(\frac{\pi}{2} +6n \pi \right)$.
\end{itemize}

\end{enumerate}

\newpage
\subsection{{\color{red}Practicando con Maxima}} 

{\bf Maxima} maneja números complejos escritos en la forma: $a+bi$. Donde la unidad imaginaria es interpretada por el programa como $i=\%i$. 
Si no queremos que las salidas del programa mantenga la notación del   $\%i$ podemos is a la parte superior de la ventana del programa y hacer click en:
\begin{verbatim} 
                wxMaxima > Preferencias > Worksheet 
\end{verbatim}
y desactivar el botón que dice 
\begin{verbatim} 
                [] Mantener signo porcentual en símbolos especiales: %e, %i, etc.
\end{verbatim}

\begin{enumerate}
\item Algunos cálculos básicos. 

Los números imaginarios aparecen si queremos calcular la raíz cuadrada de un número negativo, por ejemplo,  $\sqrt{-7}$

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i1) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
sqrt(-7);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o1) }
\sqrt{7}\,i
\end{math}
\newline

El programa nos permite desarrollar toda el algebra en variable compleja. Si queremos sumar $z_1=1+2i$ y $z_2=3+4i$, escribimos: 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i2) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
z1:1+2*%i; z2:3+4*%i;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o2) }
2\,i+1
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o3) }
4\,i+3
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i4) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
z1+z2;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o4) }
6\,i+4
\end{math}
\newline

La multiplicación:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i5) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
z1*z2,expand;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o5) }
10\,i-5
\end{math}
\newline

Y la división:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i6) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
z1/z2;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o6) }
\frac{2\,i+1}{4\,i+3}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i7) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
rectform(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o7) }
\frac{2\,i}{25}+\frac{11}{25}
\end{math}
\newline

Este último comando pertenece a una lista de funciones de {\bf Maxima} para el cálculo de números complejos:
\begin{verbatim} 
          rectform(expresión) expresión en forma cartesiana o binómica
          realpart(expresión) parte real de expresión
          imagpart(expresión) parte imaginaria de expresión
          polarform(expresión) forma polar de expresión
          abs(expresión) módulo o valor absoluto de expresión
          cabs(expresión) módulo de expresión compleja
          carg(expresión) argumento de expresión
          conjugate(expresión) conjugado de expresión
          demoivre(expresión) expresa el número complejo utilizando senos y cosenos
          exponentialize(expresión) expresa el número complejo utilizando exponenciales
\end{verbatim}

Veamos como funcionan algunas de estos comandos:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i8) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
realpart(z1); imagpart(z1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o8) }
1
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o9) }
2
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i10) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
abs(z1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o10) }
\sqrt{5}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i11) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
polarform(z1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o11) }
\sqrt{5}\,e^{i\,\arctan(2)}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i12) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
cabs(z1);carg(z1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o12) }
\sqrt{5}
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o13) }
\arctan(2)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i14) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
conjugate(z1);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o14) }
1-2\,i
\end{math}
\newline

\item Para una función, digamos $\tan(x+iy)$,  la podemos escribir como exponenciales o funciones senos y cosenos.

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i15) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
tan(x+%i*y);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o15) }
\tan \left(i\,y+x\right)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i16) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
exponentialize(%),factor;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o16) }
\frac{i\,\left(e^{y}-e^{i\,x}\right)\,\left(e^{y}+e^{i\,x}\right)}{
 e^{2\,y}+e^{2\,i\,x}}
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i17) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
demoivre(%),factor;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o17) }
\frac{i\,\left(e^{y}-i\,\sin(x)-\cos(x)\right)\,\left(e^{y}+i\,\sin(x)
 +\cos(x)\right)}{e^{2\,y}+i\,\sin \left(2\,x\right)+\cos \left(2\,x
 \right)}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i18) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
log(3+%i*2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o18) }
\log \left(2\,i+3\right)
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i19) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
cabs(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o19) }
\sqrt{\frac{\log ^213}{4}+\arctan ^2\left(\frac{2}{3}\right)}
\end{math}

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i20) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
float(%);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o20) }
1.410846683153171
\end{math}
\newline

\item Tomemos dos números complejos, o vectores del plano complejo:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i21) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
z:a+b*%i; w:c+d*%i;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o21) }
i\,b+a
\end{math}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o22) }
i\,d+c
\end{math}
\newline

Revisemos la llamada igualdad del paralelogramo: la suma de los cuadrados de las longitudes de los cuatro lados de un paralelogramo, es igual a la suma de los cuadrados de las longitudes de las dos diagonales de éste. Es decir:
\[
|z+w|^2+|z-w|^2=2\left( |z|^2 +|w|^2 \right) \,.
\] 

Pero sabemos que $|z|^2=zz^{*}$, y por lo tanto:
\[
(w+z)(w+z)^{*} +(w-z)(w-z)^{*}= 2\left( |z|^2 +|w|^2 \right)\,.
\]

Calculemos el lado izquierdo de la ecuación anterior:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i23) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
(w+z)*conjugate(w+z)+(w-z)*conjugate(w-z),expand;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o23) }
2\,d^2+2\,c^2+2\,b^2+2\,a^2
\end{math}
\newline

Ahora el lado derecho, es decir, la suma de las longitudes al cuadrado de los cuatro lados:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i24) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
2*cabs(z)^2+2*cabs(w)^2,expand;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o24) }
2\,d^2+2\,c^2+2\,b^2+2\,a^2
\end{math}
\newline

\item Para encontrar las raíces de un número complejo, debemos declarar a la variable como compleja. 

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i25) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
declare(z,complex)$
\end{verbatim}}
\end{minipage}
\newline

De manera que si queremos encontrar las raíces de $z^3=1$

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i26) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ec1:z^3=1;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o26) }
z^3=1
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i27) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
solve(ec1,z);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o27) }
\left[ z=\frac{\sqrt{3}\,i-1}{2} , z=-\frac{\sqrt{3}\,i+1}{2} , z=1 \right] 
\end{math}
\newline

\item En otro de los ejemplo que discutimos anteriormente teníamos la ecuación:
\[
z^6-z^5+4z^4-6z^3 +2z^2-8z+8=0 \,,
\]
por lo tanto:

%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i28) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
ec2:z^6-z^5+4*z^4-6*z^3+2*z^2-8*z+8=0;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o28) }
z^6-z^5+4\,z^4-6\,z^3+2\,z^2-8\,z+8=0
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i29) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
factor(ec2);
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o29) }
\left(z-1\right)\,\left(z^2+4\right)\,\left(z^3-2\right)=0
\end{math}


%%%%%% INPUT:
\begin{minipage}[t]{8ex}
{\color{red}\bf \begin{verbatim} (%i30) 
\end{verbatim}}
\end{minipage}
\begin{minipage}[t]{\textwidth}{\color{blue}
\begin{verbatim}
solve(ec2,z),factor;
\end{verbatim}}
\end{minipage}

%%% OUTPUT:
\begin{math}\displaystyle \parbox{8ex}{\color{labelcolor}(\%o30) }
\left[ z=\frac{\sqrt{3}\,i-1}{2^{\frac{2}{3}}} , z=-\frac{\sqrt{3}
 \,i+1}{2^{\frac{2}{3}}} , z=2^{\frac{1}{3}} , z=1 , z=-2\,i , z=2\,i  \right] 
\end{math}

\end{enumerate}

\begin{center}
{\color{red}\rule{15.8cm}{0.4mm}}
\end{center}


\subsection{{\color{OliveGreen}Ejercicios}}
\begin{enumerate}
\item Si los números complejos $z_1=x_1+iy_1$ y $z_2=x_2+iy_2$ se pueden representar como vectores en el plano ${\bf z}_1= x_1{\bf i}+y_1{\bf j}$ y ${\bf z}_2= x_2{\bf i}+y_2{\bf j}$, muestre que:
\[
z_1^{*}z_2= {\bf z}_1\cdot{\bf z}_2+i{\bf k}\cdot ( {\bf z}_1\times{\bf z}_2)\,.
\]

\item Demuestre: 
\begin{enumerate}
\item
$
\cos(3\alpha)= \cos^3(\alpha)-3\cos(\alpha) \mbox{sen}^2(\alpha)\,.
$
\item
$
\mbox{sen}(3\alpha)= 3\cos^2(\alpha) \mbox{sen}(\alpha)- \mbox{sen}^3(\alpha) \,.
$
\end{enumerate}
\item Demuestre:
\begin{enumerate}
\item
$
\cos^4(\alpha)= \frac18 \left(3+4\cos(2\alpha) +\cos(4\alpha)\right)\,.
$
\item
$
\cos^3(\alpha)+\mbox{sen}^3(\alpha)= \frac14 
\left(\cos(3\alpha)+3\cos(\alpha)-  \mbox{sen}^3(\alpha) + 3\mbox{sen}(\alpha) \right) \,.
$
\end{enumerate}

\item Demuestre:
\[
\left(\frac{ix-1}{ix+1}\right)^{iy}=e^{(-2y\cot^{-1}(x))}\,,
\]
donde $x$ y $y$ son números reales.

\item Encuentre las raíces de: 
\[
{a)} \quad  (2i)^{1/2} \qquad {b)} \quad  \left(1-\sqrt{3}i\right)^{1/2} \qquad 
{c)} \quad  (-1)^{1/3} \qquad {d)} \quad  8^{1/6} \qquad 
{e)} \quad  (-8-8\sqrt{3}i)^{1/4} \,.
\]

\item Demuestre que:
\begin{enumerate}
\item
$
\mbox{Log}(-ie)=1-\frac{\pi}{2}i  \,.
$
\item
$
\mbox{Log}(1-i)=\frac{1}{2}\ln(2)-\frac{\pi}{4}i \,.
$
\item
$
\mbox{Log}(e)=1+2n\pi i \,.
$
\item
$
\mbox{Log}(i)=\left(2n+\frac12  \right) \pi i \,.
$

\end{enumerate}

 \item Dos funciones complejas $Z_{1}(t)$  y $Z_{2}(t)$ cumplen con las siguientes ecuaciones:
  \[
\frac{\mathrm{d} Z^{\ast}_{1}}{\mathrm{d}t}= = \frac{-i}{Z_{1} - Z_{2}} \quad \mathrm{y}  \quad \frac{\mathrm{d} Z^{\ast}_{2}}{\mathrm{d}t}= = \frac{-i}{Z_{2} - Z_{1}}
  \]Muestre que las siguientes cantidades son constantes:
  \begin{enumerate}
  \item $Z_{1} + Z_{2}$
  \item $|Z_{1} - Z_{2}|$
  \item $|Z_{1}|^{2} + |Z_{2}|^{2}$
  \end{enumerate}
  
\item Considere la siguiente ecuación:
\[
z^{7} -4z^{6} + 6z^{5} -6z^{4} +6z^{3} -12z^{2} +8z +4 =0 \,.
\] 
Encuentre sus raíces sabiendo que $z^{3}=2$.

\item Muestre que la expansión binomial puede ser escrita como:
\[
(1+x)^{n} = \sum^{n}_{m=0} A_{m}(n) \; x^{m} \,, \quad \mathrm{con} \quad 
A_{m}(n) = \frac{n!}{m!(n-m)!} \,.
\] 
Si está convencido de la expansión anterior, considere ahora una parecida: $\left(1 + e^{i \theta} \right)^{n} $ y muestre que: 
\[
\sum^{n}_{m=0} A_{m}(n) \; \cos (n \theta) = 2^{n} \cos^{n}\left( \frac{\theta}{2}\right) \cos \left( \frac{n \theta}{2} \right)  \,,
\] 
y
\[
\sum^{n}_{m=0} A_{m}(n) \; \mathrm{sen}(n \theta) = 
2^{n} \cos^{n}\left( \frac{\theta}{2}\right)  \mathrm{sen}\left( \frac{n \theta}{2} \right)\,.
\]

\item Las funciones hiperbólicas se definen como:
\[
\cosh (x) = \frac{e^{x} + e^{-x}}{2} \quad \mathrm{y} \quad \mathrm{senh}(x)  = \frac{e^{x} - e^{-x}}{2} \,,
\]
y de manera análoga a las funciones trigonométricas tendremos el resto de funciones:
\[
\tanh(x)=\frac{\mathrm{senh}(x)}{\cosh (x)}; \quad \mathrm{sech}(x) = \frac{1}{\cosh (x)};
\quad \mathrm{csech}(x) = \frac{1}{\mathrm{senh}(x)}; \quad \mathrm{ctanh}(x) = \frac{1}{\tanh(x)};
\]
\begin{enumerate}
  \item Muestre las siguientes equivalencias: 
  \[
\cosh(x) = \cos(ix), \quad  i \, \mathrm{senh}(x) = \mathrm{sen}(ix), \quad \cos(x) = \cosh(ix)
\quad \mathrm{y} \quad i \,\mathrm{sen}(x) = \mathrm{senh}(x)  \,.
  \]
  \item Muestre las siguientes identidades:
\[
\cosh^{2}(x) -  \mathrm{senh}^{2}(x) = 1; \quad 
\mathrm{sech}^{2}(x) = 1 -\tanh^{2}(x); \quad 
\cosh(2x) =   \cosh^{2}(x) +  \mathrm{senh}^{2}(x) \,.
\]  
  \item Resuelva las siguientes ecuaciones hiperbólicas:
\[
\cosh(x) -5 \mathrm{senh}(x) -5 =0, \quad 2 \cosh(4x) -8\cosh(2x) +5=0 \quad \mathrm{y} \quad
\cosh(x) = \mathrm{senh}(x) + 2\mathrm{sech}(x)\,.
\]  
\end{enumerate}

\item Resuelva con {\bf Maxima} los ejercicios anteriores.

\item Utilizando un programa de manipulación simbólica (ver Apéndice \ref{IntroMaxima}) realice las siguientes tareas.

\begin{enumerate}
\item Calcule la función $f(z)=e^z$ a partir de su expansión en serie que la define. Calcule también $f(z)$ cuando $z=e^{\frac{in\pi}{6}}$ para $n=0,1,2, \dots , 12$. 
Para los diferentes valores de $n$ haga una tabla con los valores de:  $\theta=\frac{n\pi}{6}$, $\operatorname{Re} \left(  z\right)$, 
$\operatorname{Im}\left(  z\right)$, 
$\operatorname{Re} \left(e^z\right)$, 
$\operatorname{Im}\left(e^z\right)$, $|z|$ y la fase de $e^z$.

\item Calcule y haga una tabla para los valores de 
$(x;y)=(0,0 ; 0,0)  (0,1 ; 0,1) (0,5 ; 0,5)  (1,0 ; 1,0) $  de:  
$\operatorname{Re} \left(\mbox{senh}(z)\right)$, 
$\operatorname{Im}\left(\mbox{senh}(z)\right)$, 
$|\mbox{senh}(z)|$ y la fase de $\mbox{senh}(z)$.

\item Calcule y haga una tabla para los valores de 
$(x;y)=(0,0 ; 0,0)  (0,1 ; 0,1) (0,5 ; 0,5)  (1,0 ; 1,0) $  de:  
$\operatorname{Re} \left(\cosh(z)\right)$, 
$\operatorname{Im}\left(\cosh(z)\right)$, 
$|\cosh(z)|$ y la fase de $\cosh(z)$.
\end{enumerate}

\end{enumerate}





